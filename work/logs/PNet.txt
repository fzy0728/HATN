loading data...
source domain:  books target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 11843
vocab-size:  100530
max  story size: 226
mean story size: 8
max  sentence size: 783
mean sentence size: 19
max memory size: 20
5600 400 6000 15750 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(100531, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 158.39541829, sen-loss: 77.05432564, dom-loss: 81.34109193, train-acc: 0.67892857, val-acc: 0.68500000 val_loss: 0.65902936, dom-acc: 0.77160714
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 146.63717198, sen-loss: 70.73615777, dom-loss: 75.90101451, train-acc: 0.75732143, val-acc: 0.79250000 val_loss: 0.59347957, dom-acc: 0.80017857
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 136.88947761, sen-loss: 61.82541096, dom-loss: 75.06406671, train-acc: 0.81500000, val-acc: 0.81500000 val_loss: 0.50043726, dom-acc: 0.74651786
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 126.23064399, sen-loss: 51.28667456, dom-loss: 74.94396943, train-acc: 0.85214286, val-acc: 0.85000000 val_loss: 0.40629584, dom-acc: 0.68375000
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 117.01018280, sen-loss: 42.04637593, dom-loss: 74.96380693, train-acc: 0.87017857, val-acc: 0.87000000 val_loss: 0.35628918, dom-acc: 0.65535714
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 112.40805835, sen-loss: 37.09000812, dom-loss: 75.31805044, train-acc: 0.87446429, val-acc: 0.87250000 val_loss: 0.34377727, dom-acc: 0.70785714
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.77587163, sen-loss: 35.26747723, dom-loss: 75.50839454, train-acc: 0.87928571, val-acc: 0.88000000 val_loss: 0.34190425, dom-acc: 0.70544643
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.04746664, sen-loss: 34.21939777, dom-loss: 75.82806855, train-acc: 0.88446429, val-acc: 0.87500000 val_loss: 0.33196807, dom-acc: 0.69955357
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.56714612, sen-loss: 33.56949235, dom-loss: 75.99765366, train-acc: 0.88071429, val-acc: 0.88000000 val_loss: 0.34637505, dom-acc: 0.70732143
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 109.02827728, sen-loss: 32.76248012, dom-loss: 76.26579726, train-acc: 0.88857143, val-acc: 0.88250000 val_loss: 0.32903945, dom-acc: 0.69285714
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 109.15040839, sen-loss: 32.41193891, dom-loss: 76.73846930, train-acc: 0.89178571, val-acc: 0.88750000 val_loss: 0.32058910, dom-acc: 0.67875000
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.55277604, sen-loss: 31.54069500, dom-loss: 77.01208103, train-acc: 0.89303571, val-acc: 0.89250000 val_loss: 0.31771204, dom-acc: 0.67258929
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 108.41954911, sen-loss: 31.21227141, dom-loss: 77.20727730, train-acc: 0.89446429, val-acc: 0.88500000 val_loss: 0.32251063, dom-acc: 0.67696429
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 108.08398992, sen-loss: 30.63881564, dom-loss: 77.44517446, train-acc: 0.89750000, val-acc: 0.89500000 val_loss: 0.31476593, dom-acc: 0.64848214
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 107.87969750, sen-loss: 30.20346390, dom-loss: 77.67623347, train-acc: 0.89892857, val-acc: 0.89250000 val_loss: 0.31157097, dom-acc: 0.65053571
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 107.69555271, sen-loss: 29.76228614, dom-loss: 77.93326676, train-acc: 0.90125000, val-acc: 0.89500000 val_loss: 0.31079021, dom-acc: 0.64937500
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 107.53530234, sen-loss: 29.40958146, dom-loss: 78.12572098, train-acc: 0.90285714, val-acc: 0.89250000 val_loss: 0.31167099, dom-acc: 0.63982143
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.38370341, sen-loss: 29.20021925, dom-loss: 78.18348402, train-acc: 0.90357143, val-acc: 0.89500000 val_loss: 0.30765685, dom-acc: 0.63982143
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 107.20621771, sen-loss: 28.69890145, dom-loss: 78.50731635, train-acc: 0.90678571, val-acc: 0.89250000 val_loss: 0.30660754, dom-acc: 0.61410714
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 106.87522274, sen-loss: 28.30972225, dom-loss: 78.56550115, train-acc: 0.90678571, val-acc: 0.89250000 val_loss: 0.30672160, dom-acc: 0.60267857
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 106.82731587, sen-loss: 28.11162747, dom-loss: 78.71568865, train-acc: 0.90910714, val-acc: 0.89250000 val_loss: 0.30394801, dom-acc: 0.60633929
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 106.51435125, sen-loss: 27.86099381, dom-loss: 78.65335721, train-acc: 0.90982143, val-acc: 0.89250000 val_loss: 0.30324152, dom-acc: 0.60883929
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 106.27986169, sen-loss: 27.47192574, dom-loss: 78.80793595, train-acc: 0.91017857, val-acc: 0.89250000 val_loss: 0.30305451, dom-acc: 0.60464286
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 106.31361663, sen-loss: 27.38318824, dom-loss: 78.93042845, train-acc: 0.91125000, val-acc: 0.89750000 val_loss: 0.30067617, dom-acc: 0.58187500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 105.62095207, sen-loss: 26.83540906, dom-loss: 78.78554308, train-acc: 0.91214286, val-acc: 0.89500000 val_loss: 0.29993811, dom-acc: 0.59044643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 105.33621132, sen-loss: 26.65584417, dom-loss: 78.68036723, train-acc: 0.91303571, val-acc: 0.89250000 val_loss: 0.30458856, dom-acc: 0.59500000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 105.30789495, sen-loss: 26.41822135, dom-loss: 78.88967359, train-acc: 0.91303571, val-acc: 0.89500000 val_loss: 0.29793316, dom-acc: 0.59830357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 104.87893271, sen-loss: 26.26738003, dom-loss: 78.61155331, train-acc: 0.91625000, val-acc: 0.89000000 val_loss: 0.29683256, dom-acc: 0.59750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 104.54292554, sen-loss: 25.88288215, dom-loss: 78.66004348, train-acc: 0.91464286, val-acc: 0.89500000 val_loss: 0.29565406, dom-acc: 0.58794643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 104.20175910, sen-loss: 25.61241426, dom-loss: 78.58934510, train-acc: 0.91589286, val-acc: 0.89500000 val_loss: 0.29503515, dom-acc: 0.58776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 103.81772649, sen-loss: 25.37929020, dom-loss: 78.43843627, train-acc: 0.91750000, val-acc: 0.89000000 val_loss: 0.30182704, dom-acc: 0.60758929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 103.33183795, sen-loss: 24.98503663, dom-loss: 78.34680098, train-acc: 0.91767857, val-acc: 0.89750000 val_loss: 0.29407373, dom-acc: 0.59633929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 103.10220659, sen-loss: 24.77362080, dom-loss: 78.32858557, train-acc: 0.92125000, val-acc: 0.89250000 val_loss: 0.29316872, dom-acc: 0.61883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.67697299, sen-loss: 24.63069445, dom-loss: 78.04627860, train-acc: 0.92125000, val-acc: 0.89500000 val_loss: 0.29256177, dom-acc: 0.62955357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 102.31354272, sen-loss: 24.33338866, dom-loss: 77.98015416, train-acc: 0.92142857, val-acc: 0.90000000 val_loss: 0.29061806, dom-acc: 0.64250000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 102.13598037, sen-loss: 24.17637357, dom-loss: 77.95960695, train-acc: 0.92285714, val-acc: 0.89500000 val_loss: 0.29195878, dom-acc: 0.61000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 101.53924304, sen-loss: 23.83004111, dom-loss: 77.70920169, train-acc: 0.92250000, val-acc: 0.89250000 val_loss: 0.30014870, dom-acc: 0.64482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 101.16804999, sen-loss: 23.51097313, dom-loss: 77.65707684, train-acc: 0.92303571, val-acc: 0.89500000 val_loss: 0.29130432, dom-acc: 0.63598214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.82888532, sen-loss: 23.20549156, dom-loss: 77.62339401, train-acc: 0.92500000, val-acc: 0.89500000 val_loss: 0.29103446, dom-acc: 0.64357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.84766173, sen-loss: 23.32748800, dom-loss: 77.52017373, train-acc: 0.92589286, val-acc: 0.89750000 val_loss: 0.29038328, dom-acc: 0.64357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 100.12953347, sen-loss: 22.73100351, dom-loss: 77.39852989, train-acc: 0.92821429, val-acc: 0.89500000 val_loss: 0.29173496, dom-acc: 0.65285714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 99.67825139, sen-loss: 22.42600854, dom-loss: 77.25224316, train-acc: 0.92714286, val-acc: 0.90000000 val_loss: 0.29028511, dom-acc: 0.65866071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 99.30800545, sen-loss: 22.09858269, dom-loss: 77.20942259, train-acc: 0.93089286, val-acc: 0.89500000 val_loss: 0.29049250, dom-acc: 0.66883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [44 ] loss: 99.06811136, sen-loss: 21.92724445, dom-loss: 77.14086699, train-acc: 0.93053571, val-acc: 0.89500000 val_loss: 0.29395536, dom-acc: 0.66678571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [45 ] loss: 98.84402496, sen-loss: 21.77720778, dom-loss: 77.06681728, train-acc: 0.93285714, val-acc: 0.89000000 val_loss: 0.29681316, dom-acc: 0.65892857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [46 ] loss: 98.54548615, sen-loss: 21.46795566, dom-loss: 77.07753050, train-acc: 0.93339286, val-acc: 0.89250000 val_loss: 0.29664931, dom-acc: 0.66937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [47 ] loss: 98.31288975, sen-loss: 21.18784048, dom-loss: 77.12504929, train-acc: 0.93232143, val-acc: 0.89500000 val_loss: 0.29244614, dom-acc: 0.66392857
---------------------------------------------------

Successfully load model from save path: ./work/models/books_dvd_PNet.ckpt
Best Epoch: [ 42] best val accuracy: 0.00000000 best val loss: 0.29028511
Testing accuracy: 0.87216667
./work/attentions/books_dvd_train.txt
./work/pivots/books_dvd_pos.txt
./work/pivots/books_dvd_neg.txt
./work/attentions/books_dvd_test.txt
loading data...
source domain:  books target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 17009
vocab-size:  83050
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 18
max memory size: 20
5600 400 6000 15750 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83051, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.47965133, sen-loss: 77.02578890, dom-loss: 82.45386320, train-acc: 0.68017857, val-acc: 0.67500000 val_loss: 0.65861726, dom-acc: 0.81133929
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 145.70526743, sen-loss: 70.69662118, dom-loss: 75.00864661, train-acc: 0.75607143, val-acc: 0.77500000 val_loss: 0.59332007, dom-acc: 0.88133929
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 135.00784540, sen-loss: 61.80851507, dom-loss: 73.19933069, train-acc: 0.81535714, val-acc: 0.81000000 val_loss: 0.50118887, dom-acc: 0.81919643
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 124.40889943, sen-loss: 51.36653012, dom-loss: 73.04236907, train-acc: 0.85232143, val-acc: 0.84750000 val_loss: 0.40814656, dom-acc: 0.74580357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 115.86517680, sen-loss: 42.11083938, dom-loss: 73.75433761, train-acc: 0.87071429, val-acc: 0.87000000 val_loss: 0.35752711, dom-acc: 0.72589286
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.57470614, sen-loss: 36.99806771, dom-loss: 74.57663858, train-acc: 0.87875000, val-acc: 0.87250000 val_loss: 0.34420031, dom-acc: 0.72767857
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.81868315, sen-loss: 35.18280517, dom-loss: 75.63587809, train-acc: 0.88071429, val-acc: 0.88250000 val_loss: 0.34264868, dom-acc: 0.70464286
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.91074288, sen-loss: 34.13146406, dom-loss: 76.77927887, train-acc: 0.88553571, val-acc: 0.87750000 val_loss: 0.33207780, dom-acc: 0.68107143
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.94131285, sen-loss: 33.49803571, dom-loss: 77.44327730, train-acc: 0.88071429, val-acc: 0.88250000 val_loss: 0.34804893, dom-acc: 0.65883929
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.93871689, sen-loss: 32.68732110, dom-loss: 78.25139570, train-acc: 0.88839286, val-acc: 0.88250000 val_loss: 0.32980317, dom-acc: 0.63303571
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.10634917, sen-loss: 32.36084256, dom-loss: 78.74550647, train-acc: 0.89178571, val-acc: 0.88500000 val_loss: 0.32049909, dom-acc: 0.57482143
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.61249721, sen-loss: 31.48285301, dom-loss: 79.12964427, train-acc: 0.89500000, val-acc: 0.89000000 val_loss: 0.31772590, dom-acc: 0.57339286
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.34275991, sen-loss: 31.16600777, dom-loss: 79.17675221, train-acc: 0.89446429, val-acc: 0.88500000 val_loss: 0.32361734, dom-acc: 0.58107143
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 109.81948876, sen-loss: 30.57575354, dom-loss: 79.24373502, train-acc: 0.89785714, val-acc: 0.89250000 val_loss: 0.31494603, dom-acc: 0.56133929
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.12522364, sen-loss: 30.14643799, dom-loss: 78.97878551, train-acc: 0.90017857, val-acc: 0.89250000 val_loss: 0.31142464, dom-acc: 0.56133929
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.46229136, sen-loss: 29.70568497, dom-loss: 78.75660628, train-acc: 0.90178571, val-acc: 0.89000000 val_loss: 0.31110299, dom-acc: 0.60008929
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 107.92830241, sen-loss: 29.33958787, dom-loss: 78.58871490, train-acc: 0.90196429, val-acc: 0.89250000 val_loss: 0.31334642, dom-acc: 0.60241071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.33273196, sen-loss: 29.14380522, dom-loss: 78.18892688, train-acc: 0.90482143, val-acc: 0.89250000 val_loss: 0.30821937, dom-acc: 0.61848214
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.75122094, sen-loss: 28.64074390, dom-loss: 78.11047739, train-acc: 0.90571429, val-acc: 0.89000000 val_loss: 0.30779466, dom-acc: 0.59580357
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 106.15322948, sen-loss: 28.24433811, dom-loss: 77.90889132, train-acc: 0.90839286, val-acc: 0.89000000 val_loss: 0.30775952, dom-acc: 0.61062500
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 105.74595344, sen-loss: 28.03257828, dom-loss: 77.71337515, train-acc: 0.90910714, val-acc: 0.89250000 val_loss: 0.30514434, dom-acc: 0.62714286
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 105.30418497, sen-loss: 27.79750447, dom-loss: 77.50668085, train-acc: 0.91035714, val-acc: 0.89500000 val_loss: 0.30474919, dom-acc: 0.63776786
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 104.95905966, sen-loss: 27.40162256, dom-loss: 77.55743730, train-acc: 0.91125000, val-acc: 0.89500000 val_loss: 0.30457282, dom-acc: 0.62437500
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 104.99936324, sen-loss: 27.34949578, dom-loss: 77.64986730, train-acc: 0.91214286, val-acc: 0.89000000 val_loss: 0.30220267, dom-acc: 0.61580357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 104.32081097, sen-loss: 26.76114231, dom-loss: 77.55966854, train-acc: 0.91303571, val-acc: 0.88750000 val_loss: 0.30149025, dom-acc: 0.62330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 104.21574312, sen-loss: 26.58700608, dom-loss: 77.62873709, train-acc: 0.91321429, val-acc: 0.89000000 val_loss: 0.30779359, dom-acc: 0.59410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 104.04148030, sen-loss: 26.34172547, dom-loss: 77.69975519, train-acc: 0.91446429, val-acc: 0.88500000 val_loss: 0.29976329, dom-acc: 0.63241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 103.89846790, sen-loss: 26.18514132, dom-loss: 77.71332622, train-acc: 0.91678571, val-acc: 0.89000000 val_loss: 0.29930094, dom-acc: 0.60955357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 103.55504787, sen-loss: 25.79823180, dom-loss: 77.75681627, train-acc: 0.91714286, val-acc: 0.88500000 val_loss: 0.29818410, dom-acc: 0.60107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 103.46384931, sen-loss: 25.53288857, dom-loss: 77.93096071, train-acc: 0.91696429, val-acc: 0.88750000 val_loss: 0.29766348, dom-acc: 0.60348214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 103.12156701, sen-loss: 25.29981170, dom-loss: 77.82175553, train-acc: 0.91678571, val-acc: 0.89000000 val_loss: 0.30656382, dom-acc: 0.61196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.76265061, sen-loss: 24.88824908, dom-loss: 77.87440157, train-acc: 0.92053571, val-acc: 0.88750000 val_loss: 0.29726997, dom-acc: 0.60482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.55097413, sen-loss: 24.68740954, dom-loss: 77.86356503, train-acc: 0.92107143, val-acc: 0.89250000 val_loss: 0.29713887, dom-acc: 0.61633929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.24648780, sen-loss: 24.52727019, dom-loss: 77.71921772, train-acc: 0.92178571, val-acc: 0.89250000 val_loss: 0.29666376, dom-acc: 0.63446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 101.90927345, sen-loss: 24.23744613, dom-loss: 77.67182720, train-acc: 0.92410714, val-acc: 0.88750000 val_loss: 0.29491022, dom-acc: 0.65339286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 101.60848814, sen-loss: 24.06041595, dom-loss: 77.54807198, train-acc: 0.92446429, val-acc: 0.89500000 val_loss: 0.29760483, dom-acc: 0.62116071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 101.10838395, sen-loss: 23.71055707, dom-loss: 77.39782685, train-acc: 0.92410714, val-acc: 0.89250000 val_loss: 0.30589327, dom-acc: 0.67500000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.67700273, sen-loss: 23.40986809, dom-loss: 77.26713467, train-acc: 0.92482143, val-acc: 0.88750000 val_loss: 0.29611146, dom-acc: 0.67696429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.18380684, sen-loss: 23.09699324, dom-loss: 77.08681333, train-acc: 0.92750000, val-acc: 0.89500000 val_loss: 0.29686376, dom-acc: 0.70196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.24457031, sen-loss: 23.15369342, dom-loss: 77.09087688, train-acc: 0.92839286, val-acc: 0.88500000 val_loss: 0.29648247, dom-acc: 0.70696429
---------------------------------------------------

Successfully load model from save path: ./work/models/books_electronics_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.29491022
Testing accuracy: 0.83883333
./work/attentions/books_electronics_train.txt
./work/pivots/books_electronics_pos.txt
./work/pivots/books_electronics_neg.txt
./work/attentions/books_electronics_test.txt
loading data...
source domain:  books target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 13856
vocab-size:  78006
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 17
max memory size: 20
5600 400 6000 15750 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78007, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 158.69050539, sen-loss: 77.00462729, dom-loss: 81.68587822, train-acc: 0.68089286, val-acc: 0.68250000 val_loss: 0.65841991, dom-acc: 0.81571429
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 145.37075281, sen-loss: 70.64262056, dom-loss: 74.72813296, train-acc: 0.75696429, val-acc: 0.78250000 val_loss: 0.59280372, dom-acc: 0.87901786
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 135.05635417, sen-loss: 61.69020867, dom-loss: 73.36614567, train-acc: 0.81589286, val-acc: 0.81250000 val_loss: 0.49987036, dom-acc: 0.86348214
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 124.44395900, sen-loss: 51.15902501, dom-loss: 73.28493381, train-acc: 0.85321429, val-acc: 0.84750000 val_loss: 0.40663862, dom-acc: 0.82428571
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 115.79341179, sen-loss: 41.87745841, dom-loss: 73.91595364, train-acc: 0.87232143, val-acc: 0.87000000 val_loss: 0.35788262, dom-acc: 0.77196429
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.68947804, sen-loss: 36.95219810, dom-loss: 74.73728007, train-acc: 0.87714286, val-acc: 0.86750000 val_loss: 0.34700531, dom-acc: 0.74285714
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 111.03313595, sen-loss: 35.17256327, dom-loss: 75.86057276, train-acc: 0.88285714, val-acc: 0.88000000 val_loss: 0.34528798, dom-acc: 0.71348214
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.81530839, sen-loss: 34.11760628, dom-loss: 76.69770277, train-acc: 0.88517857, val-acc: 0.87250000 val_loss: 0.33599809, dom-acc: 0.68875000
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.88623202, sen-loss: 33.49481125, dom-loss: 77.39142084, train-acc: 0.88250000, val-acc: 0.87500000 val_loss: 0.35156214, dom-acc: 0.67526786
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.78037655, sen-loss: 32.68351007, dom-loss: 78.09686613, train-acc: 0.88821429, val-acc: 0.87750000 val_loss: 0.33307546, dom-acc: 0.65741071
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.04774958, sen-loss: 32.33759493, dom-loss: 78.71015501, train-acc: 0.89232143, val-acc: 0.88250000 val_loss: 0.32477653, dom-acc: 0.63348214
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.32537925, sen-loss: 31.46858658, dom-loss: 78.85679305, train-acc: 0.89392857, val-acc: 0.88250000 val_loss: 0.32208335, dom-acc: 0.62357143
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.20830107, sen-loss: 31.14598025, dom-loss: 79.06232059, train-acc: 0.89392857, val-acc: 0.88000000 val_loss: 0.32751817, dom-acc: 0.61714286
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 109.70000237, sen-loss: 30.57636395, dom-loss: 79.12363774, train-acc: 0.89785714, val-acc: 0.88250000 val_loss: 0.31921795, dom-acc: 0.60062500
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.15382862, sen-loss: 30.12671170, dom-loss: 79.02711666, train-acc: 0.89928571, val-acc: 0.88250000 val_loss: 0.31601152, dom-acc: 0.60616071
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.45286739, sen-loss: 29.70436269, dom-loss: 78.74850464, train-acc: 0.90017857, val-acc: 0.88000000 val_loss: 0.31558344, dom-acc: 0.62455357
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 108.05392754, sen-loss: 29.34654732, dom-loss: 78.70738024, train-acc: 0.90160714, val-acc: 0.88500000 val_loss: 0.31761813, dom-acc: 0.62294643
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.36345279, sen-loss: 29.11601277, dom-loss: 78.24744004, train-acc: 0.90446429, val-acc: 0.88250000 val_loss: 0.31288475, dom-acc: 0.63276786
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.89235383, sen-loss: 28.64662286, dom-loss: 78.24573094, train-acc: 0.90571429, val-acc: 0.88250000 val_loss: 0.31234622, dom-acc: 0.62526786
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 106.41126680, sen-loss: 28.24627091, dom-loss: 78.16499597, train-acc: 0.90821429, val-acc: 0.88000000 val_loss: 0.31201801, dom-acc: 0.62446429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 105.87420923, sen-loss: 28.04742394, dom-loss: 77.82678556, train-acc: 0.90785714, val-acc: 0.88500000 val_loss: 0.30969235, dom-acc: 0.63839286
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 105.43706077, sen-loss: 27.80044083, dom-loss: 77.63662010, train-acc: 0.91035714, val-acc: 0.88500000 val_loss: 0.30904552, dom-acc: 0.64455357
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 105.13374811, sen-loss: 27.40794641, dom-loss: 77.72580189, train-acc: 0.91250000, val-acc: 0.89000000 val_loss: 0.30967355, dom-acc: 0.64169643
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 104.85920531, sen-loss: 27.33928921, dom-loss: 77.51991642, train-acc: 0.91321429, val-acc: 0.88750000 val_loss: 0.30670241, dom-acc: 0.64294643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 104.16694337, sen-loss: 26.77823036, dom-loss: 77.38871306, train-acc: 0.91321429, val-acc: 0.88750000 val_loss: 0.30615529, dom-acc: 0.63785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 103.96330881, sen-loss: 26.60306406, dom-loss: 77.36024457, train-acc: 0.91375000, val-acc: 0.88750000 val_loss: 0.31139994, dom-acc: 0.64660714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 103.74441719, sen-loss: 26.36913791, dom-loss: 77.37527925, train-acc: 0.91464286, val-acc: 0.88250000 val_loss: 0.30434030, dom-acc: 0.64732143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 103.56791151, sen-loss: 26.20393496, dom-loss: 77.36397666, train-acc: 0.91589286, val-acc: 0.89000000 val_loss: 0.30359858, dom-acc: 0.64285714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 103.16050971, sen-loss: 25.83287998, dom-loss: 77.32762933, train-acc: 0.91678571, val-acc: 0.88500000 val_loss: 0.30285698, dom-acc: 0.64750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 102.93860555, sen-loss: 25.56092402, dom-loss: 77.37768167, train-acc: 0.91660714, val-acc: 0.88500000 val_loss: 0.30230078, dom-acc: 0.64000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 102.55581862, sen-loss: 25.34851913, dom-loss: 77.20729941, train-acc: 0.91571429, val-acc: 0.88500000 val_loss: 0.31157446, dom-acc: 0.65669643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.19853783, sen-loss: 24.92522731, dom-loss: 77.27331060, train-acc: 0.91875000, val-acc: 0.88750000 val_loss: 0.30175099, dom-acc: 0.64866071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.98715967, sen-loss: 24.70754294, dom-loss: 77.27961653, train-acc: 0.92035714, val-acc: 0.89500000 val_loss: 0.30168769, dom-acc: 0.65625000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 101.82085717, sen-loss: 24.56917217, dom-loss: 77.25168461, train-acc: 0.92107143, val-acc: 0.89500000 val_loss: 0.30116045, dom-acc: 0.66750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 101.39261973, sen-loss: 24.26345223, dom-loss: 77.12916768, train-acc: 0.92321429, val-acc: 0.89000000 val_loss: 0.29908234, dom-acc: 0.66508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 101.34614819, sen-loss: 24.12205764, dom-loss: 77.22409046, train-acc: 0.92160714, val-acc: 0.89500000 val_loss: 0.30147412, dom-acc: 0.67008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.86096197, sen-loss: 23.77571375, dom-loss: 77.08524841, train-acc: 0.92303571, val-acc: 0.89000000 val_loss: 0.31101716, dom-acc: 0.67446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.46814078, sen-loss: 23.43399958, dom-loss: 77.03414112, train-acc: 0.92392857, val-acc: 0.89250000 val_loss: 0.30053443, dom-acc: 0.66366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.19804889, sen-loss: 23.11698074, dom-loss: 77.08106816, train-acc: 0.92589286, val-acc: 0.89500000 val_loss: 0.30123281, dom-acc: 0.67366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.37150753, sen-loss: 23.24210521, dom-loss: 77.12940252, train-acc: 0.92696429, val-acc: 0.89750000 val_loss: 0.30069113, dom-acc: 0.68169643
---------------------------------------------------

Successfully load model from save path: ./work/models/books_kitchen_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.29908234
Testing accuracy: 0.85183333
./work/attentions/books_kitchen_train.txt
./work/pivots/books_kitchen_pos.txt
./work/pivots/books_kitchen_neg.txt
./work/attentions/books_kitchen_test.txt
loading data...
source domain:  books target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 30180
vocab-size:  98084
max  story size: 189
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
5600 400 6000 15750 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(98085, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 158.41588271, sen-loss: 77.00354797, dom-loss: 81.41233510, train-acc: 0.68035714, val-acc: 0.67250000 val_loss: 0.65829533, dom-acc: 0.78428571
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 146.47627056, sen-loss: 70.57519794, dom-loss: 75.90107268, train-acc: 0.75678571, val-acc: 0.77750000 val_loss: 0.59169340, dom-acc: 0.80705357
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 136.70477712, sen-loss: 61.57961196, dom-loss: 75.12516499, train-acc: 0.81321429, val-acc: 0.81250000 val_loss: 0.49872458, dom-acc: 0.76714286
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 126.11570680, sen-loss: 51.07031944, dom-loss: 75.04538751, train-acc: 0.85625000, val-acc: 0.85000000 val_loss: 0.40303540, dom-acc: 0.72008929
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 116.86411095, sen-loss: 41.74062265, dom-loss: 75.12348843, train-acc: 0.87017857, val-acc: 0.87750000 val_loss: 0.35256267, dom-acc: 0.72089286
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 112.13157469, sen-loss: 36.91053271, dom-loss: 75.22104222, train-acc: 0.87714286, val-acc: 0.87500000 val_loss: 0.34134945, dom-acc: 0.74053571
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.65330482, sen-loss: 35.20054185, dom-loss: 75.45276248, train-acc: 0.87946429, val-acc: 0.88000000 val_loss: 0.33839861, dom-acc: 0.73535714
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 109.98378795, sen-loss: 34.14718145, dom-loss: 75.83660638, train-acc: 0.88482143, val-acc: 0.88250000 val_loss: 0.32828021, dom-acc: 0.73491071
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.33655059, sen-loss: 33.50872205, dom-loss: 75.82782894, train-acc: 0.88035714, val-acc: 0.88000000 val_loss: 0.34345251, dom-acc: 0.72812500
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 108.91000718, sen-loss: 32.72306941, dom-loss: 76.18693805, train-acc: 0.88839286, val-acc: 0.88250000 val_loss: 0.32570738, dom-acc: 0.71830357
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 108.95877337, sen-loss: 32.38545664, dom-loss: 76.57331651, train-acc: 0.89321429, val-acc: 0.88750000 val_loss: 0.31685093, dom-acc: 0.70928571
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.41038394, sen-loss: 31.51754634, dom-loss: 76.89283776, train-acc: 0.89482143, val-acc: 0.88500000 val_loss: 0.31402993, dom-acc: 0.70116071
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 108.13083243, sen-loss: 31.21254964, dom-loss: 76.91828310, train-acc: 0.89357143, val-acc: 0.88500000 val_loss: 0.32031149, dom-acc: 0.69794643
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 108.02400744, sen-loss: 30.63200185, dom-loss: 77.39200592, train-acc: 0.89785714, val-acc: 0.89250000 val_loss: 0.31112608, dom-acc: 0.67410714
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 107.86677599, sen-loss: 30.19785148, dom-loss: 77.66892433, train-acc: 0.90000000, val-acc: 0.88750000 val_loss: 0.30795109, dom-acc: 0.67392857
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 107.41880018, sen-loss: 29.77870159, dom-loss: 77.64009839, train-acc: 0.90178571, val-acc: 0.89000000 val_loss: 0.30726644, dom-acc: 0.66848214
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 107.42995447, sen-loss: 29.41289708, dom-loss: 78.01705694, train-acc: 0.90125000, val-acc: 0.88750000 val_loss: 0.30973187, dom-acc: 0.65848214
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.28636503, sen-loss: 29.22850247, dom-loss: 78.05786246, train-acc: 0.90482143, val-acc: 0.89250000 val_loss: 0.30463761, dom-acc: 0.65678571
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 107.05966043, sen-loss: 28.73176780, dom-loss: 78.32789260, train-acc: 0.90589286, val-acc: 0.89000000 val_loss: 0.30440369, dom-acc: 0.64267857
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 106.78200942, sen-loss: 28.34239136, dom-loss: 78.43961740, train-acc: 0.90803571, val-acc: 0.88750000 val_loss: 0.30442324, dom-acc: 0.64187500
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 106.63933802, sen-loss: 28.15809716, dom-loss: 78.48124045, train-acc: 0.90803571, val-acc: 0.89000000 val_loss: 0.30149513, dom-acc: 0.63294643
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 106.47662354, sen-loss: 27.89786002, dom-loss: 78.57876360, train-acc: 0.90964286, val-acc: 0.89250000 val_loss: 0.30080935, dom-acc: 0.64151786
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 106.20153600, sen-loss: 27.51497288, dom-loss: 78.68656290, train-acc: 0.91089286, val-acc: 0.89000000 val_loss: 0.30086476, dom-acc: 0.63419643
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 106.08668977, sen-loss: 27.46264993, dom-loss: 78.62403977, train-acc: 0.91214286, val-acc: 0.89000000 val_loss: 0.29802623, dom-acc: 0.62857143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 105.56030518, sen-loss: 26.89766109, dom-loss: 78.66264379, train-acc: 0.91250000, val-acc: 0.89000000 val_loss: 0.29726815, dom-acc: 0.62330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 105.27049977, sen-loss: 26.72752924, dom-loss: 78.54297042, train-acc: 0.91285714, val-acc: 0.89250000 val_loss: 0.30313000, dom-acc: 0.62750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 105.11293375, sen-loss: 26.49859727, dom-loss: 78.61433667, train-acc: 0.91339286, val-acc: 0.88500000 val_loss: 0.29524276, dom-acc: 0.63482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 104.80359727, sen-loss: 26.32927043, dom-loss: 78.47432691, train-acc: 0.91607143, val-acc: 0.89250000 val_loss: 0.29437029, dom-acc: 0.62678571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 104.34834975, sen-loss: 25.96207874, dom-loss: 78.38627118, train-acc: 0.91642857, val-acc: 0.88750000 val_loss: 0.29315436, dom-acc: 0.63821429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 103.93527597, sen-loss: 25.68074057, dom-loss: 78.25453562, train-acc: 0.91607143, val-acc: 0.88750000 val_loss: 0.29236683, dom-acc: 0.63553571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 103.48092574, sen-loss: 25.45889147, dom-loss: 78.02203476, train-acc: 0.91678571, val-acc: 0.89000000 val_loss: 0.30126652, dom-acc: 0.65089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.94511592, sen-loss: 25.05547534, dom-loss: 77.88964033, train-acc: 0.91875000, val-acc: 0.89000000 val_loss: 0.29146609, dom-acc: 0.63553571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.84567100, sen-loss: 24.86780757, dom-loss: 77.97786337, train-acc: 0.92035714, val-acc: 0.89500000 val_loss: 0.29110301, dom-acc: 0.64535714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.47355521, sen-loss: 24.70967356, dom-loss: 77.76388186, train-acc: 0.92053571, val-acc: 0.89750000 val_loss: 0.29042953, dom-acc: 0.65901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 101.85288125, sen-loss: 24.41785184, dom-loss: 77.43502933, train-acc: 0.92160714, val-acc: 0.89750000 val_loss: 0.28808859, dom-acc: 0.65732143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 101.76705712, sen-loss: 24.23785720, dom-loss: 77.52919948, train-acc: 0.92303571, val-acc: 0.89750000 val_loss: 0.29001293, dom-acc: 0.64919643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 101.13388145, sen-loss: 23.90122320, dom-loss: 77.23265803, train-acc: 0.92375000, val-acc: 0.89250000 val_loss: 0.29941303, dom-acc: 0.67160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.67212415, sen-loss: 23.60864083, dom-loss: 77.06348342, train-acc: 0.92250000, val-acc: 0.89000000 val_loss: 0.28810072, dom-acc: 0.65910714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.33248222, sen-loss: 23.27644093, dom-loss: 77.05604136, train-acc: 0.92750000, val-acc: 0.89750000 val_loss: 0.28918779, dom-acc: 0.66678571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.38107276, sen-loss: 23.37454315, dom-loss: 77.00652963, train-acc: 0.92607143, val-acc: 0.90000000 val_loss: 0.28728732, dom-acc: 0.67330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 99.64069712, sen-loss: 22.77707857, dom-loss: 76.86361825, train-acc: 0.92946429, val-acc: 0.89500000 val_loss: 0.28963098, dom-acc: 0.67321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 99.11977798, sen-loss: 22.47670290, dom-loss: 76.64307511, train-acc: 0.92857143, val-acc: 0.90000000 val_loss: 0.28749824, dom-acc: 0.67589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 98.84855586, sen-loss: 22.18659345, dom-loss: 76.66196203, train-acc: 0.93160714, val-acc: 0.89750000 val_loss: 0.28910029, dom-acc: 0.68071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [44 ] loss: 98.59047657, sen-loss: 22.01197232, dom-loss: 76.57850403, train-acc: 0.93125000, val-acc: 0.89250000 val_loss: 0.29332498, dom-acc: 0.68428571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [45 ] loss: 98.40216893, sen-loss: 21.87318528, dom-loss: 76.52898359, train-acc: 0.93214286, val-acc: 0.89000000 val_loss: 0.29477412, dom-acc: 0.68250000
---------------------------------------------------

Successfully load model from save path: ./work/models/books_video_PNet.ckpt
Best Epoch: [ 40] best val accuracy: 0.00000000 best val loss: 0.28728732
Testing accuracy: 0.87283333
./work/attentions/books_video_train.txt
./work/pivots/books_video_pos.txt
./work/pivots/books_video_neg.txt
./work/attentions/books_video_test.txt
loading data...
source domain:  dvd target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 9750
vocab-size:  100530
max  story size: 226
mean story size: 8
max  sentence size: 783
mean sentence size: 19
max memory size: 20
5600 400 6000 17843 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(100531, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.99689209, sen-loss: 77.37509912, dom-loss: 82.62179267, train-acc: 0.69321429, val-acc: 0.70000000 val_loss: 0.66347396, dom-acc: 0.68062500
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 148.61344683, sen-loss: 71.72560787, dom-loss: 76.88783896, train-acc: 0.74589286, val-acc: 0.76000000 val_loss: 0.60386652, dom-acc: 0.75517857
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 139.71016943, sen-loss: 64.02324101, dom-loss: 75.68692881, train-acc: 0.79535714, val-acc: 0.79750000 val_loss: 0.51631141, dom-acc: 0.76276786
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 129.71547246, sen-loss: 54.67635223, dom-loss: 75.03912044, train-acc: 0.83625000, val-acc: 0.84750000 val_loss: 0.42529553, dom-acc: 0.75455357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 121.01265413, sen-loss: 46.06035060, dom-loss: 74.95230383, train-acc: 0.85660714, val-acc: 0.87750000 val_loss: 0.35951945, dom-acc: 0.75205357
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 114.26487941, sen-loss: 40.07118863, dom-loss: 74.19369030, train-acc: 0.86625000, val-acc: 0.89250000 val_loss: 0.32655713, dom-acc: 0.74741071
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 111.80611390, sen-loss: 37.52836190, dom-loss: 74.27775234, train-acc: 0.87392857, val-acc: 0.88750000 val_loss: 0.32088369, dom-acc: 0.75116071
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.22956496, sen-loss: 36.16848645, dom-loss: 74.06107920, train-acc: 0.87571429, val-acc: 0.89750000 val_loss: 0.30996349, dom-acc: 0.74580357
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.53906244, sen-loss: 35.31597677, dom-loss: 74.22308600, train-acc: 0.87696429, val-acc: 0.90000000 val_loss: 0.30557644, dom-acc: 0.74267857
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 109.41899633, sen-loss: 34.90422572, dom-loss: 74.51477033, train-acc: 0.88214286, val-acc: 0.90000000 val_loss: 0.30490980, dom-acc: 0.73651786
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 108.44637418, sen-loss: 34.13596642, dom-loss: 74.31040794, train-acc: 0.88285714, val-acc: 0.90250000 val_loss: 0.30055234, dom-acc: 0.73187500
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.65562093, sen-loss: 33.59201007, dom-loss: 75.06361097, train-acc: 0.88482143, val-acc: 0.90250000 val_loss: 0.29999563, dom-acc: 0.72535714
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 108.54458785, sen-loss: 33.30463059, dom-loss: 75.23995727, train-acc: 0.88642857, val-acc: 0.90500000 val_loss: 0.29571953, dom-acc: 0.71964286
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 108.33795464, sen-loss: 32.64996567, dom-loss: 75.68798888, train-acc: 0.88589286, val-acc: 0.90250000 val_loss: 0.30060869, dom-acc: 0.70973214
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 108.29104668, sen-loss: 32.36388995, dom-loss: 75.92715675, train-acc: 0.88678571, val-acc: 0.90750000 val_loss: 0.30058134, dom-acc: 0.70250000
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.02902657, sen-loss: 32.14476502, dom-loss: 75.88426095, train-acc: 0.89321429, val-acc: 0.90500000 val_loss: 0.29240960, dom-acc: 0.70098214
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 108.32437742, sen-loss: 31.87141940, dom-loss: 76.45295805, train-acc: 0.88696429, val-acc: 0.90500000 val_loss: 0.30204114, dom-acc: 0.68937500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 108.07615143, sen-loss: 31.26685515, dom-loss: 76.80929595, train-acc: 0.89553571, val-acc: 0.91250000 val_loss: 0.29211131, dom-acc: 0.69035714
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 107.96837085, sen-loss: 31.04592334, dom-loss: 76.92244750, train-acc: 0.89517857, val-acc: 0.91000000 val_loss: 0.29239684, dom-acc: 0.67776786
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 107.87415439, sen-loss: 30.78715287, dom-loss: 77.08700132, train-acc: 0.89642857, val-acc: 0.90000000 val_loss: 0.28840914, dom-acc: 0.67500000
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 107.90189463, sen-loss: 30.49158424, dom-loss: 77.41031051, train-acc: 0.89875000, val-acc: 0.91250000 val_loss: 0.28909472, dom-acc: 0.67080357
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 107.83426970, sen-loss: 30.06169803, dom-loss: 77.77257180, train-acc: 0.89464286, val-acc: 0.91000000 val_loss: 0.29527354, dom-acc: 0.66357143
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 107.55568784, sen-loss: 29.93615933, dom-loss: 77.61952853, train-acc: 0.89928571, val-acc: 0.91500000 val_loss: 0.29041383, dom-acc: 0.66026786
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 107.72774512, sen-loss: 29.57875714, dom-loss: 78.14898837, train-acc: 0.90053571, val-acc: 0.91500000 val_loss: 0.29042307, dom-acc: 0.65428571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 107.23734266, sen-loss: 29.45999502, dom-loss: 77.77734715, train-acc: 0.90089286, val-acc: 0.91000000 val_loss: 0.29357547, dom-acc: 0.66357143
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_books_PNet.ckpt
Best Epoch: [ 20] best val accuracy: 0.00000000 best val loss: 0.28840914
Testing accuracy: 0.87833333
./work/attentions/dvd_books_train.txt
./work/pivots/dvd_books_pos.txt
./work/pivots/dvd_books_neg.txt
./work/attentions/dvd_books_test.txt
loading data...
source domain:  dvd target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 17009
vocab-size:  85442
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 18
max memory size: 20
5600 400 6000 17843 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(85443, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 160.32706213, sen-loss: 77.39226466, dom-loss: 82.93479675, train-acc: 0.68285714, val-acc: 0.69250000 val_loss: 0.66499299, dom-acc: 0.77339286
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 147.45266497, sen-loss: 71.90185052, dom-loss: 75.55081457, train-acc: 0.73892857, val-acc: 0.75000000 val_loss: 0.60601962, dom-acc: 0.88553571
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 137.79412353, sen-loss: 64.22345287, dom-loss: 73.57067060, train-acc: 0.79464286, val-acc: 0.79750000 val_loss: 0.51702791, dom-acc: 0.87267857
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 127.70184517, sen-loss: 54.77326387, dom-loss: 72.92858124, train-acc: 0.83857143, val-acc: 0.86000000 val_loss: 0.42333713, dom-acc: 0.83205357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 119.18000877, sen-loss: 46.05015898, dom-loss: 73.12985021, train-acc: 0.85839286, val-acc: 0.88500000 val_loss: 0.35614207, dom-acc: 0.78955357
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 113.55800831, sen-loss: 39.97462673, dom-loss: 73.58338165, train-acc: 0.86553571, val-acc: 0.89000000 val_loss: 0.32446915, dom-acc: 0.78687500
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 111.93028545, sen-loss: 37.46817838, dom-loss: 74.46210700, train-acc: 0.87553571, val-acc: 0.89250000 val_loss: 0.31831306, dom-acc: 0.79526786
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 111.43902075, sen-loss: 36.10762534, dom-loss: 75.33139521, train-acc: 0.87839286, val-acc: 0.89750000 val_loss: 0.30839106, dom-acc: 0.75937500
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 111.56582350, sen-loss: 35.28951560, dom-loss: 76.27630782, train-acc: 0.87750000, val-acc: 0.89750000 val_loss: 0.30375358, dom-acc: 0.69651786
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 112.09687495, sen-loss: 34.89685528, dom-loss: 77.20001954, train-acc: 0.88232143, val-acc: 0.89750000 val_loss: 0.30362654, dom-acc: 0.63267857
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 112.15991396, sen-loss: 34.12366846, dom-loss: 78.03624564, train-acc: 0.88267857, val-acc: 0.89750000 val_loss: 0.29868624, dom-acc: 0.59169643
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 112.49285036, sen-loss: 33.58209384, dom-loss: 78.91075706, train-acc: 0.88482143, val-acc: 0.90000000 val_loss: 0.29849789, dom-acc: 0.54017857
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 112.82296246, sen-loss: 33.30069706, dom-loss: 79.52226597, train-acc: 0.88767857, val-acc: 0.90250000 val_loss: 0.29393557, dom-acc: 0.51258929
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 112.49031430, sen-loss: 32.63585015, dom-loss: 79.85446352, train-acc: 0.88446429, val-acc: 0.90750000 val_loss: 0.29910696, dom-acc: 0.49973214
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 112.34169024, sen-loss: 32.36586437, dom-loss: 79.97582597, train-acc: 0.88660714, val-acc: 0.90750000 val_loss: 0.29956841, dom-acc: 0.47223214
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 112.21460700, sen-loss: 32.12289532, dom-loss: 80.09171212, train-acc: 0.89160714, val-acc: 0.90500000 val_loss: 0.29140094, dom-acc: 0.49785714
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 111.87763602, sen-loss: 31.86023043, dom-loss: 80.01740533, train-acc: 0.88803571, val-acc: 0.90250000 val_loss: 0.30136380, dom-acc: 0.48607143
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 111.14988989, sen-loss: 31.27732043, dom-loss: 79.87256914, train-acc: 0.89482143, val-acc: 0.90750000 val_loss: 0.29103944, dom-acc: 0.47473214
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 110.60798603, sen-loss: 31.04226537, dom-loss: 79.56572098, train-acc: 0.89482143, val-acc: 0.91000000 val_loss: 0.29177520, dom-acc: 0.43750000
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 110.12930244, sen-loss: 30.78193161, dom-loss: 79.34737116, train-acc: 0.89642857, val-acc: 0.90250000 val_loss: 0.28745684, dom-acc: 0.50741071
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 109.58707851, sen-loss: 30.50376265, dom-loss: 79.08331621, train-acc: 0.89892857, val-acc: 0.91250000 val_loss: 0.28885576, dom-acc: 0.51348214
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 108.96559620, sen-loss: 30.06088756, dom-loss: 78.90470880, train-acc: 0.89678571, val-acc: 0.91000000 val_loss: 0.29426518, dom-acc: 0.51187500
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 108.45541584, sen-loss: 29.92418176, dom-loss: 78.53123355, train-acc: 0.89964286, val-acc: 0.91250000 val_loss: 0.29053947, dom-acc: 0.52446429
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 107.92479980, sen-loss: 29.56970212, dom-loss: 78.35509831, train-acc: 0.90035714, val-acc: 0.91250000 val_loss: 0.29057953, dom-acc: 0.49589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 107.66708124, sen-loss: 29.46128750, dom-loss: 78.20579368, train-acc: 0.90071429, val-acc: 0.90750000 val_loss: 0.29346636, dom-acc: 0.57750000
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_electronics_PNet.ckpt
Best Epoch: [ 20] best val accuracy: 0.00000000 best val loss: 0.28745684
Testing accuracy: 0.83933333
./work/attentions/dvd_electronics_train.txt
./work/pivots/dvd_electronics_pos.txt
./work/pivots/dvd_electronics_neg.txt
./work/attentions/dvd_electronics_test.txt
loading data...
source domain:  dvd target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 13856
vocab-size:  80685
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 17
max memory size: 20
5600 400 6000 17843 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(80686, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.86606407, sen-loss: 77.32742560, dom-loss: 82.53863823, train-acc: 0.69178571, val-acc: 0.70000000 val_loss: 0.66315663, dom-acc: 0.76241071
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 147.28258002, sen-loss: 71.76410180, dom-loss: 75.51847792, train-acc: 0.73785714, val-acc: 0.75250000 val_loss: 0.60349172, dom-acc: 0.85937500
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 137.94242382, sen-loss: 64.03160164, dom-loss: 73.91082269, train-acc: 0.79750000, val-acc: 0.80750000 val_loss: 0.51389879, dom-acc: 0.84357143
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 127.90863919, sen-loss: 54.52076870, dom-loss: 73.38787019, train-acc: 0.83892857, val-acc: 0.86000000 val_loss: 0.42026654, dom-acc: 0.80044643
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 119.43185782, sen-loss: 45.80328968, dom-loss: 73.62856793, train-acc: 0.85964286, val-acc: 0.88500000 val_loss: 0.35424486, dom-acc: 0.76750000
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 114.06205076, sen-loss: 39.83128171, dom-loss: 74.23076928, train-acc: 0.86589286, val-acc: 0.89250000 val_loss: 0.32248530, dom-acc: 0.73875000
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 112.32060468, sen-loss: 37.31687099, dom-loss: 75.00373346, train-acc: 0.87553571, val-acc: 0.89500000 val_loss: 0.31703833, dom-acc: 0.73062500
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 111.47777134, sen-loss: 35.99350828, dom-loss: 75.48426318, train-acc: 0.87714286, val-acc: 0.90250000 val_loss: 0.30610752, dom-acc: 0.70107143
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 111.71675813, sen-loss: 35.17372847, dom-loss: 76.54302913, train-acc: 0.87625000, val-acc: 0.90000000 val_loss: 0.30168194, dom-acc: 0.67875000
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 112.19131351, sen-loss: 34.77272816, dom-loss: 77.41858536, train-acc: 0.88232143, val-acc: 0.90250000 val_loss: 0.30085984, dom-acc: 0.66437500
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.84534729, sen-loss: 34.02079420, dom-loss: 77.82455266, train-acc: 0.88321429, val-acc: 0.90250000 val_loss: 0.29648736, dom-acc: 0.63294643
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 112.35380071, sen-loss: 33.48877594, dom-loss: 78.86502510, train-acc: 0.88446429, val-acc: 0.90250000 val_loss: 0.29576758, dom-acc: 0.60625000
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 112.70154637, sen-loss: 33.21191986, dom-loss: 79.48962617, train-acc: 0.88517857, val-acc: 0.90250000 val_loss: 0.29137373, dom-acc: 0.57116071
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 112.20200157, sen-loss: 32.56909190, dom-loss: 79.63290972, train-acc: 0.88535714, val-acc: 0.91250000 val_loss: 0.29586297, dom-acc: 0.58276786
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 111.98211694, sen-loss: 32.29965721, dom-loss: 79.68245959, train-acc: 0.88750000, val-acc: 0.91000000 val_loss: 0.29728201, dom-acc: 0.57883929
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 111.59974575, sen-loss: 32.09164420, dom-loss: 79.50810194, train-acc: 0.89142857, val-acc: 0.90500000 val_loss: 0.28803325, dom-acc: 0.57044643
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 111.41992819, sen-loss: 31.82477881, dom-loss: 79.59514934, train-acc: 0.88767857, val-acc: 0.90250000 val_loss: 0.29758874, dom-acc: 0.58116071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 110.47504848, sen-loss: 31.23594905, dom-loss: 79.23909926, train-acc: 0.89464286, val-acc: 0.91000000 val_loss: 0.28734946, dom-acc: 0.59714286
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 109.72838587, sen-loss: 31.01046532, dom-loss: 78.71792018, train-acc: 0.89446429, val-acc: 0.90500000 val_loss: 0.28763899, dom-acc: 0.59366071
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 109.14863503, sen-loss: 30.75420080, dom-loss: 78.39443386, train-acc: 0.89625000, val-acc: 0.90250000 val_loss: 0.28400186, dom-acc: 0.60973214
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 108.44942367, sen-loss: 30.47707964, dom-loss: 77.97234404, train-acc: 0.89875000, val-acc: 0.90750000 val_loss: 0.28475934, dom-acc: 0.63696429
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 107.86082548, sen-loss: 30.05382019, dom-loss: 77.80700499, train-acc: 0.89535714, val-acc: 0.91000000 val_loss: 0.29038644, dom-acc: 0.66321429
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 107.37544405, sen-loss: 29.91250736, dom-loss: 77.46293706, train-acc: 0.90053571, val-acc: 0.91000000 val_loss: 0.28588212, dom-acc: 0.67178571
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 106.80234343, sen-loss: 29.57746129, dom-loss: 77.22488201, train-acc: 0.90107143, val-acc: 0.91000000 val_loss: 0.28608489, dom-acc: 0.68741071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 106.41045284, sen-loss: 29.45762661, dom-loss: 76.95282644, train-acc: 0.90089286, val-acc: 0.91000000 val_loss: 0.28845307, dom-acc: 0.69089286
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_kitchen_PNet.ckpt
Best Epoch: [ 20] best val accuracy: 0.00000000 best val loss: 0.28400186
Testing accuracy: 0.84666667
./work/attentions/dvd_kitchen_train.txt
./work/pivots/dvd_kitchen_pos.txt
./work/pivots/dvd_kitchen_neg.txt
./work/attentions/dvd_kitchen_test.txt
loading data...
source domain:  dvd target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 30180
vocab-size:  91852
max  story size: 226
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
5600 400 6000 17843 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(91853, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 160.13918304, sen-loss: 77.42947477, dom-loss: 82.70970815, train-acc: 0.68714286, val-acc: 0.68750000 val_loss: 0.66539770, dom-acc: 0.57848214
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 150.61024940, sen-loss: 71.93259305, dom-loss: 78.67765617, train-acc: 0.73821429, val-acc: 0.74750000 val_loss: 0.60662061, dom-acc: 0.59633929
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 142.76203656, sen-loss: 64.29842839, dom-loss: 78.46360826, train-acc: 0.79357143, val-acc: 0.80750000 val_loss: 0.51807821, dom-acc: 0.62089286
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 133.03457463, sen-loss: 54.91803637, dom-loss: 78.11653811, train-acc: 0.83428571, val-acc: 0.86000000 val_loss: 0.42581737, dom-acc: 0.63964286
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 124.42673349, sen-loss: 46.45633525, dom-loss: 77.97039741, train-acc: 0.85250000, val-acc: 0.87750000 val_loss: 0.36216861, dom-acc: 0.63928571
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 118.29116368, sen-loss: 40.39803363, dom-loss: 77.89312953, train-acc: 0.86375000, val-acc: 0.89500000 val_loss: 0.32829508, dom-acc: 0.63937500
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 115.06784809, sen-loss: 37.64765909, dom-loss: 77.42018861, train-acc: 0.87553571, val-acc: 0.89000000 val_loss: 0.32258353, dom-acc: 0.66410714
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 113.53068691, sen-loss: 36.27028717, dom-loss: 77.26039922, train-acc: 0.87446429, val-acc: 0.89250000 val_loss: 0.31092572, dom-acc: 0.65473214
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 112.69736397, sen-loss: 35.42192328, dom-loss: 77.27544135, train-acc: 0.87607143, val-acc: 0.89500000 val_loss: 0.30573502, dom-acc: 0.65062500
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 112.34320772, sen-loss: 35.00487636, dom-loss: 77.33833134, train-acc: 0.88089286, val-acc: 0.90000000 val_loss: 0.30593121, dom-acc: 0.66651786
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.00205725, sen-loss: 34.25832792, dom-loss: 76.74372905, train-acc: 0.88267857, val-acc: 0.90000000 val_loss: 0.30056998, dom-acc: 0.66116071
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.98106354, sen-loss: 33.69534870, dom-loss: 77.28571469, train-acc: 0.88517857, val-acc: 0.90000000 val_loss: 0.30022228, dom-acc: 0.65973214
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.51820177, sen-loss: 33.40878262, dom-loss: 77.10941911, train-acc: 0.88589286, val-acc: 0.90000000 val_loss: 0.29556441, dom-acc: 0.65642857
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 109.92698884, sen-loss: 32.74847388, dom-loss: 77.17851454, train-acc: 0.88642857, val-acc: 0.90500000 val_loss: 0.30027500, dom-acc: 0.67285714
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.57161850, sen-loss: 32.48167235, dom-loss: 77.08994567, train-acc: 0.88696429, val-acc: 0.90500000 val_loss: 0.30140901, dom-acc: 0.67339286
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.67242712, sen-loss: 32.25022484, dom-loss: 76.42220289, train-acc: 0.88946429, val-acc: 0.90250000 val_loss: 0.29234356, dom-acc: 0.66732143
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 109.11967826, sen-loss: 31.97710250, dom-loss: 77.14257568, train-acc: 0.88696429, val-acc: 0.89750000 val_loss: 0.30234498, dom-acc: 0.67642857
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 108.17715549, sen-loss: 31.40010867, dom-loss: 76.77704638, train-acc: 0.89464286, val-acc: 0.91250000 val_loss: 0.29179239, dom-acc: 0.67276786
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 107.97644192, sen-loss: 31.16738106, dom-loss: 76.80906129, train-acc: 0.89410714, val-acc: 0.91000000 val_loss: 0.29143047, dom-acc: 0.66758929
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 107.55223840, sen-loss: 30.91523977, dom-loss: 76.63699871, train-acc: 0.89517857, val-acc: 0.89750000 val_loss: 0.28778878, dom-acc: 0.66446429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 107.20507216, sen-loss: 30.62519488, dom-loss: 76.57987732, train-acc: 0.89714286, val-acc: 0.91250000 val_loss: 0.28873092, dom-acc: 0.67080357
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 107.32948411, sen-loss: 30.19960967, dom-loss: 77.12987393, train-acc: 0.89535714, val-acc: 0.90500000 val_loss: 0.29395613, dom-acc: 0.67241071
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 106.73609322, sen-loss: 30.06363274, dom-loss: 76.67246109, train-acc: 0.89964286, val-acc: 0.91250000 val_loss: 0.28923625, dom-acc: 0.67223214
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 106.48955482, sen-loss: 29.71742076, dom-loss: 76.77213389, train-acc: 0.90125000, val-acc: 0.91250000 val_loss: 0.28939843, dom-acc: 0.67008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 106.21703637, sen-loss: 29.60408280, dom-loss: 76.61295378, train-acc: 0.89910714, val-acc: 0.91000000 val_loss: 0.29254940, dom-acc: 0.67767857
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_video_PNet.ckpt
Best Epoch: [ 20] best val accuracy: 0.00000000 best val loss: 0.28778878
Testing accuracy: 0.88216667
./work/attentions/dvd_video_train.txt
./work/pivots/dvd_video_pos.txt
./work/pivots/dvd_video_neg.txt
./work/attentions/dvd_video_test.txt
loading data...
source domain:  electronics target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 9750
vocab-size:  83050
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 18
max memory size: 20
5600 400 6000 23009 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83051, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.18004596, sen-loss: 75.79676020, dom-loss: 79.38328511, train-acc: 0.77535714, val-acc: 0.79750000 val_loss: 0.63261575, dom-acc: 0.88955357
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 137.97321522, sen-loss: 65.65786821, dom-loss: 72.31534708, train-acc: 0.78821429, val-acc: 0.82750000 val_loss: 0.50984728, dom-acc: 0.83696429
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 123.05978668, sen-loss: 52.45669070, dom-loss: 70.60309613, train-acc: 0.79464286, val-acc: 0.81500000 val_loss: 0.41831124, dom-acc: 0.63544643
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 117.72616684, sen-loss: 46.91938126, dom-loss: 70.80678463, train-acc: 0.83357143, val-acc: 0.86000000 val_loss: 0.36781517, dom-acc: 0.60410714
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 114.31931466, sen-loss: 42.47365110, dom-loss: 71.84566355, train-acc: 0.85767857, val-acc: 0.88250000 val_loss: 0.32859981, dom-acc: 0.58223214
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 112.19323856, sen-loss: 38.90623017, dom-loss: 73.28700882, train-acc: 0.86053571, val-acc: 0.88750000 val_loss: 0.30872324, dom-acc: 0.57035714
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.95840991, sen-loss: 36.41521908, dom-loss: 74.54319018, train-acc: 0.87678571, val-acc: 0.89500000 val_loss: 0.27815518, dom-acc: 0.54598214
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.65136558, sen-loss: 34.76505512, dom-loss: 75.88631004, train-acc: 0.88392857, val-acc: 0.90500000 val_loss: 0.26421443, dom-acc: 0.52678571
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.79007107, sen-loss: 33.57912862, dom-loss: 77.21094233, train-acc: 0.88803571, val-acc: 0.90500000 val_loss: 0.25780931, dom-acc: 0.50151786
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.91346246, sen-loss: 32.57175234, dom-loss: 78.34171051, train-acc: 0.89053571, val-acc: 0.91000000 val_loss: 0.25502169, dom-acc: 0.47178571
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.21824086, sen-loss: 32.08964963, dom-loss: 79.12859100, train-acc: 0.89410714, val-acc: 0.91000000 val_loss: 0.24645784, dom-acc: 0.44044643
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 111.02530885, sen-loss: 31.24034896, dom-loss: 79.78496027, train-acc: 0.89660714, val-acc: 0.90500000 val_loss: 0.23940079, dom-acc: 0.43205357
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.53752649, sen-loss: 30.40859752, dom-loss: 80.12892860, train-acc: 0.90107143, val-acc: 0.91000000 val_loss: 0.23808593, dom-acc: 0.40803571
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 110.36316389, sen-loss: 29.84096582, dom-loss: 80.52219844, train-acc: 0.90125000, val-acc: 0.91500000 val_loss: 0.23343979, dom-acc: 0.40232143
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.74378365, sen-loss: 29.32138978, dom-loss: 80.42239439, train-acc: 0.90375000, val-acc: 0.92250000 val_loss: 0.23152228, dom-acc: 0.40339286
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 109.08016360, sen-loss: 28.82800381, dom-loss: 80.25216001, train-acc: 0.90482143, val-acc: 0.92250000 val_loss: 0.22985190, dom-acc: 0.40553571
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 108.10192591, sen-loss: 28.35361578, dom-loss: 79.74830997, train-acc: 0.90678571, val-acc: 0.92000000 val_loss: 0.22883649, dom-acc: 0.41580357
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.47801560, sen-loss: 28.03542131, dom-loss: 79.44259411, train-acc: 0.90857143, val-acc: 0.92250000 val_loss: 0.22895345, dom-acc: 0.43241071
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.46331114, sen-loss: 27.65509884, dom-loss: 78.80821228, train-acc: 0.91000000, val-acc: 0.92250000 val_loss: 0.22521958, dom-acc: 0.45642857
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 105.45996124, sen-loss: 27.25829239, dom-loss: 78.20166880, train-acc: 0.91196429, val-acc: 0.92000000 val_loss: 0.22475192, dom-acc: 0.46821429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 104.85455054, sen-loss: 26.96362188, dom-loss: 77.89092851, train-acc: 0.91500000, val-acc: 0.92250000 val_loss: 0.22329010, dom-acc: 0.48544643
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.83037490, sen-loss: 26.36953295, dom-loss: 77.46084183, train-acc: 0.91250000, val-acc: 0.92750000 val_loss: 0.22507659, dom-acc: 0.50803571
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 103.06314170, sen-loss: 26.14822443, dom-loss: 76.91491729, train-acc: 0.91607143, val-acc: 0.92500000 val_loss: 0.22279513, dom-acc: 0.51660714
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.57370722, sen-loss: 25.82372753, dom-loss: 76.74997991, train-acc: 0.91982143, val-acc: 0.92250000 val_loss: 0.22161987, dom-acc: 0.52776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.16967565, sen-loss: 25.51309384, dom-loss: 76.65658140, train-acc: 0.91785714, val-acc: 0.91750000 val_loss: 0.22205757, dom-acc: 0.53473214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.59194094, sen-loss: 25.13893439, dom-loss: 76.45300710, train-acc: 0.92107143, val-acc: 0.92000000 val_loss: 0.22058308, dom-acc: 0.52937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.34468430, sen-loss: 24.86716235, dom-loss: 76.47752184, train-acc: 0.92142857, val-acc: 0.92250000 val_loss: 0.22102973, dom-acc: 0.52607143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.08143467, sen-loss: 24.57937486, dom-loss: 76.50205952, train-acc: 0.92250000, val-acc: 0.92500000 val_loss: 0.21974729, dom-acc: 0.51000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.10590744, sen-loss: 24.23967055, dom-loss: 76.86623681, train-acc: 0.92357143, val-acc: 0.92500000 val_loss: 0.22085968, dom-acc: 0.54330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.71968389, sen-loss: 24.01741611, dom-loss: 76.70226753, train-acc: 0.92517857, val-acc: 0.92000000 val_loss: 0.21885303, dom-acc: 0.50598214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.91393656, sen-loss: 23.82823453, dom-loss: 77.08570206, train-acc: 0.92553571, val-acc: 0.92500000 val_loss: 0.21870708, dom-acc: 0.50857143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.62685251, sen-loss: 23.48781280, dom-loss: 77.13903981, train-acc: 0.92642857, val-acc: 0.92250000 val_loss: 0.22004347, dom-acc: 0.48767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.87173998, sen-loss: 23.21166283, dom-loss: 77.66007757, train-acc: 0.92642857, val-acc: 0.92500000 val_loss: 0.21981247, dom-acc: 0.48437500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.78832352, sen-loss: 22.99481611, dom-loss: 77.79350770, train-acc: 0.92910714, val-acc: 0.92000000 val_loss: 0.21786730, dom-acc: 0.47035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.92921036, sen-loss: 22.72690079, dom-loss: 78.20230949, train-acc: 0.93107143, val-acc: 0.92250000 val_loss: 0.21786411, dom-acc: 0.47187500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.64810872, sen-loss: 22.31063171, dom-loss: 78.33747715, train-acc: 0.93107143, val-acc: 0.92250000 val_loss: 0.21710181, dom-acc: 0.46205357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.63969350, sen-loss: 22.12321567, dom-loss: 78.51647824, train-acc: 0.92892857, val-acc: 0.91750000 val_loss: 0.22193101, dom-acc: 0.43383929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.60406893, sen-loss: 21.94770481, dom-loss: 78.65636408, train-acc: 0.93285714, val-acc: 0.92250000 val_loss: 0.21694003, dom-acc: 0.44258929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.48304915, sen-loss: 21.70517769, dom-loss: 78.77787185, train-acc: 0.93142857, val-acc: 0.92250000 val_loss: 0.22053778, dom-acc: 0.41071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.32365561, sen-loss: 21.43019133, dom-loss: 78.89346421, train-acc: 0.93517857, val-acc: 0.92750000 val_loss: 0.21830738, dom-acc: 0.42589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 99.91080266, sen-loss: 21.17342466, dom-loss: 78.73737770, train-acc: 0.93625000, val-acc: 0.92750000 val_loss: 0.22018412, dom-acc: 0.40714286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 99.43093711, sen-loss: 20.80768849, dom-loss: 78.62324864, train-acc: 0.93696429, val-acc: 0.92500000 val_loss: 0.22026919, dom-acc: 0.39982143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 99.27638179, sen-loss: 20.65295602, dom-loss: 78.62342578, train-acc: 0.93982143, val-acc: 0.92500000 val_loss: 0.21951121, dom-acc: 0.42776786
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_books_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.21694003
Testing accuracy: 0.83283333
./work/attentions/electronics_books_train.txt
./work/pivots/electronics_books_pos.txt
./work/pivots/electronics_books_neg.txt
./work/attentions/electronics_books_test.txt
loading data...
source domain:  electronics target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 11843
vocab-size:  85442
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 18
max memory size: 20
5600 400 6000 23009 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(85443, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.71901965, sen-loss: 75.76668227, dom-loss: 78.95233780, train-acc: 0.77535714, val-acc: 0.79500000 val_loss: 0.63180882, dom-acc: 0.89473214
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 137.27644420, sen-loss: 65.43115905, dom-loss: 71.84528577, train-acc: 0.78785714, val-acc: 0.82000000 val_loss: 0.50755686, dom-acc: 0.82928571
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 122.42378765, sen-loss: 52.23720074, dom-loss: 70.18658698, train-acc: 0.79428571, val-acc: 0.81750000 val_loss: 0.41699407, dom-acc: 0.63544643
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 117.08852875, sen-loss: 46.80890587, dom-loss: 70.27962309, train-acc: 0.83250000, val-acc: 0.86250000 val_loss: 0.36699218, dom-acc: 0.61946429
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 113.52685034, sen-loss: 42.38050148, dom-loss: 71.14634907, train-acc: 0.85785714, val-acc: 0.88250000 val_loss: 0.32811290, dom-acc: 0.60187500
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 110.95939088, sen-loss: 38.78222108, dom-loss: 72.17717004, train-acc: 0.86017857, val-acc: 0.89000000 val_loss: 0.30749199, dom-acc: 0.58491071
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.08368987, sen-loss: 36.28541024, dom-loss: 73.79828000, train-acc: 0.87875000, val-acc: 0.89000000 val_loss: 0.27693596, dom-acc: 0.57098214
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 109.59302104, sen-loss: 34.63227922, dom-loss: 74.96074224, train-acc: 0.88357143, val-acc: 0.89500000 val_loss: 0.26261058, dom-acc: 0.55026786
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.64746737, sen-loss: 33.45386711, dom-loss: 76.19360030, train-acc: 0.89035714, val-acc: 0.90250000 val_loss: 0.25724497, dom-acc: 0.52285714
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 109.88900369, sen-loss: 32.44999737, dom-loss: 77.43900639, train-acc: 0.89285714, val-acc: 0.91750000 val_loss: 0.25432703, dom-acc: 0.49116071
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 110.33816886, sen-loss: 31.99372019, dom-loss: 78.34444880, train-acc: 0.89678571, val-acc: 0.91000000 val_loss: 0.24501573, dom-acc: 0.46901786
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.12271816, sen-loss: 31.15546368, dom-loss: 78.96725440, train-acc: 0.89875000, val-acc: 0.90750000 val_loss: 0.23708250, dom-acc: 0.45866071
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.05886137, sen-loss: 30.30479486, dom-loss: 79.75406599, train-acc: 0.90339286, val-acc: 0.90750000 val_loss: 0.23614669, dom-acc: 0.44169643
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 110.08391958, sen-loss: 29.75811186, dom-loss: 80.32580811, train-acc: 0.90464286, val-acc: 0.91250000 val_loss: 0.23119895, dom-acc: 0.42883929
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.45111442, sen-loss: 29.26741928, dom-loss: 80.18369520, train-acc: 0.90589286, val-acc: 0.91500000 val_loss: 0.22911786, dom-acc: 0.42303571
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.97663802, sen-loss: 28.77540129, dom-loss: 80.20123732, train-acc: 0.90678571, val-acc: 0.91000000 val_loss: 0.22699255, dom-acc: 0.42526786
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 108.12008464, sen-loss: 28.32259013, dom-loss: 79.79749465, train-acc: 0.90821429, val-acc: 0.92000000 val_loss: 0.22599006, dom-acc: 0.43312500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.46187234, sen-loss: 28.00461904, dom-loss: 79.45725310, train-acc: 0.91035714, val-acc: 0.92250000 val_loss: 0.22626929, dom-acc: 0.43794643
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.57513428, sen-loss: 27.65559101, dom-loss: 78.91954350, train-acc: 0.91089286, val-acc: 0.91750000 val_loss: 0.22164476, dom-acc: 0.46357143
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 105.58925837, sen-loss: 27.24110808, dom-loss: 78.34815031, train-acc: 0.91321429, val-acc: 0.91000000 val_loss: 0.22036736, dom-acc: 0.48678571
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 104.80899113, sen-loss: 26.99155623, dom-loss: 77.81743431, train-acc: 0.91500000, val-acc: 0.91750000 val_loss: 0.21880664, dom-acc: 0.49500000
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.77718520, sen-loss: 26.36371057, dom-loss: 77.41347456, train-acc: 0.91428571, val-acc: 0.92250000 val_loss: 0.22035165, dom-acc: 0.50321429
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 103.09926844, sen-loss: 26.14243343, dom-loss: 76.95683539, train-acc: 0.91642857, val-acc: 0.92500000 val_loss: 0.21741012, dom-acc: 0.51866071
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.33200967, sen-loss: 25.82035835, dom-loss: 76.51165146, train-acc: 0.91964286, val-acc: 0.92250000 val_loss: 0.21592326, dom-acc: 0.51794643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 101.99505216, sen-loss: 25.48379985, dom-loss: 76.51125246, train-acc: 0.91785714, val-acc: 0.90750000 val_loss: 0.21602295, dom-acc: 0.53651786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.37245047, sen-loss: 25.11359648, dom-loss: 76.25885415, train-acc: 0.92035714, val-acc: 0.92000000 val_loss: 0.21413708, dom-acc: 0.53348214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.05544609, sen-loss: 24.87460039, dom-loss: 76.18084562, train-acc: 0.92125000, val-acc: 0.92500000 val_loss: 0.21450031, dom-acc: 0.53178571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 100.92833066, sen-loss: 24.56693143, dom-loss: 76.36139941, train-acc: 0.92357143, val-acc: 0.92500000 val_loss: 0.21257994, dom-acc: 0.52633929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.76716566, sen-loss: 24.23429245, dom-loss: 76.53287321, train-acc: 0.92214286, val-acc: 0.92250000 val_loss: 0.21329585, dom-acc: 0.53089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.40175003, sen-loss: 24.00000027, dom-loss: 76.40174949, train-acc: 0.92607143, val-acc: 0.91750000 val_loss: 0.21107221, dom-acc: 0.51607143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.67595291, sen-loss: 23.83312458, dom-loss: 76.84282857, train-acc: 0.92678571, val-acc: 0.92750000 val_loss: 0.21028034, dom-acc: 0.51205357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.50908649, sen-loss: 23.47752102, dom-loss: 77.03156531, train-acc: 0.92500000, val-acc: 0.92000000 val_loss: 0.21187405, dom-acc: 0.50178571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.60415095, sen-loss: 23.22125218, dom-loss: 77.38289887, train-acc: 0.92660714, val-acc: 0.92250000 val_loss: 0.21084975, dom-acc: 0.49562500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.61388266, sen-loss: 23.00827159, dom-loss: 77.60561126, train-acc: 0.93053571, val-acc: 0.92250000 val_loss: 0.20885220, dom-acc: 0.49035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.71903473, sen-loss: 22.72926118, dom-loss: 77.98977357, train-acc: 0.92910714, val-acc: 0.92000000 val_loss: 0.20807500, dom-acc: 0.47607143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.49755043, sen-loss: 22.34022521, dom-loss: 78.15732515, train-acc: 0.93178571, val-acc: 0.92500000 val_loss: 0.20718314, dom-acc: 0.46821429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.52898461, sen-loss: 22.15145800, dom-loss: 78.37752664, train-acc: 0.92946429, val-acc: 0.92250000 val_loss: 0.21213196, dom-acc: 0.44741071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.50273919, sen-loss: 21.96352613, dom-loss: 78.53921354, train-acc: 0.93357143, val-acc: 0.92000000 val_loss: 0.20643812, dom-acc: 0.44321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.21502674, sen-loss: 21.73656078, dom-loss: 78.47846597, train-acc: 0.93339286, val-acc: 0.92000000 val_loss: 0.21008158, dom-acc: 0.42776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.28135043, sen-loss: 21.46411874, dom-loss: 78.81723166, train-acc: 0.93678571, val-acc: 0.92500000 val_loss: 0.20696709, dom-acc: 0.44008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 99.80554307, sen-loss: 21.22650626, dom-loss: 78.57903677, train-acc: 0.93767857, val-acc: 0.92750000 val_loss: 0.20836233, dom-acc: 0.43089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 99.27762181, sen-loss: 20.84250595, dom-loss: 78.43511599, train-acc: 0.93821429, val-acc: 0.92250000 val_loss: 0.20865805, dom-acc: 0.43276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 99.16735262, sen-loss: 20.71443725, dom-loss: 78.45291489, train-acc: 0.93946429, val-acc: 0.92000000 val_loss: 0.20676561, dom-acc: 0.44491071
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_dvd_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.20643812
Testing accuracy: 0.83400000
./work/attentions/electronics_dvd_train.txt
./work/pivots/electronics_dvd_pos.txt
./work/pivots/electronics_dvd_neg.txt
./work/attentions/electronics_dvd_test.txt
loading data...
source domain:  electronics target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 13856
vocab-size:  49470
max  story size: 129
mean story size: 6
max  sentence size: 440
mean sentence size: 15
max memory size: 20
5600 400 6000 23009 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(49471, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 156.98690164, sen-loss: 75.83608735, dom-loss: 81.15081435, train-acc: 0.77750000, val-acc: 0.78250000 val_loss: 0.63289028, dom-acc: 0.76464286
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 141.45005941, sen-loss: 65.60731730, dom-loss: 75.84274238, train-acc: 0.78625000, val-acc: 0.82000000 val_loss: 0.50878656, dom-acc: 0.78562500
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 127.53224170, sen-loss: 52.48996592, dom-loss: 75.04227626, train-acc: 0.79392857, val-acc: 0.82000000 val_loss: 0.41851306, dom-acc: 0.73125000
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 122.09240907, sen-loss: 47.22098419, dom-loss: 74.87142426, train-acc: 0.83017857, val-acc: 0.85000000 val_loss: 0.37024814, dom-acc: 0.75437500
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 117.74811852, sen-loss: 42.96372406, dom-loss: 74.78439522, train-acc: 0.85535714, val-acc: 0.88500000 val_loss: 0.33157519, dom-acc: 0.74803571
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 114.25887114, sen-loss: 39.36100368, dom-loss: 74.89786804, train-acc: 0.85750000, val-acc: 0.88750000 val_loss: 0.31003499, dom-acc: 0.74107143
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 111.70999503, sen-loss: 36.80153316, dom-loss: 74.90846217, train-acc: 0.87732143, val-acc: 0.89000000 val_loss: 0.27792618, dom-acc: 0.74026786
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.04677010, sen-loss: 35.05691729, dom-loss: 74.98985255, train-acc: 0.88303571, val-acc: 0.89750000 val_loss: 0.26242399, dom-acc: 0.73151786
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 109.17639977, sen-loss: 33.81528735, dom-loss: 75.36111265, train-acc: 0.88964286, val-acc: 0.91250000 val_loss: 0.25564608, dom-acc: 0.73151786
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 108.25924450, sen-loss: 32.78365636, dom-loss: 75.47558767, train-acc: 0.89017857, val-acc: 0.92000000 val_loss: 0.25226980, dom-acc: 0.72767857
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 108.04613954, sen-loss: 32.31960439, dom-loss: 75.72653496, train-acc: 0.89553571, val-acc: 0.91750000 val_loss: 0.24209501, dom-acc: 0.72133929
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 107.30321735, sen-loss: 31.42747021, dom-loss: 75.87574780, train-acc: 0.89964286, val-acc: 0.91250000 val_loss: 0.23357700, dom-acc: 0.71366071
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 106.91315532, sen-loss: 30.60056877, dom-loss: 76.31258625, train-acc: 0.89982143, val-acc: 0.92000000 val_loss: 0.23249803, dom-acc: 0.71285714
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.57635438, sen-loss: 30.04809271, dom-loss: 76.52826178, train-acc: 0.90428571, val-acc: 0.92000000 val_loss: 0.22669947, dom-acc: 0.70910714
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 106.04487628, sen-loss: 29.55033179, dom-loss: 76.49454498, train-acc: 0.90625000, val-acc: 0.92250000 val_loss: 0.22407211, dom-acc: 0.69767857
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 105.82725489, sen-loss: 29.04676809, dom-loss: 76.78048664, train-acc: 0.90767857, val-acc: 0.92500000 val_loss: 0.22181340, dom-acc: 0.69294643
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 105.69451070, sen-loss: 28.60148359, dom-loss: 77.09302682, train-acc: 0.90660714, val-acc: 0.93000000 val_loss: 0.22061582, dom-acc: 0.68178571
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 105.51020944, sen-loss: 28.26974665, dom-loss: 77.24046284, train-acc: 0.90750000, val-acc: 0.92750000 val_loss: 0.22061314, dom-acc: 0.68741071
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 105.19873422, sen-loss: 27.90008616, dom-loss: 77.29864824, train-acc: 0.91142857, val-acc: 0.92500000 val_loss: 0.21547033, dom-acc: 0.67937500
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 105.16818213, sen-loss: 27.49242316, dom-loss: 77.67575926, train-acc: 0.91178571, val-acc: 0.92000000 val_loss: 0.21390450, dom-acc: 0.66446429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 104.86847526, sen-loss: 27.23692381, dom-loss: 77.63155133, train-acc: 0.91482143, val-acc: 0.92750000 val_loss: 0.21219394, dom-acc: 0.66937500
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 104.45655352, sen-loss: 26.59279811, dom-loss: 77.86375523, train-acc: 0.91196429, val-acc: 0.93250000 val_loss: 0.21420610, dom-acc: 0.67598214
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 104.49485278, sen-loss: 26.37137391, dom-loss: 78.12347943, train-acc: 0.91464286, val-acc: 0.93000000 val_loss: 0.21143053, dom-acc: 0.66812500
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 104.10225594, sen-loss: 26.03662769, dom-loss: 78.06562823, train-acc: 0.91892857, val-acc: 0.93000000 val_loss: 0.20895706, dom-acc: 0.66178571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.66185713, sen-loss: 25.67685019, dom-loss: 77.98500675, train-acc: 0.91678571, val-acc: 0.92250000 val_loss: 0.20780937, dom-acc: 0.65276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 103.49271053, sen-loss: 25.31038255, dom-loss: 78.18232805, train-acc: 0.92107143, val-acc: 0.93000000 val_loss: 0.20700245, dom-acc: 0.64321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 103.11496305, sen-loss: 25.04042541, dom-loss: 78.07453793, train-acc: 0.92089286, val-acc: 0.92500000 val_loss: 0.20761935, dom-acc: 0.65633929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.95080590, sen-loss: 24.73920107, dom-loss: 78.21160454, train-acc: 0.92339286, val-acc: 0.93000000 val_loss: 0.20519786, dom-acc: 0.64964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 102.28979832, sen-loss: 24.40136636, dom-loss: 77.88843197, train-acc: 0.92250000, val-acc: 0.92500000 val_loss: 0.20674345, dom-acc: 0.67258929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 102.31843746, sen-loss: 24.14584249, dom-loss: 78.17259455, train-acc: 0.92517857, val-acc: 0.93000000 val_loss: 0.20334601, dom-acc: 0.64732143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 101.96503222, sen-loss: 23.96848965, dom-loss: 77.99654257, train-acc: 0.92589286, val-acc: 0.92750000 val_loss: 0.20243058, dom-acc: 0.66125000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 101.53434741, sen-loss: 23.61055414, dom-loss: 77.92379332, train-acc: 0.92535714, val-acc: 0.92500000 val_loss: 0.20490600, dom-acc: 0.66678571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.28227109, sen-loss: 23.34494817, dom-loss: 77.93732303, train-acc: 0.92696429, val-acc: 0.92500000 val_loss: 0.20367038, dom-acc: 0.66107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 101.11913824, sen-loss: 23.12722056, dom-loss: 77.99191779, train-acc: 0.92892857, val-acc: 0.93000000 val_loss: 0.20002978, dom-acc: 0.65071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.52706403, sen-loss: 22.83902735, dom-loss: 77.68803674, train-acc: 0.93053571, val-acc: 0.92750000 val_loss: 0.20038283, dom-acc: 0.65803571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.98787135, sen-loss: 22.44458527, dom-loss: 77.54328555, train-acc: 0.93107143, val-acc: 0.92750000 val_loss: 0.19892740, dom-acc: 0.66937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.76955843, sen-loss: 22.25380851, dom-loss: 77.51574969, train-acc: 0.93035714, val-acc: 0.92250000 val_loss: 0.20437098, dom-acc: 0.67821429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.41171110, sen-loss: 22.08764463, dom-loss: 77.32406682, train-acc: 0.93392857, val-acc: 0.92750000 val_loss: 0.19721164, dom-acc: 0.67044643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 99.38261247, sen-loss: 21.84868769, dom-loss: 77.53392446, train-acc: 0.93339286, val-acc: 0.92750000 val_loss: 0.20154576, dom-acc: 0.67133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.59173477, sen-loss: 21.56486566, dom-loss: 77.02686870, train-acc: 0.93375000, val-acc: 0.93000000 val_loss: 0.19843800, dom-acc: 0.68321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 98.44038606, sen-loss: 21.32732799, dom-loss: 77.11305797, train-acc: 0.93517857, val-acc: 0.92750000 val_loss: 0.19965234, dom-acc: 0.67910714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 98.07695884, sen-loss: 20.96377207, dom-loss: 77.11318702, train-acc: 0.93732143, val-acc: 0.93000000 val_loss: 0.19954690, dom-acc: 0.67767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 97.51332402, sen-loss: 20.79826088, dom-loss: 76.71506304, train-acc: 0.93857143, val-acc: 0.92750000 val_loss: 0.19764793, dom-acc: 0.67035714
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_kitchen_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.19721164
Testing accuracy: 0.90100000
./work/attentions/electronics_kitchen_train.txt
./work/pivots/electronics_kitchen_pos.txt
./work/pivots/electronics_kitchen_neg.txt
./work/attentions/electronics_kitchen_test.txt
loading data...
source domain:  electronics target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 30180
vocab-size:  83059
max  story size: 129
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
5600 400 6000 23009 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83060, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.78046095, sen-loss: 75.89951086, dom-loss: 78.88095003, train-acc: 0.77035714, val-acc: 0.80500000 val_loss: 0.63320881, dom-acc: 0.90937500
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 137.37747574, sen-loss: 65.74364293, dom-loss: 71.63383317, train-acc: 0.78589286, val-acc: 0.82250000 val_loss: 0.50902647, dom-acc: 0.86580357
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 122.78565890, sen-loss: 52.58729059, dom-loss: 70.19836837, train-acc: 0.79196429, val-acc: 0.80750000 val_loss: 0.41799611, dom-acc: 0.66553571
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 117.21740574, sen-loss: 47.20552823, dom-loss: 70.01187766, train-acc: 0.83089286, val-acc: 0.86000000 val_loss: 0.36856452, dom-acc: 0.62598214
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 114.07662570, sen-loss: 42.82481477, dom-loss: 71.25181079, train-acc: 0.85553571, val-acc: 0.88250000 val_loss: 0.32940039, dom-acc: 0.60732143
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.68028265, sen-loss: 39.15937516, dom-loss: 72.52090752, train-acc: 0.85696429, val-acc: 0.89000000 val_loss: 0.30776227, dom-acc: 0.58571429
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.80177999, sen-loss: 36.56058368, dom-loss: 74.24119657, train-acc: 0.87785714, val-acc: 0.89750000 val_loss: 0.27581435, dom-acc: 0.56544643
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.45577490, sen-loss: 34.84691358, dom-loss: 75.60886139, train-acc: 0.88357143, val-acc: 0.90750000 val_loss: 0.26066110, dom-acc: 0.54142857
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.64767408, sen-loss: 33.66003071, dom-loss: 76.98764366, train-acc: 0.89160714, val-acc: 0.91250000 val_loss: 0.25459126, dom-acc: 0.51169643
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.88414884, sen-loss: 32.61543934, dom-loss: 78.26870954, train-acc: 0.89285714, val-acc: 0.91750000 val_loss: 0.25076804, dom-acc: 0.48044643
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 111.39748091, sen-loss: 32.17304515, dom-loss: 79.22443599, train-acc: 0.89625000, val-acc: 0.91500000 val_loss: 0.24242902, dom-acc: 0.45312500
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 111.04058361, sen-loss: 31.31717578, dom-loss: 79.72340739, train-acc: 0.89892857, val-acc: 0.91250000 val_loss: 0.23417090, dom-acc: 0.43803571
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 110.73316151, sen-loss: 30.44454811, dom-loss: 80.28861368, train-acc: 0.90410714, val-acc: 0.92250000 val_loss: 0.23285605, dom-acc: 0.42669643
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 110.43898690, sen-loss: 29.89480752, dom-loss: 80.54417944, train-acc: 0.90392857, val-acc: 0.92250000 val_loss: 0.22816327, dom-acc: 0.41776786
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 109.76784563, sen-loss: 29.40011220, dom-loss: 80.36773312, train-acc: 0.90625000, val-acc: 0.92750000 val_loss: 0.22618705, dom-acc: 0.42160714
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 109.09357184, sen-loss: 28.90086214, dom-loss: 80.19270974, train-acc: 0.90785714, val-acc: 0.92500000 val_loss: 0.22389486, dom-acc: 0.43642857
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 107.97023529, sen-loss: 28.44513378, dom-loss: 79.52510160, train-acc: 0.90892857, val-acc: 0.93500000 val_loss: 0.22314335, dom-acc: 0.44116071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 107.21699727, sen-loss: 28.12686387, dom-loss: 79.09013349, train-acc: 0.90946429, val-acc: 0.93250000 val_loss: 0.22287047, dom-acc: 0.46758929
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 106.23580670, sen-loss: 27.77542276, dom-loss: 78.46038359, train-acc: 0.91071429, val-acc: 0.93000000 val_loss: 0.21873190, dom-acc: 0.48901786
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 105.31292164, sen-loss: 27.35806292, dom-loss: 77.95485878, train-acc: 0.91250000, val-acc: 0.92000000 val_loss: 0.21744758, dom-acc: 0.51000000
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 104.59806615, sen-loss: 27.08043141, dom-loss: 77.51763433, train-acc: 0.91303571, val-acc: 0.92500000 val_loss: 0.21595554, dom-acc: 0.51696429
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.54134798, sen-loss: 26.47769752, dom-loss: 77.06365073, train-acc: 0.91553571, val-acc: 0.92500000 val_loss: 0.21784078, dom-acc: 0.52526786
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 102.99137181, sen-loss: 26.27876554, dom-loss: 76.71260649, train-acc: 0.91571429, val-acc: 0.93000000 val_loss: 0.21546948, dom-acc: 0.53410714
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.65893608, sen-loss: 25.93929802, dom-loss: 76.71963805, train-acc: 0.91714286, val-acc: 0.92500000 val_loss: 0.21325824, dom-acc: 0.53785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.25901330, sen-loss: 25.59021068, dom-loss: 76.66880274, train-acc: 0.91750000, val-acc: 0.91750000 val_loss: 0.21275254, dom-acc: 0.53973214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.65567130, sen-loss: 25.21074432, dom-loss: 76.44492692, train-acc: 0.92089286, val-acc: 0.92250000 val_loss: 0.21164462, dom-acc: 0.52785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.72251391, sen-loss: 24.96056247, dom-loss: 76.76195145, train-acc: 0.92125000, val-acc: 0.92500000 val_loss: 0.21242788, dom-acc: 0.52517857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.62611043, sen-loss: 24.65170366, dom-loss: 76.97440684, train-acc: 0.92339286, val-acc: 0.92500000 val_loss: 0.21026605, dom-acc: 0.51035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.56652939, sen-loss: 24.30927467, dom-loss: 77.25725520, train-acc: 0.92178571, val-acc: 0.91750000 val_loss: 0.21147281, dom-acc: 0.52160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.41447532, sen-loss: 24.08050147, dom-loss: 77.33397365, train-acc: 0.92517857, val-acc: 0.92250000 val_loss: 0.20881589, dom-acc: 0.49732143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 101.71180624, sen-loss: 23.92540105, dom-loss: 77.78640527, train-acc: 0.92660714, val-acc: 0.92500000 val_loss: 0.20831305, dom-acc: 0.48589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 101.68951666, sen-loss: 23.54999961, dom-loss: 78.13951719, train-acc: 0.92535714, val-acc: 0.91750000 val_loss: 0.21043666, dom-acc: 0.47535714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.72893918, sen-loss: 23.29833338, dom-loss: 78.43060577, train-acc: 0.92589286, val-acc: 0.91750000 val_loss: 0.20963441, dom-acc: 0.45883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 101.49664086, sen-loss: 23.07039205, dom-loss: 78.42624873, train-acc: 0.92821429, val-acc: 0.91750000 val_loss: 0.20640601, dom-acc: 0.43812500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 101.69384974, sen-loss: 22.79699185, dom-loss: 78.89685822, train-acc: 0.92803571, val-acc: 0.92250000 val_loss: 0.20733789, dom-acc: 0.43446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 101.35969597, sen-loss: 22.40063486, dom-loss: 78.95906109, train-acc: 0.92964286, val-acc: 0.92500000 val_loss: 0.20574872, dom-acc: 0.43267857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 101.20584363, sen-loss: 22.19700859, dom-loss: 79.00883472, train-acc: 0.93071429, val-acc: 0.91500000 val_loss: 0.21130866, dom-acc: 0.41928571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.98832172, sen-loss: 22.02211849, dom-loss: 78.96620333, train-acc: 0.93232143, val-acc: 0.92250000 val_loss: 0.20443183, dom-acc: 0.44392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.54875797, sen-loss: 21.79099391, dom-loss: 78.75776434, train-acc: 0.93250000, val-acc: 0.91750000 val_loss: 0.20947814, dom-acc: 0.42053571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 100.14227563, sen-loss: 21.51591323, dom-loss: 78.62636280, train-acc: 0.93464286, val-acc: 0.92250000 val_loss: 0.20574403, dom-acc: 0.44482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 99.53096634, sen-loss: 21.24326336, dom-loss: 78.28770322, train-acc: 0.93482143, val-acc: 0.92250000 val_loss: 0.20792434, dom-acc: 0.43776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 98.94090575, sen-loss: 20.88686125, dom-loss: 78.05404472, train-acc: 0.93625000, val-acc: 0.92000000 val_loss: 0.20760170, dom-acc: 0.45508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 98.47003943, sen-loss: 20.75033655, dom-loss: 77.71970320, train-acc: 0.93767857, val-acc: 0.92250000 val_loss: 0.20577623, dom-acc: 0.46598214
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_video_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.20443183
Testing accuracy: 0.83516667
./work/attentions/electronics_video_train.txt
./work/pivots/electronics_video_pos.txt
./work/pivots/electronics_video_neg.txt
./work/attentions/electronics_video_test.txt
loading data...
source domain:  kitchen target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 9750
vocab-size:  78006
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 17
max memory size: 20
5600 400 6000 19856 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78007, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.51494825, sen-loss: 75.15250850, dom-loss: 80.36243939, train-acc: 0.77910714, val-acc: 0.78500000 val_loss: 0.62645739, dom-acc: 0.86732143
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 136.94068933, sen-loss: 63.84493077, dom-loss: 73.09575814, train-acc: 0.80803571, val-acc: 0.83000000 val_loss: 0.49128160, dom-acc: 0.77526786
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 120.08610415, sen-loss: 49.15911666, dom-loss: 70.92698759, train-acc: 0.83607143, val-acc: 0.84000000 val_loss: 0.39045683, dom-acc: 0.60642857
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 113.49527121, sen-loss: 42.15067600, dom-loss: 71.34459502, train-acc: 0.85750000, val-acc: 0.85750000 val_loss: 0.35025516, dom-acc: 0.57955357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 109.95169067, sen-loss: 37.55634572, dom-loss: 72.39534467, train-acc: 0.87821429, val-acc: 0.88500000 val_loss: 0.32803184, dom-acc: 0.56571429
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 108.09507954, sen-loss: 34.10333219, dom-loss: 73.99174714, train-acc: 0.88142857, val-acc: 0.88500000 val_loss: 0.30126566, dom-acc: 0.56196429
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 106.77723610, sen-loss: 31.81480472, dom-loss: 74.96243131, train-acc: 0.89339286, val-acc: 0.89750000 val_loss: 0.29402831, dom-acc: 0.53910714
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 106.48939067, sen-loss: 30.24845243, dom-loss: 76.24093831, train-acc: 0.90196429, val-acc: 0.90500000 val_loss: 0.29074383, dom-acc: 0.51660714
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 106.78166753, sen-loss: 29.19168410, dom-loss: 77.58998328, train-acc: 0.90464286, val-acc: 0.90250000 val_loss: 0.29028073, dom-acc: 0.49366071
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 107.07795280, sen-loss: 28.49501666, dom-loss: 78.58293700, train-acc: 0.90642857, val-acc: 0.90500000 val_loss: 0.28843969, dom-acc: 0.46598214
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 107.34832090, sen-loss: 27.91233297, dom-loss: 79.43598813, train-acc: 0.90910714, val-acc: 0.91000000 val_loss: 0.28552884, dom-acc: 0.44214286
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 107.47801703, sen-loss: 27.41222813, dom-loss: 80.06578869, train-acc: 0.91160714, val-acc: 0.91000000 val_loss: 0.28689808, dom-acc: 0.42151786
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 106.98382819, sen-loss: 26.79815579, dom-loss: 80.18567246, train-acc: 0.91017857, val-acc: 0.90250000 val_loss: 0.30276832, dom-acc: 0.39517857
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.58249420, sen-loss: 26.35865549, dom-loss: 80.22383827, train-acc: 0.91375000, val-acc: 0.92000000 val_loss: 0.27860034, dom-acc: 0.40982143
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 106.02984172, sen-loss: 25.87373154, dom-loss: 80.15611017, train-acc: 0.91625000, val-acc: 0.91750000 val_loss: 0.28159440, dom-acc: 0.40875000
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 105.31053811, sen-loss: 25.65058371, dom-loss: 79.65995413, train-acc: 0.91785714, val-acc: 0.91750000 val_loss: 0.27949187, dom-acc: 0.42125000
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 104.23161989, sen-loss: 25.08021401, dom-loss: 79.15140563, train-acc: 0.91928571, val-acc: 0.92000000 val_loss: 0.27984226, dom-acc: 0.43419643
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 103.51132923, sen-loss: 24.90418603, dom-loss: 78.60714340, train-acc: 0.91821429, val-acc: 0.92500000 val_loss: 0.27238974, dom-acc: 0.45803571
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 102.69582516, sen-loss: 24.47161157, dom-loss: 78.22421330, train-acc: 0.91910714, val-acc: 0.92500000 val_loss: 0.27178925, dom-acc: 0.49866071
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 101.94411784, sen-loss: 24.20710748, dom-loss: 77.73701024, train-acc: 0.92232143, val-acc: 0.92000000 val_loss: 0.27491775, dom-acc: 0.47294643
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 101.23475128, sen-loss: 23.87201747, dom-loss: 77.36273402, train-acc: 0.92339286, val-acc: 0.92000000 val_loss: 0.27888730, dom-acc: 0.49294643
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 100.68999499, sen-loss: 23.58615896, dom-loss: 77.10383588, train-acc: 0.92375000, val-acc: 0.92250000 val_loss: 0.28275162, dom-acc: 0.51705357
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 100.28579360, sen-loss: 23.35700670, dom-loss: 76.92878681, train-acc: 0.92446429, val-acc: 0.92250000 val_loss: 0.28065827, dom-acc: 0.50651786
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 100.21396178, sen-loss: 23.18257152, dom-loss: 77.03139019, train-acc: 0.92767857, val-acc: 0.92250000 val_loss: 0.27648944, dom-acc: 0.51330357
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_books_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27178925
Testing accuracy: 0.83983333
./work/attentions/kitchen_books_train.txt
./work/pivots/kitchen_books_pos.txt
./work/pivots/kitchen_books_neg.txt
./work/attentions/kitchen_books_test.txt
loading data...
source domain:  kitchen target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 11843
vocab-size:  80685
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 17
max memory size: 20
5600 400 6000 19856 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(80686, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.08540976, sen-loss: 75.12500679, dom-loss: 79.96040356, train-acc: 0.77571429, val-acc: 0.78500000 val_loss: 0.62536871, dom-acc: 0.86303571
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 136.92896354, sen-loss: 63.85886377, dom-loss: 73.07009947, train-acc: 0.81160714, val-acc: 0.83250000 val_loss: 0.49296334, dom-acc: 0.79464286
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 120.50303298, sen-loss: 49.27848664, dom-loss: 71.22454602, train-acc: 0.83678571, val-acc: 0.84500000 val_loss: 0.38998133, dom-acc: 0.61187500
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 113.82846916, sen-loss: 42.05717133, dom-loss: 71.77129805, train-acc: 0.85678571, val-acc: 0.86750000 val_loss: 0.35023537, dom-acc: 0.58562500
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 110.00240731, sen-loss: 37.43284069, dom-loss: 72.56956697, train-acc: 0.87839286, val-acc: 0.88750000 val_loss: 0.32828715, dom-acc: 0.56544643
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 107.99913514, sen-loss: 34.04918793, dom-loss: 73.94994724, train-acc: 0.87964286, val-acc: 0.89250000 val_loss: 0.30201972, dom-acc: 0.56133929
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 106.83913612, sen-loss: 31.84869336, dom-loss: 74.99044305, train-acc: 0.89321429, val-acc: 0.90500000 val_loss: 0.29464868, dom-acc: 0.54133929
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 106.18265581, sen-loss: 30.24658141, dom-loss: 75.93607491, train-acc: 0.90089286, val-acc: 0.91000000 val_loss: 0.29026309, dom-acc: 0.51553571
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 106.34411097, sen-loss: 29.20341349, dom-loss: 77.14069724, train-acc: 0.90339286, val-acc: 0.90750000 val_loss: 0.28873965, dom-acc: 0.49616071
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 106.47708774, sen-loss: 28.50928606, dom-loss: 77.96780163, train-acc: 0.90642857, val-acc: 0.90750000 val_loss: 0.28602624, dom-acc: 0.47187500
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 106.75378907, sen-loss: 27.89547157, dom-loss: 78.85831785, train-acc: 0.90892857, val-acc: 0.91000000 val_loss: 0.28400525, dom-acc: 0.46133929
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 106.73039198, sen-loss: 27.40119276, dom-loss: 79.32919902, train-acc: 0.91000000, val-acc: 0.91000000 val_loss: 0.28512433, dom-acc: 0.43508929
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 106.48884737, sen-loss: 26.77750579, dom-loss: 79.71134156, train-acc: 0.90803571, val-acc: 0.91250000 val_loss: 0.29950449, dom-acc: 0.42107143
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.13413465, sen-loss: 26.33830680, dom-loss: 79.79582757, train-acc: 0.91464286, val-acc: 0.91750000 val_loss: 0.27552858, dom-acc: 0.43732143
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 105.64809841, sen-loss: 25.87724179, dom-loss: 79.77085692, train-acc: 0.91767857, val-acc: 0.91750000 val_loss: 0.27989191, dom-acc: 0.43544643
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 105.09130156, sen-loss: 25.65032205, dom-loss: 79.44097972, train-acc: 0.91964286, val-acc: 0.91750000 val_loss: 0.27689913, dom-acc: 0.43892857
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 104.14215010, sen-loss: 25.06090834, dom-loss: 79.08124197, train-acc: 0.92089286, val-acc: 0.91750000 val_loss: 0.27799723, dom-acc: 0.44705357
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 103.36286420, sen-loss: 24.89651918, dom-loss: 78.46634477, train-acc: 0.91910714, val-acc: 0.92250000 val_loss: 0.26988518, dom-acc: 0.46250000
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 102.77476096, sen-loss: 24.46052697, dom-loss: 78.31423390, train-acc: 0.92178571, val-acc: 0.92500000 val_loss: 0.26931757, dom-acc: 0.48544643
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 101.83142060, sen-loss: 24.18970457, dom-loss: 77.64171594, train-acc: 0.92357143, val-acc: 0.92250000 val_loss: 0.27306572, dom-acc: 0.48303571
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 100.94700432, sen-loss: 23.84145713, dom-loss: 77.10554677, train-acc: 0.92571429, val-acc: 0.91750000 val_loss: 0.27725145, dom-acc: 0.49116071
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 100.37021601, sen-loss: 23.56832097, dom-loss: 76.80189514, train-acc: 0.92464286, val-acc: 0.92000000 val_loss: 0.28023449, dom-acc: 0.50428571
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 99.84220815, sen-loss: 23.32482804, dom-loss: 76.51737994, train-acc: 0.92464286, val-acc: 0.92000000 val_loss: 0.27946845, dom-acc: 0.50991071
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 99.41949266, sen-loss: 23.15388303, dom-loss: 76.26560962, train-acc: 0.92946429, val-acc: 0.92500000 val_loss: 0.27487400, dom-acc: 0.50991071
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_dvd_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.26931757
Testing accuracy: 0.83566667
./work/attentions/kitchen_dvd_train.txt
./work/pivots/kitchen_dvd_pos.txt
./work/pivots/kitchen_dvd_neg.txt
./work/attentions/kitchen_dvd_test.txt
loading data...
source domain:  kitchen target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 17009
vocab-size:  49470
max  story size: 129
mean story size: 6
max  sentence size: 440
mean sentence size: 15
max memory size: 20
5600 400 6000 19856 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(49471, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 157.88033688, sen-loss: 75.20185870, dom-loss: 82.67847794, train-acc: 0.77803571, val-acc: 0.80250000 val_loss: 0.62705737, dom-acc: 0.65866071
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 141.13442349, sen-loss: 63.97707936, dom-loss: 77.15734392, train-acc: 0.80839286, val-acc: 0.83000000 val_loss: 0.49206865, dom-acc: 0.65553571
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 125.32832426, sen-loss: 49.26758987, dom-loss: 76.06073451, train-acc: 0.83375000, val-acc: 0.84000000 val_loss: 0.39072287, dom-acc: 0.55892857
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 117.95116639, sen-loss: 42.29875866, dom-loss: 75.65240753, train-acc: 0.85553571, val-acc: 0.85750000 val_loss: 0.35004377, dom-acc: 0.56303571
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 113.28917819, sen-loss: 37.69239986, dom-loss: 75.59677833, train-acc: 0.87767857, val-acc: 0.88000000 val_loss: 0.32722652, dom-acc: 0.57883929
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 109.87466115, sen-loss: 34.20998730, dom-loss: 75.66467404, train-acc: 0.88089286, val-acc: 0.87750000 val_loss: 0.30128944, dom-acc: 0.61973214
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 107.59164178, sen-loss: 31.87446657, dom-loss: 75.71717530, train-acc: 0.89571429, val-acc: 0.90500000 val_loss: 0.29422307, dom-acc: 0.62348214
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 106.05299938, sen-loss: 30.26978701, dom-loss: 75.78321218, train-acc: 0.90071429, val-acc: 0.91000000 val_loss: 0.28949210, dom-acc: 0.62125000
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 105.04481733, sen-loss: 29.19716509, dom-loss: 75.84765232, train-acc: 0.90464286, val-acc: 0.90500000 val_loss: 0.28823394, dom-acc: 0.64383929
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 104.47095138, sen-loss: 28.52260096, dom-loss: 75.94835043, train-acc: 0.90714286, val-acc: 0.90250000 val_loss: 0.28650588, dom-acc: 0.60964286
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 103.98468864, sen-loss: 27.91793291, dom-loss: 76.06675547, train-acc: 0.90982143, val-acc: 0.91250000 val_loss: 0.28439763, dom-acc: 0.65160714
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 103.66175264, sen-loss: 27.37511375, dom-loss: 76.28663886, train-acc: 0.91196429, val-acc: 0.90500000 val_loss: 0.28703809, dom-acc: 0.63187500
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 103.11577338, sen-loss: 26.76047058, dom-loss: 76.35530233, train-acc: 0.90982143, val-acc: 0.90750000 val_loss: 0.30194524, dom-acc: 0.62767857
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 102.89692855, sen-loss: 26.32543730, dom-loss: 76.57149166, train-acc: 0.91642857, val-acc: 0.92000000 val_loss: 0.27762946, dom-acc: 0.61437500
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 102.56840241, sen-loss: 25.81134147, dom-loss: 76.75706112, train-acc: 0.91803571, val-acc: 0.91250000 val_loss: 0.28185722, dom-acc: 0.59750000
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 102.46885401, sen-loss: 25.58049478, dom-loss: 76.88835937, train-acc: 0.92035714, val-acc: 0.91750000 val_loss: 0.27964854, dom-acc: 0.61446429
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 102.06082577, sen-loss: 25.01213303, dom-loss: 77.04869264, train-acc: 0.91946429, val-acc: 0.91750000 val_loss: 0.27948225, dom-acc: 0.59357143
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 101.89410079, sen-loss: 24.81629702, dom-loss: 77.07780379, train-acc: 0.92035714, val-acc: 0.92500000 val_loss: 0.27256632, dom-acc: 0.54732143
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 101.77399141, sen-loss: 24.37935568, dom-loss: 77.39463603, train-acc: 0.92285714, val-acc: 0.92250000 val_loss: 0.27264518, dom-acc: 0.57562500
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 101.54502320, sen-loss: 24.08574776, dom-loss: 77.45927548, train-acc: 0.92482143, val-acc: 0.92000000 val_loss: 0.27495152, dom-acc: 0.56928571
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 101.38139713, sen-loss: 23.75500493, dom-loss: 77.62639219, train-acc: 0.92428571, val-acc: 0.91500000 val_loss: 0.27874729, dom-acc: 0.56169643
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 101.21665895, sen-loss: 23.44927998, dom-loss: 77.76737911, train-acc: 0.92392857, val-acc: 0.92500000 val_loss: 0.28406948, dom-acc: 0.58232143
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 100.93039566, sen-loss: 23.22844084, dom-loss: 77.70195448, train-acc: 0.92607143, val-acc: 0.92750000 val_loss: 0.28178748, dom-acc: 0.54625000
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_electronics_PNet.ckpt
Best Epoch: [ 18] best val accuracy: 0.00000000 best val loss: 0.27256632
Testing accuracy: 0.88066667
./work/attentions/kitchen_electronics_train.txt
./work/pivots/kitchen_electronics_pos.txt
./work/pivots/kitchen_electronics_neg.txt
./work/attentions/kitchen_electronics_test.txt
loading data...
source domain:  kitchen target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 30180
vocab-size:  78115
max  story size: 104
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
5600 400 6000 19856 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78116, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.71090448, sen-loss: 75.06412411, dom-loss: 79.64678079, train-acc: 0.77964286, val-acc: 0.78500000 val_loss: 0.62459260, dom-acc: 0.89303571
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 135.83655608, sen-loss: 63.65610197, dom-loss: 72.18045378, train-acc: 0.81089286, val-acc: 0.82500000 val_loss: 0.48925287, dom-acc: 0.80214286
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 119.55329686, sen-loss: 49.07959330, dom-loss: 70.47370362, train-acc: 0.83517857, val-acc: 0.84500000 val_loss: 0.38911486, dom-acc: 0.62633929
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 112.82857871, sen-loss: 42.05905144, dom-loss: 70.76952720, train-acc: 0.85642857, val-acc: 0.86500000 val_loss: 0.34987769, dom-acc: 0.59169643
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 109.46369225, sen-loss: 37.44550900, dom-loss: 72.01818323, train-acc: 0.87910714, val-acc: 0.89000000 val_loss: 0.32809117, dom-acc: 0.57633929
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 107.66803014, sen-loss: 34.00184345, dom-loss: 73.66618663, train-acc: 0.88071429, val-acc: 0.88500000 val_loss: 0.30311593, dom-acc: 0.56580357
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 106.80321652, sen-loss: 31.81178759, dom-loss: 74.99142897, train-acc: 0.89553571, val-acc: 0.90250000 val_loss: 0.29642475, dom-acc: 0.54232143
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 106.48718303, sen-loss: 30.20102219, dom-loss: 76.28616130, train-acc: 0.90017857, val-acc: 0.90500000 val_loss: 0.29172474, dom-acc: 0.51232143
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 106.85717583, sen-loss: 29.15395240, dom-loss: 77.70322371, train-acc: 0.90500000, val-acc: 0.89500000 val_loss: 0.29062203, dom-acc: 0.48785714
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 107.25501311, sen-loss: 28.45459557, dom-loss: 78.80041826, train-acc: 0.90732143, val-acc: 0.90000000 val_loss: 0.28820682, dom-acc: 0.46098214
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 107.70192176, sen-loss: 27.86364841, dom-loss: 79.83827353, train-acc: 0.90928571, val-acc: 0.91250000 val_loss: 0.28439060, dom-acc: 0.44401786
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 107.53256685, sen-loss: 27.34995557, dom-loss: 80.18261147, train-acc: 0.91357143, val-acc: 0.90500000 val_loss: 0.28687122, dom-acc: 0.41535714
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 107.21988124, sen-loss: 26.74345054, dom-loss: 80.47643054, train-acc: 0.90928571, val-acc: 0.90500000 val_loss: 0.30068648, dom-acc: 0.40562500
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.54842132, sen-loss: 26.29969983, dom-loss: 80.24872184, train-acc: 0.91517857, val-acc: 0.91750000 val_loss: 0.27643171, dom-acc: 0.42946429
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 105.83453566, sen-loss: 25.82927014, dom-loss: 80.00526571, train-acc: 0.91785714, val-acc: 0.91750000 val_loss: 0.28013489, dom-acc: 0.42223214
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 105.15419495, sen-loss: 25.58389025, dom-loss: 79.57030451, train-acc: 0.91892857, val-acc: 0.92000000 val_loss: 0.27712661, dom-acc: 0.45428571
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 103.79516846, sen-loss: 25.02073871, dom-loss: 78.77442998, train-acc: 0.92053571, val-acc: 0.91750000 val_loss: 0.27815279, dom-acc: 0.45937500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 102.97191787, sen-loss: 24.84459756, dom-loss: 78.12731993, train-acc: 0.92000000, val-acc: 0.92250000 val_loss: 0.27042541, dom-acc: 0.48937500
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 102.09740251, sen-loss: 24.39471698, dom-loss: 77.70268542, train-acc: 0.92142857, val-acc: 0.92500000 val_loss: 0.26968461, dom-acc: 0.51000000
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 101.19342512, sen-loss: 24.14022564, dom-loss: 77.05319929, train-acc: 0.92321429, val-acc: 0.92000000 val_loss: 0.27273503, dom-acc: 0.51151786
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 100.35331333, sen-loss: 23.78622153, dom-loss: 76.56709188, train-acc: 0.92500000, val-acc: 0.91750000 val_loss: 0.27664179, dom-acc: 0.52223214
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 99.69635755, sen-loss: 23.49623430, dom-loss: 76.20012313, train-acc: 0.92428571, val-acc: 0.92250000 val_loss: 0.28172588, dom-acc: 0.52991071
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 99.31377888, sen-loss: 23.26935215, dom-loss: 76.04442674, train-acc: 0.92625000, val-acc: 0.92250000 val_loss: 0.27951315, dom-acc: 0.52750000
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 99.33351803, sen-loss: 23.10850080, dom-loss: 76.22501695, train-acc: 0.92785714, val-acc: 0.92250000 val_loss: 0.27399519, dom-acc: 0.53214286
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_video_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.26968461
Testing accuracy: 0.83700000
./work/attentions/kitchen_video_train.txt
./work/pivots/kitchen_video_pos.txt
./work/pivots/kitchen_video_neg.txt
./work/attentions/kitchen_video_test.txt
loading data...
source domain:  video target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 9750
vocab-size:  98084
max  story size: 189
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
5600 400 6000 36180 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(98085, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.43508077, sen-loss: 76.72117436, dom-loss: 82.71390653, train-acc: 0.72035714, val-acc: 0.72500000 val_loss: 0.65240115, dom-acc: 0.69258929
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 146.25804162, sen-loss: 69.25681496, dom-loss: 77.00122660, train-acc: 0.74321429, val-acc: 0.72500000 val_loss: 0.58349824, dom-acc: 0.76437500
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 135.25647235, sen-loss: 59.42539299, dom-loss: 75.83107907, train-acc: 0.80250000, val-acc: 0.78000000 val_loss: 0.49077126, dom-acc: 0.78071429
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 124.91137666, sen-loss: 49.56572852, dom-loss: 75.34564775, train-acc: 0.84517857, val-acc: 0.82750000 val_loss: 0.41215056, dom-acc: 0.79026786
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 117.66405296, sen-loss: 42.32479106, dom-loss: 75.33926183, train-acc: 0.86696429, val-acc: 0.85000000 val_loss: 0.36525974, dom-acc: 0.76964286
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.96346390, sen-loss: 37.17770751, dom-loss: 74.78575677, train-acc: 0.88446429, val-acc: 0.87750000 val_loss: 0.33116779, dom-acc: 0.76660714
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 109.42096084, sen-loss: 34.57891710, dom-loss: 74.84204364, train-acc: 0.88232143, val-acc: 0.86750000 val_loss: 0.32743737, dom-acc: 0.74151786
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 108.19043553, sen-loss: 33.31014153, dom-loss: 74.88029385, train-acc: 0.89178571, val-acc: 0.87750000 val_loss: 0.31359765, dom-acc: 0.72705357
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 107.21819729, sen-loss: 32.38700508, dom-loss: 74.83119184, train-acc: 0.89875000, val-acc: 0.88250000 val_loss: 0.30857661, dom-acc: 0.71205357
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 106.31684202, sen-loss: 31.24465451, dom-loss: 75.07218790, train-acc: 0.90142857, val-acc: 0.88500000 val_loss: 0.30258864, dom-acc: 0.70535714
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 105.54295969, sen-loss: 30.38205169, dom-loss: 75.16090804, train-acc: 0.90321429, val-acc: 0.88750000 val_loss: 0.29982257, dom-acc: 0.68571429
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 105.49026728, sen-loss: 29.85611200, dom-loss: 75.63415509, train-acc: 0.90535714, val-acc: 0.88750000 val_loss: 0.29690927, dom-acc: 0.67696429
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 104.81960517, sen-loss: 29.07107309, dom-loss: 75.74853235, train-acc: 0.90910714, val-acc: 0.89250000 val_loss: 0.29661831, dom-acc: 0.65419643
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 104.77334762, sen-loss: 28.51927829, dom-loss: 76.25406945, train-acc: 0.91267857, val-acc: 0.89500000 val_loss: 0.29604089, dom-acc: 0.63839286
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 104.52121407, sen-loss: 27.95216872, dom-loss: 76.56904519, train-acc: 0.91285714, val-acc: 0.89750000 val_loss: 0.28916359, dom-acc: 0.62875000
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 104.82893980, sen-loss: 28.07850426, dom-loss: 76.75043547, train-acc: 0.91410714, val-acc: 0.89000000 val_loss: 0.29436675, dom-acc: 0.62071429
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 104.24728322, sen-loss: 27.10229690, dom-loss: 77.14498603, train-acc: 0.91696429, val-acc: 0.89500000 val_loss: 0.28568193, dom-acc: 0.60339286
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 104.50277489, sen-loss: 26.93400371, dom-loss: 77.56877118, train-acc: 0.91839286, val-acc: 0.89500000 val_loss: 0.28378403, dom-acc: 0.59669643
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 104.33361548, sen-loss: 26.45038052, dom-loss: 77.88323474, train-acc: 0.91964286, val-acc: 0.90000000 val_loss: 0.28257218, dom-acc: 0.58794643
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 103.96418077, sen-loss: 25.91468001, dom-loss: 78.04950052, train-acc: 0.91678571, val-acc: 0.89500000 val_loss: 0.28031477, dom-acc: 0.58035714
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 103.71499115, sen-loss: 25.56754182, dom-loss: 78.14744943, train-acc: 0.92125000, val-acc: 0.89750000 val_loss: 0.28449839, dom-acc: 0.56928571
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.88565093, sen-loss: 25.32141323, dom-loss: 78.56423777, train-acc: 0.92392857, val-acc: 0.90000000 val_loss: 0.28007182, dom-acc: 0.56312500
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 103.42168474, sen-loss: 24.86167267, dom-loss: 78.56001174, train-acc: 0.92482143, val-acc: 0.90000000 val_loss: 0.27821541, dom-acc: 0.55383929
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 103.42833006, sen-loss: 24.57439961, dom-loss: 78.85393047, train-acc: 0.92535714, val-acc: 0.90000000 val_loss: 0.28258976, dom-acc: 0.54160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.11322600, sen-loss: 24.28061367, dom-loss: 78.83261222, train-acc: 0.92660714, val-acc: 0.89750000 val_loss: 0.27649763, dom-acc: 0.54910714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.68626517, sen-loss: 23.89680111, dom-loss: 78.78946447, train-acc: 0.92625000, val-acc: 0.90000000 val_loss: 0.28405765, dom-acc: 0.53446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.58219731, sen-loss: 23.67610423, dom-loss: 78.90609282, train-acc: 0.92678571, val-acc: 0.90250000 val_loss: 0.28477392, dom-acc: 0.53696429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.24276984, sen-loss: 23.36427819, dom-loss: 78.87849140, train-acc: 0.92892857, val-acc: 0.89750000 val_loss: 0.28208074, dom-acc: 0.53062500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.98902667, sen-loss: 23.13752633, dom-loss: 78.85150057, train-acc: 0.92946429, val-acc: 0.89500000 val_loss: 0.27670008, dom-acc: 0.53821429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.57673723, sen-loss: 22.80461176, dom-loss: 78.77212512, train-acc: 0.93178571, val-acc: 0.89750000 val_loss: 0.27814817, dom-acc: 0.52142857
---------------------------------------------------

Successfully load model from save path: ./work/models/video_books_PNet.ckpt
Best Epoch: [ 25] best val accuracy: 0.00000000 best val loss: 0.27649763
Testing accuracy: 0.86816667
./work/attentions/video_books_train.txt
./work/pivots/video_books_pos.txt
./work/pivots/video_books_neg.txt
./work/attentions/video_books_test.txt
loading data...
source domain:  video target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 11843
vocab-size:  91852
max  story size: 226
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
5600 400 6000 36180 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(91853, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.74616778, sen-loss: 76.69244957, dom-loss: 83.05371839, train-acc: 0.72357143, val-acc: 0.72250000 val_loss: 0.65095228, dom-acc: 0.57464286
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 148.10195947, sen-loss: 69.15725392, dom-loss: 78.94470567, train-acc: 0.74428571, val-acc: 0.73250000 val_loss: 0.58052003, dom-acc: 0.57357143
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 138.02672029, sen-loss: 59.18351990, dom-loss: 78.84320015, train-acc: 0.80625000, val-acc: 0.78250000 val_loss: 0.48675224, dom-acc: 0.58848214
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 128.01986063, sen-loss: 49.24595731, dom-loss: 78.77390319, train-acc: 0.84482143, val-acc: 0.84500000 val_loss: 0.40818691, dom-acc: 0.58919643
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 120.62331265, sen-loss: 41.91630307, dom-loss: 78.70700932, train-acc: 0.87017857, val-acc: 0.84750000 val_loss: 0.36259022, dom-acc: 0.56562500
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 115.40687954, sen-loss: 36.80519155, dom-loss: 78.60168785, train-acc: 0.88857143, val-acc: 0.87000000 val_loss: 0.33169156, dom-acc: 0.54151786
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 112.91549122, sen-loss: 34.34294271, dom-loss: 78.57254869, train-acc: 0.88517857, val-acc: 0.86750000 val_loss: 0.32920596, dom-acc: 0.59875000
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 111.64118302, sen-loss: 33.12833102, dom-loss: 78.51285166, train-acc: 0.89428571, val-acc: 0.87750000 val_loss: 0.31511283, dom-acc: 0.54375000
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.68655705, sen-loss: 32.22895849, dom-loss: 78.45759857, train-acc: 0.89964286, val-acc: 0.88250000 val_loss: 0.31044149, dom-acc: 0.59848214
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 109.49494964, sen-loss: 31.07996644, dom-loss: 78.41498327, train-acc: 0.90214286, val-acc: 0.89000000 val_loss: 0.30423841, dom-acc: 0.57169643
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 108.64907372, sen-loss: 30.23152386, dom-loss: 78.41755044, train-acc: 0.90428571, val-acc: 0.88750000 val_loss: 0.30164465, dom-acc: 0.56767857
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.06157792, sen-loss: 29.71810644, dom-loss: 78.34347171, train-acc: 0.90767857, val-acc: 0.89000000 val_loss: 0.29855716, dom-acc: 0.56642857
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 107.24954700, sen-loss: 28.93412667, dom-loss: 78.31542069, train-acc: 0.91232143, val-acc: 0.89000000 val_loss: 0.29783720, dom-acc: 0.59017857
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 106.64477539, sen-loss: 28.41909997, dom-loss: 78.22567534, train-acc: 0.91303571, val-acc: 0.88750000 val_loss: 0.29774928, dom-acc: 0.59410714
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 106.07993400, sen-loss: 27.84476401, dom-loss: 78.23516989, train-acc: 0.91392857, val-acc: 0.89000000 val_loss: 0.29012626, dom-acc: 0.60848214
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 106.11294633, sen-loss: 27.96482858, dom-loss: 78.14811772, train-acc: 0.91607143, val-acc: 0.88750000 val_loss: 0.29437965, dom-acc: 0.61803571
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 105.20111680, sen-loss: 27.01448582, dom-loss: 78.18663114, train-acc: 0.91732143, val-acc: 0.89250000 val_loss: 0.28636703, dom-acc: 0.56839286
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 105.08122563, sen-loss: 26.85375736, dom-loss: 78.22746789, train-acc: 0.91821429, val-acc: 0.89500000 val_loss: 0.28433049, dom-acc: 0.56473214
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 104.47522527, sen-loss: 26.36929072, dom-loss: 78.10593456, train-acc: 0.91875000, val-acc: 0.89750000 val_loss: 0.28243276, dom-acc: 0.55616071
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 103.89827347, sen-loss: 25.83858611, dom-loss: 78.05968744, train-acc: 0.91857143, val-acc: 0.89250000 val_loss: 0.28005251, dom-acc: 0.59696429
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 103.52316737, sen-loss: 25.47705255, dom-loss: 78.04611474, train-acc: 0.92232143, val-acc: 0.89000000 val_loss: 0.28333569, dom-acc: 0.57616071
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.34777725, sen-loss: 25.24530786, dom-loss: 78.10246980, train-acc: 0.92464286, val-acc: 0.89250000 val_loss: 0.27973244, dom-acc: 0.54848214
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 102.79093957, sen-loss: 24.78083827, dom-loss: 78.01010120, train-acc: 0.92428571, val-acc: 0.89500000 val_loss: 0.27701020, dom-acc: 0.61544643
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.52271169, sen-loss: 24.48650263, dom-loss: 78.03620881, train-acc: 0.92464286, val-acc: 0.89500000 val_loss: 0.28151065, dom-acc: 0.54241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.19537121, sen-loss: 24.20873172, dom-loss: 77.98663956, train-acc: 0.92607143, val-acc: 0.89500000 val_loss: 0.27459332, dom-acc: 0.56982143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.78937203, sen-loss: 23.81564905, dom-loss: 77.97372317, train-acc: 0.92607143, val-acc: 0.89750000 val_loss: 0.28204864, dom-acc: 0.57410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.52697033, sen-loss: 23.60106964, dom-loss: 77.92590111, train-acc: 0.92625000, val-acc: 0.89750000 val_loss: 0.28247964, dom-acc: 0.60750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.25542760, sen-loss: 23.28560401, dom-loss: 77.96982342, train-acc: 0.92910714, val-acc: 0.89500000 val_loss: 0.27916640, dom-acc: 0.59937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.97788060, sen-loss: 23.06989449, dom-loss: 77.90798604, train-acc: 0.93053571, val-acc: 0.88750000 val_loss: 0.27369124, dom-acc: 0.54785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.64206946, sen-loss: 22.73015139, dom-loss: 77.91191816, train-acc: 0.93232143, val-acc: 0.89500000 val_loss: 0.27596685, dom-acc: 0.54616071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.32972383, sen-loss: 22.48049673, dom-loss: 77.84922659, train-acc: 0.93250000, val-acc: 0.89750000 val_loss: 0.27859643, dom-acc: 0.51964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.01213449, sen-loss: 22.07764746, dom-loss: 77.93448699, train-acc: 0.93517857, val-acc: 0.89250000 val_loss: 0.27111813, dom-acc: 0.51285714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 99.70870042, sen-loss: 21.82331204, dom-loss: 77.88538855, train-acc: 0.93642857, val-acc: 0.90000000 val_loss: 0.27179420, dom-acc: 0.53169643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.43223614, sen-loss: 21.60770002, dom-loss: 77.82453638, train-acc: 0.93821429, val-acc: 0.89750000 val_loss: 0.27617779, dom-acc: 0.56848214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.03521699, sen-loss: 21.15862300, dom-loss: 77.87659425, train-acc: 0.93089286, val-acc: 0.89000000 val_loss: 0.27672857, dom-acc: 0.55383929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 98.92945415, sen-loss: 21.08753098, dom-loss: 77.84192312, train-acc: 0.93875000, val-acc: 0.89500000 val_loss: 0.27160650, dom-acc: 0.56196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 98.42019641, sen-loss: 20.64972687, dom-loss: 77.77046955, train-acc: 0.94000000, val-acc: 0.89750000 val_loss: 0.27299377, dom-acc: 0.57267857
---------------------------------------------------

Successfully load model from save path: ./work/models/video_dvd_PNet.ckpt
Best Epoch: [ 32] best val accuracy: 0.00000000 best val loss: 0.27111813
Testing accuracy: 0.87366667
./work/attentions/video_dvd_train.txt
./work/pivots/video_dvd_pos.txt
./work/pivots/video_dvd_neg.txt
./work/attentions/video_dvd_test.txt
loading data...
source domain:  video target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 17009
vocab-size:  83059
max  story size: 129
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
5600 400 6000 36180 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83060, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.62167144, sen-loss: 76.72450727, dom-loss: 82.89716411, train-acc: 0.72142857, val-acc: 0.72500000 val_loss: 0.65184677, dom-acc: 0.77544643
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 144.45616019, sen-loss: 69.38188696, dom-loss: 75.07427341, train-acc: 0.74125000, val-acc: 0.71750000 val_loss: 0.58343327, dom-acc: 0.82464286
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 131.78560579, sen-loss: 59.80694696, dom-loss: 71.97865927, train-acc: 0.80178571, val-acc: 0.77500000 val_loss: 0.49247313, dom-acc: 0.70366071
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 120.98254400, sen-loss: 50.28975254, dom-loss: 70.69279170, train-acc: 0.84160714, val-acc: 0.83500000 val_loss: 0.41802120, dom-acc: 0.60589286
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 115.33584261, sen-loss: 43.26865453, dom-loss: 72.06718808, train-acc: 0.86196429, val-acc: 0.85250000 val_loss: 0.37288204, dom-acc: 0.57571429
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 110.79147291, sen-loss: 37.95071152, dom-loss: 72.84076160, train-acc: 0.88392857, val-acc: 0.87000000 val_loss: 0.33471364, dom-acc: 0.57205357
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 109.08502913, sen-loss: 35.12336321, dom-loss: 73.96166569, train-acc: 0.88089286, val-acc: 0.87000000 val_loss: 0.33126587, dom-acc: 0.56866071
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 108.57539934, sen-loss: 33.77955954, dom-loss: 74.79584002, train-acc: 0.88857143, val-acc: 0.87500000 val_loss: 0.31494135, dom-acc: 0.54517857
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 108.54364622, sen-loss: 32.82918747, dom-loss: 75.71445918, train-acc: 0.89642857, val-acc: 0.88250000 val_loss: 0.31141877, dom-acc: 0.51517857
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 108.21139210, sen-loss: 31.64381374, dom-loss: 76.56757843, train-acc: 0.89982143, val-acc: 0.88000000 val_loss: 0.30380952, dom-acc: 0.48241071
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 107.98373204, sen-loss: 30.73791195, dom-loss: 77.24582028, train-acc: 0.90142857, val-acc: 0.88500000 val_loss: 0.30063507, dom-acc: 0.46008929
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 108.19991821, sen-loss: 30.20042743, dom-loss: 77.99949068, train-acc: 0.90500000, val-acc: 0.89250000 val_loss: 0.29822248, dom-acc: 0.44482143
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 108.09740365, sen-loss: 29.39573467, dom-loss: 78.70166892, train-acc: 0.90964286, val-acc: 0.88500000 val_loss: 0.29783741, dom-acc: 0.43812500
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 107.66615713, sen-loss: 28.84619471, dom-loss: 78.81996238, train-acc: 0.90946429, val-acc: 0.88500000 val_loss: 0.29744720, dom-acc: 0.43473214
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 106.96192884, sen-loss: 28.25476778, dom-loss: 78.70716077, train-acc: 0.91357143, val-acc: 0.89500000 val_loss: 0.28963205, dom-acc: 0.42616071
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 107.44382083, sen-loss: 28.38117878, dom-loss: 79.06264216, train-acc: 0.91160714, val-acc: 0.88750000 val_loss: 0.29538098, dom-acc: 0.43267857
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 106.31033063, sen-loss: 27.38666023, dom-loss: 78.92367035, train-acc: 0.91732143, val-acc: 0.89500000 val_loss: 0.28548694, dom-acc: 0.43562500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 105.79912859, sen-loss: 27.20544543, dom-loss: 78.59368283, train-acc: 0.91750000, val-acc: 0.90000000 val_loss: 0.28296769, dom-acc: 0.42705357
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 105.10426223, sen-loss: 26.74015556, dom-loss: 78.36410654, train-acc: 0.92035714, val-acc: 0.90000000 val_loss: 0.28200063, dom-acc: 0.42785714
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 104.47186881, sen-loss: 26.17745718, dom-loss: 78.29441184, train-acc: 0.91839286, val-acc: 0.89250000 val_loss: 0.27876297, dom-acc: 0.44000000
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 103.88612902, sen-loss: 25.83152039, dom-loss: 78.05460846, train-acc: 0.92017857, val-acc: 0.89750000 val_loss: 0.28324798, dom-acc: 0.44214286
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 103.49291044, sen-loss: 25.58234794, dom-loss: 77.91056252, train-acc: 0.92339286, val-acc: 0.90250000 val_loss: 0.27820694, dom-acc: 0.44473214
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 102.75493306, sen-loss: 25.10450540, dom-loss: 77.65042752, train-acc: 0.92392857, val-acc: 0.89750000 val_loss: 0.27625719, dom-acc: 0.44705357
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 102.18817157, sen-loss: 24.81627937, dom-loss: 77.37189221, train-acc: 0.92053571, val-acc: 0.90000000 val_loss: 0.28161889, dom-acc: 0.44303571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 101.94077367, sen-loss: 24.55317561, dom-loss: 77.38759828, train-acc: 0.92625000, val-acc: 0.89500000 val_loss: 0.27360877, dom-acc: 0.44937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.05483729, sen-loss: 24.14621267, dom-loss: 76.90862429, train-acc: 0.92375000, val-acc: 0.90250000 val_loss: 0.28305838, dom-acc: 0.44089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.26124603, sen-loss: 23.93917798, dom-loss: 77.32206815, train-acc: 0.92446429, val-acc: 0.90500000 val_loss: 0.28232232, dom-acc: 0.46000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 100.69032067, sen-loss: 23.63078086, dom-loss: 77.05953979, train-acc: 0.92678571, val-acc: 0.90250000 val_loss: 0.28001344, dom-acc: 0.45089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.36704338, sen-loss: 23.41052531, dom-loss: 76.95651799, train-acc: 0.93053571, val-acc: 0.89500000 val_loss: 0.27236488, dom-acc: 0.45982143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 99.96688312, sen-loss: 23.06292102, dom-loss: 76.90396190, train-acc: 0.93125000, val-acc: 0.90500000 val_loss: 0.27569890, dom-acc: 0.46401786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 99.53904641, sen-loss: 22.81022996, dom-loss: 76.72881651, train-acc: 0.93196429, val-acc: 0.90250000 val_loss: 0.27922124, dom-acc: 0.46214286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 98.84202462, sen-loss: 22.42409486, dom-loss: 76.41793031, train-acc: 0.93250000, val-acc: 0.90250000 val_loss: 0.27015796, dom-acc: 0.47464286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 98.47252834, sen-loss: 22.15815008, dom-loss: 76.31437796, train-acc: 0.93267857, val-acc: 0.89250000 val_loss: 0.27046117, dom-acc: 0.48026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 98.45399505, sen-loss: 21.94757234, dom-loss: 76.50642264, train-acc: 0.93625000, val-acc: 0.90250000 val_loss: 0.27618471, dom-acc: 0.48151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 97.80889404, sen-loss: 21.50195447, dom-loss: 76.30693948, train-acc: 0.93035714, val-acc: 0.87750000 val_loss: 0.27384076, dom-acc: 0.49383929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 97.86613059, sen-loss: 21.41395608, dom-loss: 76.45217448, train-acc: 0.93892857, val-acc: 0.89750000 val_loss: 0.27012154, dom-acc: 0.48196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 97.44198430, sen-loss: 20.99633626, dom-loss: 76.44564784, train-acc: 0.93875000, val-acc: 0.90000000 val_loss: 0.27236640, dom-acc: 0.48812500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 96.92012042, sen-loss: 20.54405450, dom-loss: 76.37606597, train-acc: 0.93696429, val-acc: 0.88500000 val_loss: 0.27158335, dom-acc: 0.48437500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 96.78164315, sen-loss: 20.29657830, dom-loss: 76.48506492, train-acc: 0.94142857, val-acc: 0.90000000 val_loss: 0.27753118, dom-acc: 0.47973214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 96.91115457, sen-loss: 20.14015795, dom-loss: 76.77099663, train-acc: 0.94375000, val-acc: 0.90000000 val_loss: 0.27652165, dom-acc: 0.47151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 96.70982081, sen-loss: 19.82351165, dom-loss: 76.88630903, train-acc: 0.94535714, val-acc: 0.90000000 val_loss: 0.27771103, dom-acc: 0.47008929
---------------------------------------------------

Successfully load model from save path: ./work/models/video_electronics_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.27012154
Testing accuracy: 0.83466667
./work/attentions/video_electronics_train.txt
./work/pivots/video_electronics_pos.txt
./work/pivots/video_electronics_neg.txt
./work/attentions/video_electronics_test.txt
loading data...
source domain:  video target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 13856
vocab-size:  78115
max  story size: 104
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
5600 400 6000 36180 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78116, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 159.32281971, sen-loss: 76.74809092, dom-loss: 82.57472903, train-acc: 0.72250000, val-acc: 0.72000000 val_loss: 0.65204102, dom-acc: 0.78687500
---------------------------------------------------

adapt 0.0499583749579 lr 0.00465506222311
Epoch: [2  ] loss: 144.54545784, sen-loss: 69.28513664, dom-loss: 75.26032114, train-acc: 0.73910714, val-acc: 0.70250000 val_loss: 0.58374369, dom-acc: 0.88633929
---------------------------------------------------

adapt 0.099667994625 lr 0.00436097974747
Epoch: [3  ] loss: 132.85538578, sen-loss: 59.48662823, dom-loss: 73.36875802, train-acc: 0.80464286, val-acc: 0.77500000 val_loss: 0.49202043, dom-acc: 0.88473214
---------------------------------------------------

adapt 0.1 lr 0.00410688450912
Epoch: [4  ] loss: 122.61700284, sen-loss: 49.63453555, dom-loss: 72.98246700, train-acc: 0.84678571, val-acc: 0.84000000 val_loss: 0.41542503, dom-acc: 0.82205357
---------------------------------------------------

adapt 0.1 lr 0.0038848475212
Epoch: [5  ] loss: 115.94595039, sen-loss: 42.25473714, dom-loss: 73.69121313, train-acc: 0.86714286, val-acc: 0.85500000 val_loss: 0.36739570, dom-acc: 0.76794643
---------------------------------------------------

adapt 0.1 lr 0.00368893973233
Epoch: [6  ] loss: 111.86083299, sen-loss: 37.12294567, dom-loss: 74.73788679, train-acc: 0.88446429, val-acc: 0.87750000 val_loss: 0.33280951, dom-acc: 0.72821429
---------------------------------------------------

adapt 0.1 lr 0.00351463328244
Epoch: [7  ] loss: 110.45262867, sen-loss: 34.61828579, dom-loss: 75.83434278, train-acc: 0.88107143, val-acc: 0.86750000 val_loss: 0.33004844, dom-acc: 0.70241071
---------------------------------------------------

adapt 0.1 lr 0.00335840689834
Epoch: [8  ] loss: 110.43101025, sen-loss: 33.39894168, dom-loss: 77.03206855, train-acc: 0.89267857, val-acc: 0.87750000 val_loss: 0.31513703, dom-acc: 0.67901786
---------------------------------------------------

adapt 0.1 lr 0.00321747829247
Epoch: [9  ] loss: 110.46166700, sen-loss: 32.51926497, dom-loss: 77.94240206, train-acc: 0.90017857, val-acc: 0.88000000 val_loss: 0.31042102, dom-acc: 0.59553571
---------------------------------------------------

adapt 0.1 lr 0.00308961812091
Epoch: [10 ] loss: 110.18993509, sen-loss: 31.35616079, dom-loss: 78.83377469, train-acc: 0.89946429, val-acc: 0.88750000 val_loss: 0.30408636, dom-acc: 0.56026786
---------------------------------------------------

adapt 0.1 lr 0.00297301778751
Epoch: [11 ] loss: 109.95354533, sen-loss: 30.50773408, dom-loss: 79.44581091, train-acc: 0.90107143, val-acc: 0.89000000 val_loss: 0.30114532, dom-acc: 0.50187500
---------------------------------------------------

adapt 0.1 lr 0.00286619367501
Epoch: [12 ] loss: 110.02710235, sen-loss: 29.99856883, dom-loss: 80.02853352, train-acc: 0.90625000, val-acc: 0.88750000 val_loss: 0.29812613, dom-acc: 0.49401786
---------------------------------------------------

adapt 0.1 lr 0.00276791655825
Epoch: [13 ] loss: 109.49610299, sen-loss: 29.20246061, dom-loss: 80.29364252, train-acc: 0.90892857, val-acc: 0.88500000 val_loss: 0.29730499, dom-acc: 0.46250000
---------------------------------------------------

adapt 0.1 lr 0.00267715876605
Epoch: [14 ] loss: 108.89189190, sen-loss: 28.65995689, dom-loss: 80.23193461, train-acc: 0.91214286, val-acc: 0.88250000 val_loss: 0.29734781, dom-acc: 0.46687500
---------------------------------------------------

adapt 0.1 lr 0.00259305407204
Epoch: [15 ] loss: 108.35276800, sen-loss: 28.11314406, dom-loss: 80.23962396, train-acc: 0.91125000, val-acc: 0.89500000 val_loss: 0.28972065, dom-acc: 0.46901786
---------------------------------------------------

adapt 0.1 lr 0.00251486685937
Epoch: [16 ] loss: 108.12486833, sen-loss: 28.22715931, dom-loss: 79.89770925, train-acc: 0.91232143, val-acc: 0.88750000 val_loss: 0.29448873, dom-acc: 0.48321429
---------------------------------------------------

adapt 0.1 lr 0.00244196813937
Epoch: [17 ] loss: 106.71019906, sen-loss: 27.26578590, dom-loss: 79.44441348, train-acc: 0.91500000, val-acc: 0.89250000 val_loss: 0.28604972, dom-acc: 0.48491071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022
Epoch: [18 ] loss: 106.25010580, sen-loss: 27.11757959, dom-loss: 79.13252640, train-acc: 0.91732143, val-acc: 0.89500000 val_loss: 0.28380248, dom-acc: 0.50187500
---------------------------------------------------

adapt 0.1 lr 0.00230994415646
Epoch: [19 ] loss: 105.11317718, sen-loss: 26.63894003, dom-loss: 78.47423702, train-acc: 0.91821429, val-acc: 0.89750000 val_loss: 0.28249288, dom-acc: 0.51678571
---------------------------------------------------

adapt 0.1 lr 0.00224994294854
Epoch: [20 ] loss: 104.11444402, sen-loss: 26.09587926, dom-loss: 78.01856512, train-acc: 0.91517857, val-acc: 0.89250000 val_loss: 0.28021026, dom-acc: 0.52526786
---------------------------------------------------

adapt 0.1 lr 0.00219345668825
Epoch: [21 ] loss: 103.37530875, sen-loss: 25.75527042, dom-loss: 77.62003857, train-acc: 0.91982143, val-acc: 0.89750000 val_loss: 0.28355056, dom-acc: 0.55348214
---------------------------------------------------

adapt 0.1 lr 0.00214017227647
Epoch: [22 ] loss: 102.80658787, sen-loss: 25.54008301, dom-loss: 77.26650476, train-acc: 0.92339286, val-acc: 0.89750000 val_loss: 0.27962881, dom-acc: 0.52392857
---------------------------------------------------

adapt 0.1 lr 0.00208981345305
Epoch: [23 ] loss: 102.17375809, sen-loss: 25.06170627, dom-loss: 77.11205220, train-acc: 0.92464286, val-acc: 0.89250000 val_loss: 0.27734220, dom-acc: 0.52419643
---------------------------------------------------

adapt 0.1 lr 0.0020421354735
Epoch: [24 ] loss: 101.78442401, sen-loss: 24.77073049, dom-loss: 77.01369303, train-acc: 0.92214286, val-acc: 0.89750000 val_loss: 0.28207952, dom-acc: 0.51205357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 101.46639985, sen-loss: 24.50019577, dom-loss: 76.96620387, train-acc: 0.92571429, val-acc: 0.89000000 val_loss: 0.27479297, dom-acc: 0.51392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.21469772, sen-loss: 24.09806588, dom-loss: 77.11663181, train-acc: 0.92464286, val-acc: 0.89750000 val_loss: 0.28211927, dom-acc: 0.49526786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.11171901, sen-loss: 23.89267864, dom-loss: 77.21904081, train-acc: 0.92410714, val-acc: 0.90250000 val_loss: 0.28271815, dom-acc: 0.51133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.01684785, sen-loss: 23.57647442, dom-loss: 77.44037348, train-acc: 0.92803571, val-acc: 0.89500000 val_loss: 0.27977628, dom-acc: 0.49151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.97175944, sen-loss: 23.35626545, dom-loss: 77.61549383, train-acc: 0.92696429, val-acc: 0.89250000 val_loss: 0.27352625, dom-acc: 0.48750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.54218870, sen-loss: 23.00689980, dom-loss: 77.53528887, train-acc: 0.93196429, val-acc: 0.89250000 val_loss: 0.27514991, dom-acc: 0.47455357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.45859140, sen-loss: 22.75803070, dom-loss: 77.70056069, train-acc: 0.93000000, val-acc: 0.90000000 val_loss: 0.27933714, dom-acc: 0.46964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.01970488, sen-loss: 22.37722430, dom-loss: 77.64248031, train-acc: 0.93214286, val-acc: 0.89000000 val_loss: 0.27086180, dom-acc: 0.47919643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 99.76699281, sen-loss: 22.12082876, dom-loss: 77.64616388, train-acc: 0.93250000, val-acc: 0.89000000 val_loss: 0.27164516, dom-acc: 0.48535714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.49976152, sen-loss: 21.91102535, dom-loss: 77.58873588, train-acc: 0.93625000, val-acc: 0.89500000 val_loss: 0.27560598, dom-acc: 0.48366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.03222144, sen-loss: 21.46992563, dom-loss: 77.56229603, train-acc: 0.93089286, val-acc: 0.88750000 val_loss: 0.27485171, dom-acc: 0.49482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 98.93481380, sen-loss: 21.37245179, dom-loss: 77.56236172, train-acc: 0.93767857, val-acc: 0.88750000 val_loss: 0.27095923, dom-acc: 0.51098214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 98.34119672, sen-loss: 20.93597571, dom-loss: 77.40522110, train-acc: 0.93785714, val-acc: 0.89000000 val_loss: 0.27269509, dom-acc: 0.52125000
---------------------------------------------------

Successfully load model from save path: ./work/models/video_kitchen_PNet.ckpt
Best Epoch: [ 32] best val accuracy: 0.00000000 best val loss: 0.27086180
Testing accuracy: 0.84633333
./work/attentions/video_kitchen_train.txt
./work/pivots/video_kitchen_pos.txt
./work/pivots/video_kitchen_neg.txt
./work/attentions/video_kitchen_test.txt
loading data...
source domain:  books target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 11843
vocab-size:  100530
max  story size: 226
mean story size: 8
max  sentence size: 783
mean sentence size: 19
max memory size: 20
100530
word_embedding done:  100531
5600 400 6000 15750 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(100531, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 156.28133273, sen-loss: 76.63467336, dom-loss: 79.64665973, train-acc: 0.76571429, val-acc: 0.77000000 val_loss: 0.65244049, dom-acc: 0.67830357
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 146.14484441, sen-loss: 69.89169145, dom-loss: 76.25315356, train-acc: 0.77589286, val-acc: 0.75250000 val_loss: 0.58330578, dom-acc: 0.67785714
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 136.50793970, sen-loss: 60.73104703, dom-loss: 75.77689207, train-acc: 0.83196429, val-acc: 0.83250000 val_loss: 0.48634887, dom-acc: 0.61839286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 125.81687677, sen-loss: 50.08047867, dom-loss: 75.73639739, train-acc: 0.86000000, val-acc: 0.85750000 val_loss: 0.39661223, dom-acc: 0.56883929
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 117.41639018, sen-loss: 41.25188009, dom-loss: 76.16450942, train-acc: 0.87250000, val-acc: 0.87000000 val_loss: 0.34595388, dom-acc: 0.59812500
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 112.95476806, sen-loss: 36.85086291, dom-loss: 76.10390532, train-acc: 0.87642857, val-acc: 0.86250000 val_loss: 0.33373284, dom-acc: 0.67267857
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.22507584, sen-loss: 35.29244214, dom-loss: 75.93263364, train-acc: 0.88214286, val-acc: 0.86500000 val_loss: 0.33948717, dom-acc: 0.67062500
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.40213799, sen-loss: 34.24239361, dom-loss: 76.15974414, train-acc: 0.88232143, val-acc: 0.87500000 val_loss: 0.32713574, dom-acc: 0.67250000
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 109.79867011, sen-loss: 33.52661499, dom-loss: 76.27205533, train-acc: 0.88803571, val-acc: 0.87500000 val_loss: 0.32785973, dom-acc: 0.66607143
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 108.82030648, sen-loss: 32.63570373, dom-loss: 76.18460298, train-acc: 0.88857143, val-acc: 0.88000000 val_loss: 0.32158798, dom-acc: 0.66455357
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.94713426, sen-loss: 32.48951387, dom-loss: 76.45762050, train-acc: 0.89089286, val-acc: 0.88250000 val_loss: 0.32193848, dom-acc: 0.66669643
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 108.09773201, sen-loss: 31.67505531, dom-loss: 76.42267692, train-acc: 0.89321429, val-acc: 0.88500000 val_loss: 0.32138315, dom-acc: 0.66687500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 107.64859265, sen-loss: 31.15581214, dom-loss: 76.49278063, train-acc: 0.89125000, val-acc: 0.87250000 val_loss: 0.32840154, dom-acc: 0.66616071
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 107.62389398, sen-loss: 30.89409357, dom-loss: 76.72980028, train-acc: 0.89500000, val-acc: 0.87250000 val_loss: 0.31330165, dom-acc: 0.64303571
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 107.30763859, sen-loss: 30.48562793, dom-loss: 76.82201058, train-acc: 0.89089286, val-acc: 0.87500000 val_loss: 0.33531117, dom-acc: 0.64946429
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.80599129, sen-loss: 29.91934000, dom-loss: 76.88665152, train-acc: 0.90071429, val-acc: 0.89250000 val_loss: 0.31013474, dom-acc: 0.64883929
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 106.73244643, sen-loss: 29.69558674, dom-loss: 77.03686041, train-acc: 0.89910714, val-acc: 0.88000000 val_loss: 0.30901411, dom-acc: 0.65473214
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 106.20495862, sen-loss: 29.16814865, dom-loss: 77.03681022, train-acc: 0.90232143, val-acc: 0.89500000 val_loss: 0.30837277, dom-acc: 0.64428571
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 106.09139627, sen-loss: 28.87822931, dom-loss: 77.21316701, train-acc: 0.90428571, val-acc: 0.89000000 val_loss: 0.30922946, dom-acc: 0.64812500
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 105.91780573, sen-loss: 28.59725832, dom-loss: 77.32054752, train-acc: 0.90517857, val-acc: 0.88750000 val_loss: 0.31260306, dom-acc: 0.64892857
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 105.67122167, sen-loss: 28.32578126, dom-loss: 77.34544039, train-acc: 0.90678571, val-acc: 0.89000000 val_loss: 0.30869302, dom-acc: 0.64839286
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 105.56913525, sen-loss: 28.14229782, dom-loss: 77.42683697, train-acc: 0.90750000, val-acc: 0.89250000 val_loss: 0.30985773, dom-acc: 0.64705357
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 105.17695612, sen-loss: 27.62886592, dom-loss: 77.54809034, train-acc: 0.90857143, val-acc: 0.89000000 val_loss: 0.30841792, dom-acc: 0.64553571
---------------------------------------------------

Successfully load model from save path: ./work/models/books_dvd_PNet.ckpt
Best Epoch: [ 18] best val accuracy: 0.00000000 best val loss: 0.30837277
Testing accuracy: 0.87033333
./work/attentions/books_dvd_train.txt
./work/pivots/books_dvd_pos.txt
./work/pivots/books_dvd_neg.txt
./work/attentions/books_dvd_test.txt
loading data...
source domain:  books target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 17009
vocab-size:  83050
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 18
max memory size: 20
83050
word_embedding done:  83051
5600 400 6000 15750 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83051, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 153.35655820, sen-loss: 76.63379496, dom-loss: 76.72276258, train-acc: 0.76571429, val-acc: 0.77000000 val_loss: 0.65241426, dom-acc: 0.89714286
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.90607440, sen-loss: 69.88640702, dom-loss: 71.01966745, train-acc: 0.77571429, val-acc: 0.75250000 val_loss: 0.58317792, dom-acc: 0.90544643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 130.46996796, sen-loss: 60.71564016, dom-loss: 69.75432760, train-acc: 0.83232143, val-acc: 0.83250000 val_loss: 0.48609090, dom-acc: 0.84071429
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 120.43441415, sen-loss: 50.05527785, dom-loss: 70.37913728, train-acc: 0.85928571, val-acc: 0.85750000 val_loss: 0.39613965, dom-acc: 0.78008929
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 112.84130800, sen-loss: 41.25685278, dom-loss: 71.58445519, train-acc: 0.87160714, val-acc: 0.87000000 val_loss: 0.34574178, dom-acc: 0.84991071
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 109.49409467, sen-loss: 36.90204839, dom-loss: 72.59204638, train-acc: 0.87607143, val-acc: 0.86750000 val_loss: 0.33337396, dom-acc: 0.84723214
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 109.16971129, sen-loss: 35.33685748, dom-loss: 73.83285409, train-acc: 0.88232143, val-acc: 0.86500000 val_loss: 0.33890665, dom-acc: 0.79571429
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 109.66509676, sen-loss: 34.27626982, dom-loss: 75.38882726, train-acc: 0.88196429, val-acc: 0.87250000 val_loss: 0.32648805, dom-acc: 0.70696429
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 110.69405633, sen-loss: 33.55990827, dom-loss: 77.13414872, train-acc: 0.88803571, val-acc: 0.87750000 val_loss: 0.32701427, dom-acc: 0.62660714
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 111.43642575, sen-loss: 32.66341722, dom-loss: 78.77300841, train-acc: 0.88839286, val-acc: 0.88000000 val_loss: 0.32095429, dom-acc: 0.56857143
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 112.67779285, sen-loss: 32.51677701, dom-loss: 80.16101581, train-acc: 0.89107143, val-acc: 0.88500000 val_loss: 0.32114679, dom-acc: 0.51830357
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 112.87278408, sen-loss: 31.69676559, dom-loss: 81.17601836, train-acc: 0.89303571, val-acc: 0.88750000 val_loss: 0.32097709, dom-acc: 0.45821429
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 113.16707379, sen-loss: 31.18298249, dom-loss: 81.98409128, train-acc: 0.89178571, val-acc: 0.87250000 val_loss: 0.32795668, dom-acc: 0.40312500
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 113.24575537, sen-loss: 30.91497891, dom-loss: 82.33077633, train-acc: 0.89410714, val-acc: 0.87500000 val_loss: 0.31269112, dom-acc: 0.35919643
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 112.85793179, sen-loss: 30.51205154, dom-loss: 82.34588045, train-acc: 0.89017857, val-acc: 0.87500000 val_loss: 0.33526143, dom-acc: 0.36223214
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 111.91343224, sen-loss: 29.94477905, dom-loss: 81.96865320, train-acc: 0.90053571, val-acc: 0.89500000 val_loss: 0.30955634, dom-acc: 0.36821429
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 111.26435316, sen-loss: 29.71973293, dom-loss: 81.54462075, train-acc: 0.90000000, val-acc: 0.88000000 val_loss: 0.30830362, dom-acc: 0.33767857
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 109.98622590, sen-loss: 29.19075046, dom-loss: 80.79547572, train-acc: 0.90232143, val-acc: 0.89500000 val_loss: 0.30762309, dom-acc: 0.39776786
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 108.89205295, sen-loss: 28.90441710, dom-loss: 79.98763627, train-acc: 0.90339286, val-acc: 0.89000000 val_loss: 0.30829591, dom-acc: 0.47803571
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 107.95036978, sen-loss: 28.62304155, dom-loss: 79.32732803, train-acc: 0.90464286, val-acc: 0.88750000 val_loss: 0.31162739, dom-acc: 0.53714286
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 106.99635792, sen-loss: 28.35589220, dom-loss: 78.64046586, train-acc: 0.90714286, val-acc: 0.88750000 val_loss: 0.30772752, dom-acc: 0.60062500
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 106.09970498, sen-loss: 28.17620075, dom-loss: 77.92350429, train-acc: 0.90767857, val-acc: 0.89000000 val_loss: 0.30855799, dom-acc: 0.65901786
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 105.00366116, sen-loss: 27.65455323, dom-loss: 77.34910780, train-acc: 0.90892857, val-acc: 0.89000000 val_loss: 0.30709103, dom-acc: 0.69580357
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 104.24570209, sen-loss: 27.29519533, dom-loss: 76.95050645, train-acc: 0.90964286, val-acc: 0.89000000 val_loss: 0.31043485, dom-acc: 0.70776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.84307861, sen-loss: 27.12043847, dom-loss: 76.72264045, train-acc: 0.91000000, val-acc: 0.89000000 val_loss: 0.30649593, dom-acc: 0.72312500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 103.29386830, sen-loss: 26.89231226, dom-loss: 76.40155607, train-acc: 0.91214286, val-acc: 0.89000000 val_loss: 0.30152360, dom-acc: 0.73107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 103.01171023, sen-loss: 26.73506828, dom-loss: 76.27664167, train-acc: 0.91339286, val-acc: 0.89000000 val_loss: 0.30151227, dom-acc: 0.72794643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.64932257, sen-loss: 26.28083077, dom-loss: 76.36849189, train-acc: 0.91125000, val-acc: 0.88500000 val_loss: 0.30298471, dom-acc: 0.72285714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 102.42449975, sen-loss: 26.05152097, dom-loss: 76.37297910, train-acc: 0.91750000, val-acc: 0.89000000 val_loss: 0.30103695, dom-acc: 0.71250000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 102.47789115, sen-loss: 25.84816597, dom-loss: 76.62972522, train-acc: 0.91857143, val-acc: 0.88750000 val_loss: 0.30060157, dom-acc: 0.70276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 102.32115716, sen-loss: 25.55172930, dom-loss: 76.76942778, train-acc: 0.91875000, val-acc: 0.89000000 val_loss: 0.30255836, dom-acc: 0.68276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.38932896, sen-loss: 25.23286440, dom-loss: 77.15646493, train-acc: 0.92053571, val-acc: 0.89000000 val_loss: 0.30064332, dom-acc: 0.65937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.49311715, sen-loss: 25.10466209, dom-loss: 77.38845485, train-acc: 0.92160714, val-acc: 0.88750000 val_loss: 0.30084157, dom-acc: 0.62625000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.68538737, sen-loss: 24.78089353, dom-loss: 77.90449393, train-acc: 0.92250000, val-acc: 0.89000000 val_loss: 0.30153069, dom-acc: 0.60883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 102.87289643, sen-loss: 24.74110772, dom-loss: 78.13178843, train-acc: 0.92250000, val-acc: 0.88750000 val_loss: 0.29949293, dom-acc: 0.58741071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 102.83792150, sen-loss: 24.31681956, dom-loss: 78.52110183, train-acc: 0.92285714, val-acc: 0.88500000 val_loss: 0.30650583, dom-acc: 0.55535714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 102.98541421, sen-loss: 24.20316071, dom-loss: 78.78225321, train-acc: 0.92482143, val-acc: 0.88250000 val_loss: 0.30348524, dom-acc: 0.54133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 102.76947337, sen-loss: 23.81108964, dom-loss: 78.95838386, train-acc: 0.92500000, val-acc: 0.88750000 val_loss: 0.29986125, dom-acc: 0.50642857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 102.91794139, sen-loss: 23.63798928, dom-loss: 79.27995199, train-acc: 0.92625000, val-acc: 0.89000000 val_loss: 0.30050156, dom-acc: 0.47008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 102.69250059, sen-loss: 23.25568715, dom-loss: 79.43681359, train-acc: 0.92785714, val-acc: 0.88250000 val_loss: 0.30297786, dom-acc: 0.48901786
---------------------------------------------------

Successfully load model from save path: ./work/models/books_electronics_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.29949293
Testing accuracy: 0.84366667
./work/attentions/books_electronics_train.txt
./work/pivots/books_electronics_pos.txt
./work/pivots/books_electronics_neg.txt
./work/attentions/books_electronics_test.txt
loading data...
source domain:  books target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 13856
vocab-size:  78006
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 17
max memory size: 20
78006
word_embedding done:  78007
5600 400 6000 15750 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78007, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 152.98876202, sen-loss: 76.63442141, dom-loss: 76.35434037, train-acc: 0.76500000, val-acc: 0.77000000 val_loss: 0.65242052, dom-acc: 0.88928571
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.86219406, sen-loss: 69.88717300, dom-loss: 70.97502065, train-acc: 0.77625000, val-acc: 0.75500000 val_loss: 0.58320981, dom-acc: 0.90062500
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 130.76751184, sen-loss: 60.71894091, dom-loss: 70.04857105, train-acc: 0.83232143, val-acc: 0.83250000 val_loss: 0.48616609, dom-acc: 0.86714286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 120.69124681, sen-loss: 50.06901574, dom-loss: 70.62223125, train-acc: 0.85928571, val-acc: 0.85750000 val_loss: 0.39636874, dom-acc: 0.84705357
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 112.87019694, sen-loss: 41.27554032, dom-loss: 71.59465647, train-acc: 0.87160714, val-acc: 0.87000000 val_loss: 0.34591472, dom-acc: 0.86303571
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 109.21085256, sen-loss: 36.91324213, dom-loss: 72.29760993, train-acc: 0.87642857, val-acc: 0.87000000 val_loss: 0.33338070, dom-acc: 0.80294643
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 108.74448347, sen-loss: 35.34592672, dom-loss: 73.39855707, train-acc: 0.88160714, val-acc: 0.86500000 val_loss: 0.33890787, dom-acc: 0.75598214
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 109.12211567, sen-loss: 34.27006415, dom-loss: 74.85205126, train-acc: 0.88250000, val-acc: 0.87500000 val_loss: 0.32630557, dom-acc: 0.70008929
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 110.10739881, sen-loss: 33.55493486, dom-loss: 76.55246401, train-acc: 0.88785714, val-acc: 0.87750000 val_loss: 0.32677364, dom-acc: 0.66062500
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 110.17295653, sen-loss: 32.65665936, dom-loss: 77.51629716, train-acc: 0.88803571, val-acc: 0.88000000 val_loss: 0.32070595, dom-acc: 0.61187500
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 111.68933558, sen-loss: 32.51475696, dom-loss: 79.17457873, train-acc: 0.89125000, val-acc: 0.88250000 val_loss: 0.32083553, dom-acc: 0.57178571
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 112.12483871, sen-loss: 31.69635366, dom-loss: 80.42848474, train-acc: 0.89232143, val-acc: 0.88250000 val_loss: 0.32069254, dom-acc: 0.53062500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 112.37455922, sen-loss: 31.17259361, dom-loss: 81.20196551, train-acc: 0.89178571, val-acc: 0.87500000 val_loss: 0.32767436, dom-acc: 0.51660714
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 112.75905466, sen-loss: 30.91335408, dom-loss: 81.84570020, train-acc: 0.89464286, val-acc: 0.87500000 val_loss: 0.31211972, dom-acc: 0.48214286
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 112.36515427, sen-loss: 30.50894041, dom-loss: 81.85621393, train-acc: 0.89035714, val-acc: 0.87500000 val_loss: 0.33557230, dom-acc: 0.49080357
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 111.74956590, sen-loss: 29.94710059, dom-loss: 81.80246544, train-acc: 0.90089286, val-acc: 0.89000000 val_loss: 0.30908999, dom-acc: 0.47598214
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 111.07212925, sen-loss: 29.71986984, dom-loss: 81.35225946, train-acc: 0.90053571, val-acc: 0.88250000 val_loss: 0.30756187, dom-acc: 0.49803571
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 109.87241167, sen-loss: 29.18675199, dom-loss: 80.68565977, train-acc: 0.90232143, val-acc: 0.89000000 val_loss: 0.30711716, dom-acc: 0.51383929
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 108.83672094, sen-loss: 28.90082949, dom-loss: 79.93589127, train-acc: 0.90410714, val-acc: 0.88750000 val_loss: 0.30785978, dom-acc: 0.54696429
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 107.69298625, sen-loss: 28.61876915, dom-loss: 79.07421720, train-acc: 0.90321429, val-acc: 0.88750000 val_loss: 0.31103832, dom-acc: 0.57741071
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 106.82719308, sen-loss: 28.35112578, dom-loss: 78.47606701, train-acc: 0.90750000, val-acc: 0.88750000 val_loss: 0.30747220, dom-acc: 0.60955357
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 105.86304301, sen-loss: 28.17812479, dom-loss: 77.68491793, train-acc: 0.90803571, val-acc: 0.89000000 val_loss: 0.30816990, dom-acc: 0.63892857
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 104.70037347, sen-loss: 27.64661486, dom-loss: 77.05375868, train-acc: 0.90857143, val-acc: 0.89000000 val_loss: 0.30681646, dom-acc: 0.66767857
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 103.97528040, sen-loss: 27.28639403, dom-loss: 76.68888670, train-acc: 0.90982143, val-acc: 0.89000000 val_loss: 0.31015852, dom-acc: 0.68491071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.35241008, sen-loss: 27.11745860, dom-loss: 76.23495132, train-acc: 0.91053571, val-acc: 0.89000000 val_loss: 0.30631006, dom-acc: 0.69258929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.98190355, sen-loss: 26.88410024, dom-loss: 76.09780347, train-acc: 0.91250000, val-acc: 0.89000000 val_loss: 0.30116734, dom-acc: 0.69401786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.67947298, sen-loss: 26.72367908, dom-loss: 75.95579422, train-acc: 0.91321429, val-acc: 0.89000000 val_loss: 0.30108935, dom-acc: 0.69410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.29116613, sen-loss: 26.27500296, dom-loss: 76.01616305, train-acc: 0.91160714, val-acc: 0.88500000 val_loss: 0.30241397, dom-acc: 0.67964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 102.10321093, sen-loss: 26.04045621, dom-loss: 76.06275487, train-acc: 0.91785714, val-acc: 0.88750000 val_loss: 0.30067325, dom-acc: 0.68616071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 102.15154058, sen-loss: 25.83347822, dom-loss: 76.31806213, train-acc: 0.91839286, val-acc: 0.88750000 val_loss: 0.30013645, dom-acc: 0.66750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 102.10154539, sen-loss: 25.54308873, dom-loss: 76.55845654, train-acc: 0.91964286, val-acc: 0.89000000 val_loss: 0.30216625, dom-acc: 0.65410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.14490938, sen-loss: 25.22152590, dom-loss: 76.92338330, train-acc: 0.92053571, val-acc: 0.89000000 val_loss: 0.30010265, dom-acc: 0.62883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.49434829, sen-loss: 25.09676441, dom-loss: 77.39758378, train-acc: 0.92071429, val-acc: 0.89000000 val_loss: 0.30028865, dom-acc: 0.61062500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.56388760, sen-loss: 24.76732961, dom-loss: 77.79655814, train-acc: 0.92089286, val-acc: 0.88750000 val_loss: 0.30095410, dom-acc: 0.59366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 102.81732345, sen-loss: 24.73560762, dom-loss: 78.08171570, train-acc: 0.92232143, val-acc: 0.88750000 val_loss: 0.29915029, dom-acc: 0.58357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 102.88675684, sen-loss: 24.30122338, dom-loss: 78.58553368, train-acc: 0.92196429, val-acc: 0.88500000 val_loss: 0.30626315, dom-acc: 0.57625000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 102.93403363, sen-loss: 24.18575561, dom-loss: 78.74827772, train-acc: 0.92607143, val-acc: 0.88250000 val_loss: 0.30292571, dom-acc: 0.56571429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 102.68070108, sen-loss: 23.79906330, dom-loss: 78.88163763, train-acc: 0.92500000, val-acc: 0.89000000 val_loss: 0.29911104, dom-acc: 0.55000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 102.80287778, sen-loss: 23.62313256, dom-loss: 79.17974508, train-acc: 0.92660714, val-acc: 0.88750000 val_loss: 0.29975092, dom-acc: 0.54741071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 102.46088272, sen-loss: 23.24196367, dom-loss: 79.21891898, train-acc: 0.92714286, val-acc: 0.88250000 val_loss: 0.30228987, dom-acc: 0.55705357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 102.23082227, sen-loss: 23.02479590, dom-loss: 79.20602608, train-acc: 0.92964286, val-acc: 0.88250000 val_loss: 0.30000055, dom-acc: 0.54517857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 101.97923803, sen-loss: 22.91345688, dom-loss: 79.06578100, train-acc: 0.92910714, val-acc: 0.87750000 val_loss: 0.30452272, dom-acc: 0.54687500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 101.21242607, sen-loss: 22.50666773, dom-loss: 78.70575809, train-acc: 0.92892857, val-acc: 0.88750000 val_loss: 0.30903950, dom-acc: 0.56875000
---------------------------------------------------

Successfully load model from save path: ./work/models/books_kitchen_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.29911104
Testing accuracy: 0.85550000
./work/attentions/books_kitchen_train.txt
./work/pivots/books_kitchen_pos.txt
./work/pivots/books_kitchen_neg.txt
./work/attentions/books_kitchen_test.txt
loading data...
source domain:  books target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 30180
vocab-size:  98084
max  story size: 189
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
98084
word_embedding done:  98085
5600 400 6000 15750 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(98085, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 156.34039187, sen-loss: 76.63415629, dom-loss: 79.70623517, train-acc: 0.76517857, val-acc: 0.77000000 val_loss: 0.65243375, dom-acc: 0.67964286
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 146.17690587, sen-loss: 69.88859415, dom-loss: 76.28831118, train-acc: 0.77571429, val-acc: 0.75250000 val_loss: 0.58323938, dom-acc: 0.69366071
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 136.63645911, sen-loss: 60.72171697, dom-loss: 75.91474164, train-acc: 0.83178571, val-acc: 0.83250000 val_loss: 0.48626876, dom-acc: 0.64687500
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 125.95355344, sen-loss: 50.07163739, dom-loss: 75.88191622, train-acc: 0.85982143, val-acc: 0.85500000 val_loss: 0.39658254, dom-acc: 0.61214286
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 117.52171201, sen-loss: 41.25450338, dom-loss: 76.26720804, train-acc: 0.87250000, val-acc: 0.87000000 val_loss: 0.34597391, dom-acc: 0.68464286
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 112.88367063, sen-loss: 36.85725331, dom-loss: 76.02641720, train-acc: 0.87607143, val-acc: 0.86250000 val_loss: 0.33378005, dom-acc: 0.71348214
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.28194362, sen-loss: 35.29649743, dom-loss: 75.98544645, train-acc: 0.88267857, val-acc: 0.86500000 val_loss: 0.33955657, dom-acc: 0.70937500
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.38121206, sen-loss: 34.24907073, dom-loss: 76.13214159, train-acc: 0.88196429, val-acc: 0.87500000 val_loss: 0.32719994, dom-acc: 0.69794643
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 109.72192663, sen-loss: 33.53557011, dom-loss: 76.18635595, train-acc: 0.88803571, val-acc: 0.87750000 val_loss: 0.32799470, dom-acc: 0.69044643
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 108.60421717, sen-loss: 32.64587259, dom-loss: 75.95834446, train-acc: 0.88875000, val-acc: 0.88000000 val_loss: 0.32166168, dom-acc: 0.68625000
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.73639315, sen-loss: 32.49638648, dom-loss: 76.24000686, train-acc: 0.89071429, val-acc: 0.88500000 val_loss: 0.32190037, dom-acc: 0.68732143
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 108.08328283, sen-loss: 31.68154453, dom-loss: 76.40173811, train-acc: 0.89303571, val-acc: 0.89000000 val_loss: 0.32132107, dom-acc: 0.68062500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 107.61535281, sen-loss: 31.16355973, dom-loss: 76.45179278, train-acc: 0.89178571, val-acc: 0.87250000 val_loss: 0.32840633, dom-acc: 0.68071429
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 107.58769166, sen-loss: 30.90216042, dom-loss: 76.68553138, train-acc: 0.89500000, val-acc: 0.87250000 val_loss: 0.31324071, dom-acc: 0.67062500
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 107.03680676, sen-loss: 30.49243807, dom-loss: 76.54436851, train-acc: 0.89035714, val-acc: 0.87250000 val_loss: 0.33531240, dom-acc: 0.68169643
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.74891317, sen-loss: 29.92582683, dom-loss: 76.82308644, train-acc: 0.90107143, val-acc: 0.89500000 val_loss: 0.31004494, dom-acc: 0.66098214
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 106.67660517, sen-loss: 29.70205167, dom-loss: 76.97455293, train-acc: 0.89982143, val-acc: 0.88000000 val_loss: 0.30886370, dom-acc: 0.65812500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 106.14040369, sen-loss: 29.17538363, dom-loss: 76.96502024, train-acc: 0.90232143, val-acc: 0.89500000 val_loss: 0.30823335, dom-acc: 0.65642857
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 106.00148684, sen-loss: 28.88487969, dom-loss: 77.11660713, train-acc: 0.90535714, val-acc: 0.89000000 val_loss: 0.30901271, dom-acc: 0.65339286
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 105.78639108, sen-loss: 28.60671308, dom-loss: 77.17967826, train-acc: 0.90535714, val-acc: 0.88750000 val_loss: 0.31243220, dom-acc: 0.65687500
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 105.60220718, sen-loss: 28.33280567, dom-loss: 77.26940173, train-acc: 0.90750000, val-acc: 0.89000000 val_loss: 0.30862251, dom-acc: 0.65696429
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 105.41198701, sen-loss: 28.14992870, dom-loss: 77.26205790, train-acc: 0.90785714, val-acc: 0.89000000 val_loss: 0.30951762, dom-acc: 0.64812500
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 105.13012719, sen-loss: 27.63529450, dom-loss: 77.49483317, train-acc: 0.90910714, val-acc: 0.89000000 val_loss: 0.30814010, dom-acc: 0.64500000
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 104.85098076, sen-loss: 27.28005082, dom-loss: 77.57092983, train-acc: 0.91000000, val-acc: 0.89250000 val_loss: 0.31172028, dom-acc: 0.64767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 104.55511814, sen-loss: 27.10414732, dom-loss: 77.45097077, train-acc: 0.91089286, val-acc: 0.89000000 val_loss: 0.30749074, dom-acc: 0.64026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 104.42165762, sen-loss: 26.88043202, dom-loss: 77.54122549, train-acc: 0.91285714, val-acc: 0.89000000 val_loss: 0.30251661, dom-acc: 0.63196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 104.36341113, sen-loss: 26.72202819, dom-loss: 77.64138311, train-acc: 0.91464286, val-acc: 0.88750000 val_loss: 0.30261156, dom-acc: 0.62428571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 104.02846915, sen-loss: 26.26757056, dom-loss: 77.76089895, train-acc: 0.91160714, val-acc: 0.88500000 val_loss: 0.30398661, dom-acc: 0.62241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 103.70198160, sen-loss: 26.04131766, dom-loss: 77.66066402, train-acc: 0.91750000, val-acc: 0.89250000 val_loss: 0.30191985, dom-acc: 0.62875000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 103.67885727, sen-loss: 25.84394930, dom-loss: 77.83490831, train-acc: 0.91714286, val-acc: 0.89250000 val_loss: 0.30134836, dom-acc: 0.62392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 103.30673200, sen-loss: 25.54130156, dom-loss: 77.76543111, train-acc: 0.91839286, val-acc: 0.89000000 val_loss: 0.30326879, dom-acc: 0.62937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 103.08855474, sen-loss: 25.22206552, dom-loss: 77.86648917, train-acc: 0.91982143, val-acc: 0.89250000 val_loss: 0.30140552, dom-acc: 0.61571429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.86810166, sen-loss: 25.09601701, dom-loss: 77.77208447, train-acc: 0.92142857, val-acc: 0.88750000 val_loss: 0.30154100, dom-acc: 0.61035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.77580845, sen-loss: 24.76839992, dom-loss: 78.00740844, train-acc: 0.92142857, val-acc: 0.89000000 val_loss: 0.30203405, dom-acc: 0.61223214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 102.59872383, sen-loss: 24.72786590, dom-loss: 77.87085801, train-acc: 0.92267857, val-acc: 0.89000000 val_loss: 0.30003065, dom-acc: 0.61973214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 102.20888388, sen-loss: 24.30582698, dom-loss: 77.90305692, train-acc: 0.92232143, val-acc: 0.88250000 val_loss: 0.30710652, dom-acc: 0.62107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 102.10236275, sen-loss: 24.20063096, dom-loss: 77.90173167, train-acc: 0.92535714, val-acc: 0.88500000 val_loss: 0.30380097, dom-acc: 0.62437500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 101.96145284, sen-loss: 23.80826671, dom-loss: 78.15318638, train-acc: 0.92428571, val-acc: 0.88750000 val_loss: 0.30020329, dom-acc: 0.59982143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 101.59023672, sen-loss: 23.63360158, dom-loss: 77.95663494, train-acc: 0.92732143, val-acc: 0.88750000 val_loss: 0.30081943, dom-acc: 0.60803571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 101.31539935, sen-loss: 23.25156364, dom-loss: 78.06383568, train-acc: 0.92875000, val-acc: 0.88500000 val_loss: 0.30308041, dom-acc: 0.61866071
---------------------------------------------------

Successfully load model from save path: ./work/models/books_video_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.30003065
Testing accuracy: 0.87816667
./work/attentions/books_video_train.txt
./work/pivots/books_video_pos.txt
./work/pivots/books_video_neg.txt
./work/attentions/books_video_test.txt
loading data...
source domain:  dvd target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 9750
vocab-size:  100530
max  story size: 226
mean story size: 8
max  sentence size: 783
mean sentence size: 19
max memory size: 20
100530
word_embedding done:  100531
5600 400 6000 17843 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(100531, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 157.88473225, sen-loss: 76.95861536, dom-loss: 80.92611694, train-acc: 0.75482143, val-acc: 0.75500000 val_loss: 0.65731001, dom-acc: 0.62196429
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 148.64806354, sen-loss: 71.18148190, dom-loss: 77.46658182, train-acc: 0.76910714, val-acc: 0.79250000 val_loss: 0.59568924, dom-acc: 0.77294643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 139.51232517, sen-loss: 63.13128683, dom-loss: 76.38103700, train-acc: 0.82035714, val-acc: 0.83250000 val_loss: 0.50309670, dom-acc: 0.79964286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 129.07900047, sen-loss: 53.57855985, dom-loss: 75.50044060, train-acc: 0.84410714, val-acc: 0.86250000 val_loss: 0.40945941, dom-acc: 0.76258929
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 119.60776937, sen-loss: 44.48156387, dom-loss: 75.12620497, train-acc: 0.85053571, val-acc: 0.87500000 val_loss: 0.33992279, dom-acc: 0.72803571
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 113.86680120, sen-loss: 39.05126075, dom-loss: 74.81554025, train-acc: 0.86696429, val-acc: 0.88000000 val_loss: 0.31736088, dom-acc: 0.74151786
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.68652123, sen-loss: 37.16172309, dom-loss: 74.52479786, train-acc: 0.87607143, val-acc: 0.90000000 val_loss: 0.30126476, dom-acc: 0.74080357
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.98214924, sen-loss: 36.41069843, dom-loss: 74.57145035, train-acc: 0.87750000, val-acc: 0.89750000 val_loss: 0.29713842, dom-acc: 0.73500000
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 109.94984365, sen-loss: 35.39354540, dom-loss: 74.55629796, train-acc: 0.88196429, val-acc: 0.90250000 val_loss: 0.29667574, dom-acc: 0.73937500
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 109.34828758, sen-loss: 34.59594880, dom-loss: 74.75233847, train-acc: 0.87464286, val-acc: 0.89750000 val_loss: 0.30813420, dom-acc: 0.73401786
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.71205437, sen-loss: 34.08444229, dom-loss: 74.62761217, train-acc: 0.88214286, val-acc: 0.89750000 val_loss: 0.29645136, dom-acc: 0.73053571
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 108.46753031, sen-loss: 33.62183102, dom-loss: 74.84569913, train-acc: 0.88678571, val-acc: 0.89500000 val_loss: 0.29328069, dom-acc: 0.72750000
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 108.42706525, sen-loss: 33.28180754, dom-loss: 75.14525759, train-acc: 0.87892857, val-acc: 0.89000000 val_loss: 0.31117266, dom-acc: 0.72142857
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 108.02070349, sen-loss: 32.94779785, dom-loss: 75.07290554, train-acc: 0.88857143, val-acc: 0.90000000 val_loss: 0.29314715, dom-acc: 0.71937500
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 107.43336999, sen-loss: 32.29644625, dom-loss: 75.13692385, train-acc: 0.88875000, val-acc: 0.90750000 val_loss: 0.29014295, dom-acc: 0.71651786
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 107.38357663, sen-loss: 31.93848050, dom-loss: 75.44509614, train-acc: 0.89053571, val-acc: 0.90250000 val_loss: 0.28930250, dom-acc: 0.71375000
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 107.17322510, sen-loss: 31.70319031, dom-loss: 75.47003502, train-acc: 0.89285714, val-acc: 0.90500000 val_loss: 0.28893477, dom-acc: 0.71000000
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 106.86740851, sen-loss: 31.28287768, dom-loss: 75.58453059, train-acc: 0.89553571, val-acc: 0.90750000 val_loss: 0.29073122, dom-acc: 0.70651786
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 106.78954118, sen-loss: 30.95787715, dom-loss: 75.83166385, train-acc: 0.89642857, val-acc: 0.90500000 val_loss: 0.28965548, dom-acc: 0.70517857
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 106.59455812, sen-loss: 30.77015685, dom-loss: 75.82440180, train-acc: 0.89125000, val-acc: 0.89000000 val_loss: 0.30051732, dom-acc: 0.70062500
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 106.46980399, sen-loss: 30.43695706, dom-loss: 76.03284705, train-acc: 0.89696429, val-acc: 0.90750000 val_loss: 0.29299304, dom-acc: 0.70098214
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 106.22370869, sen-loss: 30.23301893, dom-loss: 75.99068975, train-acc: 0.89446429, val-acc: 0.88500000 val_loss: 0.30384234, dom-acc: 0.69482143
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_books_PNet.ckpt
Best Epoch: [ 17] best val accuracy: 0.00000000 best val loss: 0.28893477
Testing accuracy: 0.87350000
./work/attentions/dvd_books_train.txt
./work/pivots/dvd_books_pos.txt
./work/pivots/dvd_books_neg.txt
./work/attentions/dvd_books_test.txt
loading data...
source domain:  dvd target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 17009
vocab-size:  85442
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 18
max memory size: 20
85442
word_embedding done:  85443
5600 400 6000 17843 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(85443, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.54160511, sen-loss: 76.95906758, dom-loss: 77.58253789, train-acc: 0.75464286, val-acc: 0.75750000 val_loss: 0.65733904, dom-acc: 0.87500000
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 143.66043067, sen-loss: 71.18561411, dom-loss: 72.47481704, train-acc: 0.76910714, val-acc: 0.79250000 val_loss: 0.59571725, dom-acc: 0.89089286
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 134.34984612, sen-loss: 63.12989292, dom-loss: 71.21995342, train-acc: 0.82053571, val-acc: 0.83500000 val_loss: 0.50283718, dom-acc: 0.85535714
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 125.05489850, sen-loss: 53.53904402, dom-loss: 71.51585388, train-acc: 0.84517857, val-acc: 0.86500000 val_loss: 0.40830067, dom-acc: 0.84053571
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 116.63821173, sen-loss: 44.39170083, dom-loss: 72.24651045, train-acc: 0.85017857, val-acc: 0.87500000 val_loss: 0.33868554, dom-acc: 0.87776786
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 112.23837072, sen-loss: 39.02717292, dom-loss: 73.21119869, train-acc: 0.86642857, val-acc: 0.88250000 val_loss: 0.31711629, dom-acc: 0.83535714
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.55764675, sen-loss: 37.15532938, dom-loss: 74.40231735, train-acc: 0.87660714, val-acc: 0.89750000 val_loss: 0.30105394, dom-acc: 0.76964286
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 112.49145305, sen-loss: 36.40038761, dom-loss: 76.09106523, train-acc: 0.87625000, val-acc: 0.89750000 val_loss: 0.29703483, dom-acc: 0.68357143
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 113.06213021, sen-loss: 35.38063572, dom-loss: 77.68149424, train-acc: 0.88232143, val-acc: 0.90000000 val_loss: 0.29663923, dom-acc: 0.61062500
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 113.98564702, sen-loss: 34.57835318, dom-loss: 79.40729380, train-acc: 0.87446429, val-acc: 0.89750000 val_loss: 0.30834448, dom-acc: 0.54008929
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 114.42286617, sen-loss: 34.06747913, dom-loss: 80.35538679, train-acc: 0.88321429, val-acc: 0.89750000 val_loss: 0.29634070, dom-acc: 0.49142857
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 114.92439067, sen-loss: 33.60296085, dom-loss: 81.32142961, train-acc: 0.88678571, val-acc: 0.89750000 val_loss: 0.29329172, dom-acc: 0.43857143
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 115.18052316, sen-loss: 33.26030011, dom-loss: 81.92022324, train-acc: 0.87857143, val-acc: 0.89000000 val_loss: 0.31142578, dom-acc: 0.39660714
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 114.99591118, sen-loss: 32.93279845, dom-loss: 82.06311226, train-acc: 0.88714286, val-acc: 0.90000000 val_loss: 0.29328778, dom-acc: 0.38375000
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 114.12474263, sen-loss: 32.28264786, dom-loss: 81.84209496, train-acc: 0.88946429, val-acc: 0.90500000 val_loss: 0.28999653, dom-acc: 0.37955357
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 113.24127823, sen-loss: 31.92760048, dom-loss: 81.31367755, train-acc: 0.89017857, val-acc: 0.90000000 val_loss: 0.28924933, dom-acc: 0.41812500
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 112.45865971, sen-loss: 31.68806185, dom-loss: 80.77059799, train-acc: 0.89178571, val-acc: 0.90000000 val_loss: 0.28867969, dom-acc: 0.39794643
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 111.28078604, sen-loss: 31.27048208, dom-loss: 80.01030397, train-acc: 0.89517857, val-acc: 0.90250000 val_loss: 0.29042760, dom-acc: 0.46892857
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 110.31616294, sen-loss: 30.94870722, dom-loss: 79.36745572, train-acc: 0.89660714, val-acc: 0.89750000 val_loss: 0.28917134, dom-acc: 0.51982143
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 109.41029936, sen-loss: 30.75912997, dom-loss: 78.65116918, train-acc: 0.89446429, val-acc: 0.89500000 val_loss: 0.30018786, dom-acc: 0.57991071
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 108.48963827, sen-loss: 30.43193907, dom-loss: 78.05769932, train-acc: 0.89732143, val-acc: 0.90750000 val_loss: 0.29243487, dom-acc: 0.61866071
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 107.70255357, sen-loss: 30.23604379, dom-loss: 77.46650988, train-acc: 0.89410714, val-acc: 0.89000000 val_loss: 0.30361894, dom-acc: 0.65187500
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_electronics_PNet.ckpt
Best Epoch: [ 17] best val accuracy: 0.00000000 best val loss: 0.28867969
Testing accuracy: 0.85000000
./work/attentions/dvd_electronics_train.txt
./work/pivots/dvd_electronics_pos.txt
./work/pivots/dvd_electronics_neg.txt
./work/attentions/dvd_electronics_test.txt
loading data...
source domain:  dvd target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 13856
vocab-size:  80685
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 17
max memory size: 20
80685
word_embedding done:  80686
5600 400 6000 17843 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(80686, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.07819533, sen-loss: 76.95870894, dom-loss: 77.11948740, train-acc: 0.75482143, val-acc: 0.75500000 val_loss: 0.65731168, dom-acc: 0.87910714
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 143.38705945, sen-loss: 71.18202877, dom-loss: 72.20503068, train-acc: 0.76910714, val-acc: 0.79250000 val_loss: 0.59568906, dom-acc: 0.90285714
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 134.13811958, sen-loss: 63.12209976, dom-loss: 71.01601958, train-acc: 0.82125000, val-acc: 0.83250000 val_loss: 0.50291616, dom-acc: 0.89839286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 124.78656876, sen-loss: 53.53380308, dom-loss: 71.25276595, train-acc: 0.84446429, val-acc: 0.86500000 val_loss: 0.40868270, dom-acc: 0.89383929
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 116.05599803, sen-loss: 44.38931334, dom-loss: 71.66668427, train-acc: 0.84982143, val-acc: 0.87500000 val_loss: 0.33924490, dom-acc: 0.81910714
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.54002792, sen-loss: 39.01839268, dom-loss: 72.52163577, train-acc: 0.86678571, val-acc: 0.88250000 val_loss: 0.31723630, dom-acc: 0.78142857
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 110.64976394, sen-loss: 37.15015118, dom-loss: 73.49961275, train-acc: 0.87696429, val-acc: 0.89750000 val_loss: 0.30121472, dom-acc: 0.73241071
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 111.68160248, sen-loss: 36.39356220, dom-loss: 75.28804034, train-acc: 0.87660714, val-acc: 0.89750000 val_loss: 0.29706883, dom-acc: 0.67883929
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 112.23721242, sen-loss: 35.37427418, dom-loss: 76.86293828, train-acc: 0.88178571, val-acc: 0.90000000 val_loss: 0.29653311, dom-acc: 0.64392857
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 112.84496868, sen-loss: 34.57811950, dom-loss: 78.26684922, train-acc: 0.87392857, val-acc: 0.89500000 val_loss: 0.30830646, dom-acc: 0.60812500
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 113.31996709, sen-loss: 34.06512421, dom-loss: 79.25484324, train-acc: 0.88160714, val-acc: 0.89750000 val_loss: 0.29625046, dom-acc: 0.56526786
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 114.27979690, sen-loss: 33.60569729, dom-loss: 80.67409986, train-acc: 0.88696429, val-acc: 0.89750000 val_loss: 0.29341117, dom-acc: 0.52276786
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 114.61506921, sen-loss: 33.26031026, dom-loss: 81.35475910, train-acc: 0.87803571, val-acc: 0.88750000 val_loss: 0.31214970, dom-acc: 0.51553571
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 114.59801519, sen-loss: 32.93686819, dom-loss: 81.66114724, train-acc: 0.88821429, val-acc: 0.89750000 val_loss: 0.29327798, dom-acc: 0.48928571
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 113.90155339, sen-loss: 32.28029831, dom-loss: 81.62125587, train-acc: 0.88964286, val-acc: 0.90250000 val_loss: 0.29026258, dom-acc: 0.47491071
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 113.28384119, sen-loss: 31.93095250, dom-loss: 81.35288835, train-acc: 0.89035714, val-acc: 0.89750000 val_loss: 0.28947490, dom-acc: 0.49044643
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 112.50687027, sen-loss: 31.68723570, dom-loss: 80.81963414, train-acc: 0.89250000, val-acc: 0.90000000 val_loss: 0.28908166, dom-acc: 0.49544643
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 111.33470368, sen-loss: 31.27244207, dom-loss: 80.06226188, train-acc: 0.89607143, val-acc: 0.90750000 val_loss: 0.29103979, dom-acc: 0.52366071
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 110.37102669, sen-loss: 30.94792425, dom-loss: 79.42310244, train-acc: 0.89660714, val-acc: 0.90500000 val_loss: 0.28987199, dom-acc: 0.55732143
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 109.31689095, sen-loss: 30.76234654, dom-loss: 78.55454385, train-acc: 0.89321429, val-acc: 0.89500000 val_loss: 0.30048802, dom-acc: 0.60178571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 108.51965612, sen-loss: 30.43189158, dom-loss: 78.08776486, train-acc: 0.89803571, val-acc: 0.90500000 val_loss: 0.29305679, dom-acc: 0.62125000
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 107.62213618, sen-loss: 30.23264246, dom-loss: 77.38949412, train-acc: 0.89446429, val-acc: 0.88750000 val_loss: 0.30414990, dom-acc: 0.65446429
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_kitchen_PNet.ckpt
Best Epoch: [ 17] best val accuracy: 0.00000000 best val loss: 0.28908166
Testing accuracy: 0.85300000
./work/attentions/dvd_kitchen_train.txt
./work/pivots/dvd_kitchen_pos.txt
./work/pivots/dvd_kitchen_neg.txt
./work/attentions/dvd_kitchen_test.txt
loading data...
source domain:  dvd target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 30180
vocab-size:  91852
max  story size: 226
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
91852
word_embedding done:  91853
5600 400 6000 17843 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(91853, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 158.03327882, sen-loss: 76.95882028, dom-loss: 81.07445824, train-acc: 0.75410714, val-acc: 0.75250000 val_loss: 0.65731931, dom-acc: 0.46392857
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 150.21649265, sen-loss: 71.18242401, dom-loss: 79.03406882, train-acc: 0.76928571, val-acc: 0.79000000 val_loss: 0.59570330, dom-acc: 0.49705357
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 141.99051678, sen-loss: 63.13328972, dom-loss: 78.85722756, train-acc: 0.82053571, val-acc: 0.83250000 val_loss: 0.50312060, dom-acc: 0.59330357
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 131.98472452, sen-loss: 53.58166549, dom-loss: 78.40305871, train-acc: 0.84375000, val-acc: 0.86250000 val_loss: 0.40939847, dom-acc: 0.64723214
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 122.48634285, sen-loss: 44.47412431, dom-loss: 78.01221836, train-acc: 0.85035714, val-acc: 0.87500000 val_loss: 0.33989114, dom-acc: 0.63500000
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 116.72096157, sen-loss: 39.04914661, dom-loss: 77.67181462, train-acc: 0.86803571, val-acc: 0.88000000 val_loss: 0.31718174, dom-acc: 0.65348214
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 114.67657924, sen-loss: 37.16187789, dom-loss: 77.51470143, train-acc: 0.87732143, val-acc: 0.90000000 val_loss: 0.30101714, dom-acc: 0.65714286
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 113.88635731, sen-loss: 36.42089979, dom-loss: 77.46545780, train-acc: 0.87589286, val-acc: 0.89750000 val_loss: 0.29682517, dom-acc: 0.65071429
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 112.63195443, sen-loss: 35.39781082, dom-loss: 77.23414356, train-acc: 0.88214286, val-acc: 0.90000000 val_loss: 0.29643139, dom-acc: 0.65696429
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 111.85072470, sen-loss: 34.59858407, dom-loss: 77.25214076, train-acc: 0.87428571, val-acc: 0.89750000 val_loss: 0.30809605, dom-acc: 0.66803571
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 111.20759165, sen-loss: 34.08445683, dom-loss: 77.12313491, train-acc: 0.88267857, val-acc: 0.90000000 val_loss: 0.29602545, dom-acc: 0.66776786
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 110.72839606, sen-loss: 33.61467510, dom-loss: 77.11372030, train-acc: 0.88785714, val-acc: 0.89750000 val_loss: 0.29290840, dom-acc: 0.66017857
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 110.35209525, sen-loss: 33.27131476, dom-loss: 77.08078086, train-acc: 0.87946429, val-acc: 0.89000000 val_loss: 0.31083378, dom-acc: 0.67535714
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 110.11391705, sen-loss: 32.94135715, dom-loss: 77.17256004, train-acc: 0.88732143, val-acc: 0.90000000 val_loss: 0.29298466, dom-acc: 0.66473214
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.03081518, sen-loss: 32.29609545, dom-loss: 76.73471993, train-acc: 0.88910714, val-acc: 0.90500000 val_loss: 0.29001138, dom-acc: 0.65625000
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 108.88458371, sen-loss: 31.94174876, dom-loss: 76.94283503, train-acc: 0.89196429, val-acc: 0.90250000 val_loss: 0.28924125, dom-acc: 0.66482143
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 108.55059588, sen-loss: 31.70143007, dom-loss: 76.84916592, train-acc: 0.89285714, val-acc: 0.90250000 val_loss: 0.28890663, dom-acc: 0.65812500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 108.18198705, sen-loss: 31.28150080, dom-loss: 76.90048641, train-acc: 0.89553571, val-acc: 0.90500000 val_loss: 0.29063123, dom-acc: 0.66687500
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 107.84393883, sen-loss: 30.96145940, dom-loss: 76.88247943, train-acc: 0.89785714, val-acc: 0.90000000 val_loss: 0.28975564, dom-acc: 0.66285714
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 107.35644960, sen-loss: 30.77647772, dom-loss: 76.57997209, train-acc: 0.89142857, val-acc: 0.89000000 val_loss: 0.30064791, dom-acc: 0.67303571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 107.34863365, sen-loss: 30.44164705, dom-loss: 76.90698647, train-acc: 0.89642857, val-acc: 0.90750000 val_loss: 0.29315373, dom-acc: 0.67008929
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 106.99782223, sen-loss: 30.24732888, dom-loss: 76.75049323, train-acc: 0.89214286, val-acc: 0.89000000 val_loss: 0.30446199, dom-acc: 0.67303571
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_video_PNet.ckpt
Best Epoch: [ 17] best val accuracy: 0.00000000 best val loss: 0.28890663
Testing accuracy: 0.88416667
./work/attentions/dvd_video_train.txt
./work/pivots/dvd_video_pos.txt
./work/pivots/dvd_video_neg.txt
./work/attentions/dvd_video_test.txt
loading data...
source domain:  electronics target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 9750
vocab-size:  83050
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 18
max memory size: 20
83050
word_embedding done:  83051
5600 400 6000 23009 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83051, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.84465182, sen-loss: 75.30518931, dom-loss: 80.53946263, train-acc: 0.78285714, val-acc: 0.81250000 val_loss: 0.62905061, dom-acc: 0.81241071
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 138.92026472, sen-loss: 64.73283848, dom-loss: 74.18742639, train-acc: 0.82053571, val-acc: 0.85500000 val_loss: 0.49968410, dom-acc: 0.80803571
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 123.07996809, sen-loss: 51.73805642, dom-loss: 71.34191185, train-acc: 0.82500000, val-acc: 0.85000000 val_loss: 0.41437352, dom-acc: 0.66517857
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 117.10738462, sen-loss: 46.16435170, dom-loss: 70.94303316, train-acc: 0.83821429, val-acc: 0.87000000 val_loss: 0.36273944, dom-acc: 0.64526786
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 113.31665969, sen-loss: 41.92319052, dom-loss: 71.39346945, train-acc: 0.86000000, val-acc: 0.89000000 val_loss: 0.32510769, dom-acc: 0.64116071
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.04602295, sen-loss: 38.55510721, dom-loss: 72.49091554, train-acc: 0.87267857, val-acc: 0.88250000 val_loss: 0.30247712, dom-acc: 0.65133929
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 109.29270744, sen-loss: 36.01915248, dom-loss: 73.27355534, train-acc: 0.87964286, val-acc: 0.90250000 val_loss: 0.27948168, dom-acc: 0.63875000
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 108.64006823, sen-loss: 34.43836541, dom-loss: 74.20170254, train-acc: 0.88339286, val-acc: 0.91250000 val_loss: 0.26246512, dom-acc: 0.61142857
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 108.82564932, sen-loss: 33.43902005, dom-loss: 75.38662970, train-acc: 0.88642857, val-acc: 0.91250000 val_loss: 0.25499994, dom-acc: 0.59660714
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 108.60717875, sen-loss: 32.29908460, dom-loss: 76.30809438, train-acc: 0.89214286, val-acc: 0.91250000 val_loss: 0.24838118, dom-acc: 0.56383929
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.69410563, sen-loss: 31.56773388, dom-loss: 77.12637180, train-acc: 0.89160714, val-acc: 0.91250000 val_loss: 0.24252410, dom-acc: 0.51133929
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 109.12597710, sen-loss: 30.97919985, dom-loss: 78.14677721, train-acc: 0.89803571, val-acc: 0.91250000 val_loss: 0.24432018, dom-acc: 0.46705357
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 109.19965345, sen-loss: 30.31902274, dom-loss: 78.88063091, train-acc: 0.90142857, val-acc: 0.92000000 val_loss: 0.23681147, dom-acc: 0.43750000
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 109.22171569, sen-loss: 29.67718992, dom-loss: 79.54452592, train-acc: 0.90303571, val-acc: 0.92250000 val_loss: 0.23404045, dom-acc: 0.40035714
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.46250004, sen-loss: 29.34418809, dom-loss: 80.11831194, train-acc: 0.90517857, val-acc: 0.92000000 val_loss: 0.23034707, dom-acc: 0.37446429
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 109.23752505, sen-loss: 28.74690597, dom-loss: 80.49061877, train-acc: 0.89857143, val-acc: 0.91500000 val_loss: 0.23336147, dom-acc: 0.36267857
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 109.07672209, sen-loss: 28.37467285, dom-loss: 80.70204926, train-acc: 0.90750000, val-acc: 0.92250000 val_loss: 0.22680610, dom-acc: 0.34223214
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 108.62962478, sen-loss: 27.79625162, dom-loss: 80.83337325, train-acc: 0.90642857, val-acc: 0.91750000 val_loss: 0.23856637, dom-acc: 0.33205357
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 108.29542857, sen-loss: 27.62347370, dom-loss: 80.67195463, train-acc: 0.90982143, val-acc: 0.92750000 val_loss: 0.22317776, dom-acc: 0.33464286
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 107.52974206, sen-loss: 27.15739650, dom-loss: 80.37234551, train-acc: 0.91017857, val-acc: 0.92750000 val_loss: 0.22242555, dom-acc: 0.34982143
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 107.03615636, sen-loss: 26.66795567, dom-loss: 80.36820096, train-acc: 0.91178571, val-acc: 0.93000000 val_loss: 0.22064222, dom-acc: 0.37223214
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 106.31845874, sen-loss: 26.46700669, dom-loss: 79.85145241, train-acc: 0.91357143, val-acc: 0.92250000 val_loss: 0.22173038, dom-acc: 0.37473214
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 105.91537315, sen-loss: 26.24980482, dom-loss: 79.66556829, train-acc: 0.91428571, val-acc: 0.93000000 val_loss: 0.21754418, dom-acc: 0.40392857
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 104.88842791, sen-loss: 25.77921127, dom-loss: 79.10921663, train-acc: 0.91625000, val-acc: 0.92500000 val_loss: 0.22120066, dom-acc: 0.42848214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 104.21083260, sen-loss: 25.38217124, dom-loss: 78.82866150, train-acc: 0.91910714, val-acc: 0.93250000 val_loss: 0.21673456, dom-acc: 0.46026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 103.53596836, sen-loss: 25.08171443, dom-loss: 78.45425385, train-acc: 0.91892857, val-acc: 0.93500000 val_loss: 0.21537496, dom-acc: 0.47901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.81458586, sen-loss: 24.78700968, dom-loss: 78.02757561, train-acc: 0.91964286, val-acc: 0.92750000 val_loss: 0.21403754, dom-acc: 0.48785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.17880100, sen-loss: 24.56183582, dom-loss: 77.61696512, train-acc: 0.92214286, val-acc: 0.93250000 val_loss: 0.21550150, dom-acc: 0.49562500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.91142642, sen-loss: 24.36003508, dom-loss: 77.55139136, train-acc: 0.92125000, val-acc: 0.92750000 val_loss: 0.21268350, dom-acc: 0.52750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.25934970, sen-loss: 24.05891968, dom-loss: 77.20043015, train-acc: 0.92410714, val-acc: 0.93000000 val_loss: 0.21480800, dom-acc: 0.53419643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.66318852, sen-loss: 23.69520453, dom-loss: 76.96798426, train-acc: 0.92642857, val-acc: 0.93000000 val_loss: 0.21416646, dom-acc: 0.52241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.49643326, sen-loss: 23.47846831, dom-loss: 77.01796472, train-acc: 0.92553571, val-acc: 0.93000000 val_loss: 0.21750711, dom-acc: 0.55267857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 99.97296715, sen-loss: 23.23619623, dom-loss: 76.73677129, train-acc: 0.92714286, val-acc: 0.92750000 val_loss: 0.21305081, dom-acc: 0.53330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.89737099, sen-loss: 23.02981876, dom-loss: 76.86755168, train-acc: 0.92928571, val-acc: 0.92750000 val_loss: 0.21190389, dom-acc: 0.58089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.54185873, sen-loss: 22.70534226, dom-loss: 76.83651650, train-acc: 0.93035714, val-acc: 0.93000000 val_loss: 0.21120647, dom-acc: 0.56241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.49329370, sen-loss: 22.70749951, dom-loss: 76.78579414, train-acc: 0.93017857, val-acc: 0.92500000 val_loss: 0.21190873, dom-acc: 0.53946429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.11471832, sen-loss: 22.30150729, dom-loss: 76.81321102, train-acc: 0.93089286, val-acc: 0.92500000 val_loss: 0.21146581, dom-acc: 0.50151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.21923786, sen-loss: 22.10734171, dom-loss: 77.11189598, train-acc: 0.93250000, val-acc: 0.92500000 val_loss: 0.21186937, dom-acc: 0.53125000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 98.94496125, sen-loss: 21.85136714, dom-loss: 77.09359413, train-acc: 0.93321429, val-acc: 0.92500000 val_loss: 0.21202093, dom-acc: 0.52580357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.69735223, sen-loss: 21.44496655, dom-loss: 77.25238597, train-acc: 0.93535714, val-acc: 0.92500000 val_loss: 0.21463384, dom-acc: 0.52705357
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_books_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.21120647
Testing accuracy: 0.83166667
./work/attentions/electronics_books_train.txt
./work/pivots/electronics_books_pos.txt
./work/pivots/electronics_books_neg.txt
./work/attentions/electronics_books_test.txt
loading data...
source domain:  electronics target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 11843
vocab-size:  85442
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 18
max memory size: 20
85442
word_embedding done:  85443
5600 400 6000 23009 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(85443, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.68767464, sen-loss: 75.30501258, dom-loss: 80.38266116, train-acc: 0.78303571, val-acc: 0.81250000 val_loss: 0.62904048, dom-acc: 0.77035714
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 139.60858130, sen-loss: 64.73086813, dom-loss: 74.87771326, train-acc: 0.82017857, val-acc: 0.85500000 val_loss: 0.49966881, dom-acc: 0.75285714
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 124.13859403, sen-loss: 51.75065604, dom-loss: 72.38793802, train-acc: 0.82517857, val-acc: 0.85250000 val_loss: 0.41462323, dom-acc: 0.63107143
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 118.08295709, sen-loss: 46.22572461, dom-loss: 71.85723227, train-acc: 0.83785714, val-acc: 0.87000000 val_loss: 0.36335796, dom-acc: 0.61473214
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 113.90249556, sen-loss: 42.01086992, dom-loss: 71.89162546, train-acc: 0.85910714, val-acc: 0.89000000 val_loss: 0.32588747, dom-acc: 0.60348214
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.56754595, sen-loss: 38.64733464, dom-loss: 72.92021143, train-acc: 0.87285714, val-acc: 0.87750000 val_loss: 0.30319199, dom-acc: 0.59660714
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 109.68107092, sen-loss: 36.09362902, dom-loss: 73.58744156, train-acc: 0.87964286, val-acc: 0.89750000 val_loss: 0.27994132, dom-acc: 0.58303571
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 108.85518700, sen-loss: 34.48952608, dom-loss: 74.36566097, train-acc: 0.88267857, val-acc: 0.91250000 val_loss: 0.26290300, dom-acc: 0.56723214
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 108.96736604, sen-loss: 33.47595720, dom-loss: 75.49140882, train-acc: 0.88625000, val-acc: 0.91250000 val_loss: 0.25538978, dom-acc: 0.53839286
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 108.72968549, sen-loss: 32.32679228, dom-loss: 76.40289319, train-acc: 0.89178571, val-acc: 0.91250000 val_loss: 0.24875087, dom-acc: 0.51187500
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.75185621, sen-loss: 31.58608481, dom-loss: 77.16577077, train-acc: 0.89267857, val-acc: 0.90750000 val_loss: 0.24293585, dom-acc: 0.48473214
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 109.01205790, sen-loss: 30.99566196, dom-loss: 78.01639611, train-acc: 0.89821429, val-acc: 0.91250000 val_loss: 0.24472299, dom-acc: 0.44741071
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 109.21505427, sen-loss: 30.33780611, dom-loss: 78.87724811, train-acc: 0.90196429, val-acc: 0.91500000 val_loss: 0.23715855, dom-acc: 0.43169643
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 109.07524610, sen-loss: 29.69031010, dom-loss: 79.38493603, train-acc: 0.90321429, val-acc: 0.92000000 val_loss: 0.23452733, dom-acc: 0.39821429
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.04505426, sen-loss: 29.35567297, dom-loss: 79.68938124, train-acc: 0.90500000, val-acc: 0.92000000 val_loss: 0.23089267, dom-acc: 0.38875000
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 108.67372221, sen-loss: 28.75414961, dom-loss: 79.91957253, train-acc: 0.89910714, val-acc: 0.91250000 val_loss: 0.23390315, dom-acc: 0.39910714
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 108.50463104, sen-loss: 28.37919170, dom-loss: 80.12543941, train-acc: 0.90732143, val-acc: 0.92250000 val_loss: 0.22727093, dom-acc: 0.37812500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 107.96638620, sen-loss: 27.80432556, dom-loss: 80.16205996, train-acc: 0.90589286, val-acc: 0.91500000 val_loss: 0.23863445, dom-acc: 0.36125000
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 107.46250701, sen-loss: 27.62884990, dom-loss: 79.83365691, train-acc: 0.91071429, val-acc: 0.92750000 val_loss: 0.22357310, dom-acc: 0.38250000
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 106.77381474, sen-loss: 27.16211282, dom-loss: 79.61170226, train-acc: 0.91035714, val-acc: 0.92500000 val_loss: 0.22278671, dom-acc: 0.39687500
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 105.95421731, sen-loss: 26.67504976, dom-loss: 79.27916759, train-acc: 0.91178571, val-acc: 0.92750000 val_loss: 0.22080016, dom-acc: 0.41946429
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 105.27444232, sen-loss: 26.47272671, dom-loss: 78.80171555, train-acc: 0.91517857, val-acc: 0.92000000 val_loss: 0.22173396, dom-acc: 0.42535714
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 104.93588674, sen-loss: 26.24986127, dom-loss: 78.68602562, train-acc: 0.91464286, val-acc: 0.93000000 val_loss: 0.21771049, dom-acc: 0.44562500
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 103.95651567, sen-loss: 25.78148466, dom-loss: 78.17503113, train-acc: 0.91589286, val-acc: 0.92500000 val_loss: 0.22139269, dom-acc: 0.45321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.39586157, sen-loss: 25.38733277, dom-loss: 78.00852895, train-acc: 0.91821429, val-acc: 0.93000000 val_loss: 0.21662256, dom-acc: 0.47991071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.68616676, sen-loss: 25.08756103, dom-loss: 77.59860575, train-acc: 0.91946429, val-acc: 0.93250000 val_loss: 0.21521924, dom-acc: 0.49035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.06874710, sen-loss: 24.79220971, dom-loss: 77.27653748, train-acc: 0.91785714, val-acc: 0.92750000 val_loss: 0.21381773, dom-acc: 0.49714286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.57925731, sen-loss: 24.56783692, dom-loss: 77.01142049, train-acc: 0.92267857, val-acc: 0.93000000 val_loss: 0.21508692, dom-acc: 0.51214286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.28101641, sen-loss: 24.36793686, dom-loss: 76.91307932, train-acc: 0.92142857, val-acc: 0.92750000 val_loss: 0.21234915, dom-acc: 0.51241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.77001500, sen-loss: 24.07089791, dom-loss: 76.69911700, train-acc: 0.92428571, val-acc: 0.92750000 val_loss: 0.21427637, dom-acc: 0.50276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.36105812, sen-loss: 23.70262410, dom-loss: 76.65843379, train-acc: 0.92642857, val-acc: 0.93250000 val_loss: 0.21386534, dom-acc: 0.51214286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.37827384, sen-loss: 23.49164297, dom-loss: 76.88663083, train-acc: 0.92553571, val-acc: 0.93000000 val_loss: 0.21685159, dom-acc: 0.53803571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 99.81799519, sen-loss: 23.24301430, dom-loss: 76.57498074, train-acc: 0.92589286, val-acc: 0.92750000 val_loss: 0.21236055, dom-acc: 0.52428571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.77802855, sen-loss: 23.03918789, dom-loss: 76.73884082, train-acc: 0.92964286, val-acc: 0.92750000 val_loss: 0.21121171, dom-acc: 0.52544643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.63580269, sen-loss: 22.71365763, dom-loss: 76.92214543, train-acc: 0.93053571, val-acc: 0.92250000 val_loss: 0.21051832, dom-acc: 0.51785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.67813593, sen-loss: 22.71844578, dom-loss: 76.95969063, train-acc: 0.93071429, val-acc: 0.92250000 val_loss: 0.21105075, dom-acc: 0.51169643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.22831392, sen-loss: 22.30707318, dom-loss: 76.92124093, train-acc: 0.93232143, val-acc: 0.92250000 val_loss: 0.21052113, dom-acc: 0.48723214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.56529933, sen-loss: 22.11583083, dom-loss: 77.44946820, train-acc: 0.93321429, val-acc: 0.92500000 val_loss: 0.21097673, dom-acc: 0.48839286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 99.18534267, sen-loss: 21.86221697, dom-loss: 77.32312506, train-acc: 0.93321429, val-acc: 0.92500000 val_loss: 0.21108116, dom-acc: 0.49250000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 99.12605661, sen-loss: 21.45482953, dom-loss: 77.67122728, train-acc: 0.93571429, val-acc: 0.92500000 val_loss: 0.21364786, dom-acc: 0.47857143
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_dvd_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.21051832
Testing accuracy: 0.83450000
./work/attentions/electronics_dvd_train.txt
./work/pivots/electronics_dvd_pos.txt
./work/pivots/electronics_dvd_neg.txt
./work/attentions/electronics_dvd_test.txt
loading data...
source domain:  electronics target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 13856
vocab-size:  49470
max  story size: 129
mean story size: 6
max  sentence size: 440
mean sentence size: 15
max memory size: 20
49470
word_embedding done:  49471
5600 400 6000 23009 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(49471, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.65628457, sen-loss: 75.30404645, dom-loss: 79.35223800, train-acc: 0.78267857, val-acc: 0.81250000 val_loss: 0.62900537, dom-acc: 0.74062500
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.85938644, sen-loss: 64.72115791, dom-loss: 76.13822818, train-acc: 0.82017857, val-acc: 0.85500000 val_loss: 0.49936816, dom-acc: 0.80642857
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 127.04518378, sen-loss: 51.72594601, dom-loss: 75.31923807, train-acc: 0.82392857, val-acc: 0.85250000 val_loss: 0.41462022, dom-acc: 0.77544643
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 121.20034671, sen-loss: 46.19373453, dom-loss: 75.00661176, train-acc: 0.83678571, val-acc: 0.87000000 val_loss: 0.36331722, dom-acc: 0.75401786
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 117.04972690, sen-loss: 41.97689453, dom-loss: 75.07283252, train-acc: 0.85892857, val-acc: 0.89000000 val_loss: 0.32572839, dom-acc: 0.75250000
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 113.65144992, sen-loss: 38.60677229, dom-loss: 75.04467803, train-acc: 0.87232143, val-acc: 0.88250000 val_loss: 0.30277288, dom-acc: 0.74696429
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.17880189, sen-loss: 36.05801480, dom-loss: 75.12078679, train-acc: 0.87910714, val-acc: 0.90750000 val_loss: 0.27973595, dom-acc: 0.72910714
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 109.90331805, sen-loss: 34.46305878, dom-loss: 75.44025928, train-acc: 0.88232143, val-acc: 0.91250000 val_loss: 0.26237595, dom-acc: 0.72366071
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 108.96452373, sen-loss: 33.45980768, dom-loss: 75.50471598, train-acc: 0.88714286, val-acc: 0.91750000 val_loss: 0.25471810, dom-acc: 0.72008929
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 107.78364724, sen-loss: 32.32943278, dom-loss: 75.45421433, train-acc: 0.89142857, val-acc: 0.91750000 val_loss: 0.24798635, dom-acc: 0.70839286
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 107.41983086, sen-loss: 31.59834763, dom-loss: 75.82148236, train-acc: 0.89142857, val-acc: 0.91750000 val_loss: 0.24202871, dom-acc: 0.70330357
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 106.89771497, sen-loss: 31.01064038, dom-loss: 75.88707447, train-acc: 0.89857143, val-acc: 0.91500000 val_loss: 0.24353714, dom-acc: 0.71053571
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 106.44291216, sen-loss: 30.35182297, dom-loss: 76.09108889, train-acc: 0.90232143, val-acc: 0.92000000 val_loss: 0.23628940, dom-acc: 0.69946429
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 105.88877398, sen-loss: 29.71476578, dom-loss: 76.17400861, train-acc: 0.90375000, val-acc: 0.92000000 val_loss: 0.23355715, dom-acc: 0.69321429
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 105.93891895, sen-loss: 29.38514285, dom-loss: 76.55377597, train-acc: 0.90392857, val-acc: 0.92250000 val_loss: 0.22989640, dom-acc: 0.68625000
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 105.65251559, sen-loss: 28.79202150, dom-loss: 76.86049384, train-acc: 0.89750000, val-acc: 0.91500000 val_loss: 0.23291734, dom-acc: 0.66696429
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.32039660, sen-loss: 28.41644800, dom-loss: 76.90394855, train-acc: 0.90660714, val-acc: 0.92500000 val_loss: 0.22633386, dom-acc: 0.67937500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 104.74821514, sen-loss: 27.84387198, dom-loss: 76.90434331, train-acc: 0.90571429, val-acc: 0.91750000 val_loss: 0.23827790, dom-acc: 0.68848214
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 104.90841371, sen-loss: 27.67269227, dom-loss: 77.23572183, train-acc: 0.90964286, val-acc: 0.93000000 val_loss: 0.22291569, dom-acc: 0.65437500
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 104.50432199, sen-loss: 27.21050113, dom-loss: 77.29382074, train-acc: 0.91035714, val-acc: 0.92750000 val_loss: 0.22208865, dom-acc: 0.66232143
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 104.00248408, sen-loss: 26.72144338, dom-loss: 77.28104055, train-acc: 0.91160714, val-acc: 0.93250000 val_loss: 0.22032759, dom-acc: 0.66312500
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 104.11365998, sen-loss: 26.52301657, dom-loss: 77.59064281, train-acc: 0.91428571, val-acc: 0.93500000 val_loss: 0.22139323, dom-acc: 0.66285714
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 103.88385087, sen-loss: 26.30252495, dom-loss: 77.58132613, train-acc: 0.91321429, val-acc: 0.93250000 val_loss: 0.21750383, dom-acc: 0.64776786
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 103.56941909, sen-loss: 25.83924706, dom-loss: 77.73017216, train-acc: 0.91446429, val-acc: 0.93000000 val_loss: 0.22091898, dom-acc: 0.65839286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.94017404, sen-loss: 25.44539887, dom-loss: 77.49477541, train-acc: 0.91821429, val-acc: 0.93000000 val_loss: 0.21651334, dom-acc: 0.65410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.76864201, sen-loss: 25.14614224, dom-loss: 77.62250006, train-acc: 0.91839286, val-acc: 0.93250000 val_loss: 0.21524251, dom-acc: 0.65044643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.63284528, sen-loss: 24.86209218, dom-loss: 77.77075309, train-acc: 0.91750000, val-acc: 0.93000000 val_loss: 0.21390896, dom-acc: 0.64232143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.67900556, sen-loss: 24.62892154, dom-loss: 78.05008411, train-acc: 0.92267857, val-acc: 0.93750000 val_loss: 0.21520935, dom-acc: 0.64410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 102.27418947, sen-loss: 24.43323849, dom-loss: 77.84095103, train-acc: 0.92035714, val-acc: 0.92750000 val_loss: 0.21272482, dom-acc: 0.64419643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.81847620, sen-loss: 24.13014475, dom-loss: 77.68833172, train-acc: 0.92428571, val-acc: 0.93250000 val_loss: 0.21453446, dom-acc: 0.63830357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 101.69100416, sen-loss: 23.77756425, dom-loss: 77.91344035, train-acc: 0.92642857, val-acc: 0.93500000 val_loss: 0.21406022, dom-acc: 0.64000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 101.17361945, sen-loss: 23.56141715, dom-loss: 77.61220264, train-acc: 0.92339286, val-acc: 0.92750000 val_loss: 0.21739222, dom-acc: 0.65392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.19837087, sen-loss: 23.31894979, dom-loss: 77.87942100, train-acc: 0.92642857, val-acc: 0.92750000 val_loss: 0.21286874, dom-acc: 0.63357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.63947487, sen-loss: 23.10715330, dom-loss: 77.53232145, train-acc: 0.92875000, val-acc: 0.92750000 val_loss: 0.21169470, dom-acc: 0.65232143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.45391673, sen-loss: 22.79454379, dom-loss: 77.65937293, train-acc: 0.93017857, val-acc: 0.92750000 val_loss: 0.21095107, dom-acc: 0.64419643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.55773085, sen-loss: 22.80559281, dom-loss: 77.75213796, train-acc: 0.92875000, val-acc: 0.92750000 val_loss: 0.21172872, dom-acc: 0.63133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.14927232, sen-loss: 22.39399874, dom-loss: 77.75527364, train-acc: 0.92982143, val-acc: 0.92750000 val_loss: 0.21121591, dom-acc: 0.61937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.62886697, sen-loss: 22.20592461, dom-loss: 77.42294228, train-acc: 0.93339286, val-acc: 0.92750000 val_loss: 0.21144894, dom-acc: 0.64687500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 99.41302574, sen-loss: 21.94430666, dom-loss: 77.46871907, train-acc: 0.93142857, val-acc: 0.92750000 val_loss: 0.21154989, dom-acc: 0.64160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.97385097, sen-loss: 21.54935706, dom-loss: 77.42449403, train-acc: 0.93410714, val-acc: 0.92500000 val_loss: 0.21398836, dom-acc: 0.65348214
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_kitchen_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.21095107
Testing accuracy: 0.90333333
./work/attentions/electronics_kitchen_train.txt
./work/pivots/electronics_kitchen_pos.txt
./work/pivots/electronics_kitchen_neg.txt
./work/attentions/electronics_kitchen_test.txt
loading data...
source domain:  electronics target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 30180
vocab-size:  83059
max  story size: 129
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
83059
word_embedding done:  83060
5600 400 6000 23009 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83060, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.55719364, sen-loss: 75.30517220, dom-loss: 80.25202197, train-acc: 0.78214286, val-acc: 0.81250000 val_loss: 0.62902749, dom-acc: 0.80651786
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 139.14320278, sen-loss: 64.72986388, dom-loss: 74.41333908, train-acc: 0.82000000, val-acc: 0.85500000 val_loss: 0.49960116, dom-acc: 0.79562500
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 123.67787230, sen-loss: 51.75314009, dom-loss: 71.92473185, train-acc: 0.82517857, val-acc: 0.85250000 val_loss: 0.41462088, dom-acc: 0.65883929
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 117.47519344, sen-loss: 46.22651854, dom-loss: 71.24867535, train-acc: 0.83732143, val-acc: 0.87000000 val_loss: 0.36344153, dom-acc: 0.63366071
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 113.47553581, sen-loss: 42.01147653, dom-loss: 71.46405947, train-acc: 0.85875000, val-acc: 0.89000000 val_loss: 0.32584143, dom-acc: 0.61848214
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.61884689, sen-loss: 38.64370123, dom-loss: 72.97514570, train-acc: 0.87285714, val-acc: 0.87750000 val_loss: 0.30315852, dom-acc: 0.61241071
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 109.88729799, sen-loss: 36.09352148, dom-loss: 73.79377627, train-acc: 0.87982143, val-acc: 0.89750000 val_loss: 0.27983996, dom-acc: 0.59080357
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 109.44085902, sen-loss: 34.49298617, dom-loss: 74.94787312, train-acc: 0.88303571, val-acc: 0.91250000 val_loss: 0.26288247, dom-acc: 0.56187500
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 109.85624170, sen-loss: 33.47870815, dom-loss: 76.37753338, train-acc: 0.88660714, val-acc: 0.91250000 val_loss: 0.25535938, dom-acc: 0.53562500
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 109.72994995, sen-loss: 32.32905459, dom-loss: 77.40089542, train-acc: 0.89196429, val-acc: 0.91250000 val_loss: 0.24869798, dom-acc: 0.50008929
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 109.90508318, sen-loss: 31.59216325, dom-loss: 78.31292021, train-acc: 0.89214286, val-acc: 0.90750000 val_loss: 0.24291565, dom-acc: 0.46285714
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 110.12649906, sen-loss: 31.00256733, dom-loss: 79.12393171, train-acc: 0.89803571, val-acc: 0.91250000 val_loss: 0.24471012, dom-acc: 0.40937500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 110.31346399, sen-loss: 30.34477602, dom-loss: 79.96868879, train-acc: 0.90196429, val-acc: 0.92000000 val_loss: 0.23714705, dom-acc: 0.39205357
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 110.04952943, sen-loss: 29.69890943, dom-loss: 80.35062027, train-acc: 0.90321429, val-acc: 0.91750000 val_loss: 0.23445792, dom-acc: 0.37160714
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.96159405, sen-loss: 29.36203194, dom-loss: 80.59956193, train-acc: 0.90482143, val-acc: 0.92000000 val_loss: 0.23089901, dom-acc: 0.36026786
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 109.25342262, sen-loss: 28.76230756, dom-loss: 80.49111474, train-acc: 0.89910714, val-acc: 0.91250000 val_loss: 0.23385583, dom-acc: 0.38571429
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 108.73898411, sen-loss: 28.38838285, dom-loss: 80.35060155, train-acc: 0.90714286, val-acc: 0.92250000 val_loss: 0.22728491, dom-acc: 0.37491071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 107.98201776, sen-loss: 27.81451359, dom-loss: 80.16750383, train-acc: 0.90535714, val-acc: 0.91500000 val_loss: 0.23881981, dom-acc: 0.37741071
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 107.21385640, sen-loss: 27.64047973, dom-loss: 79.57337689, train-acc: 0.91071429, val-acc: 0.92750000 val_loss: 0.22367026, dom-acc: 0.39553571
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 106.22798890, sen-loss: 27.17208791, dom-loss: 79.05590105, train-acc: 0.91000000, val-acc: 0.92500000 val_loss: 0.22293074, dom-acc: 0.42803571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 105.36168367, sen-loss: 26.68491759, dom-loss: 78.67676610, train-acc: 0.91160714, val-acc: 0.92500000 val_loss: 0.22093363, dom-acc: 0.45500000
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 104.55006731, sen-loss: 26.48108991, dom-loss: 78.06897759, train-acc: 0.91482143, val-acc: 0.92250000 val_loss: 0.22186053, dom-acc: 0.46660714
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 104.12683374, sen-loss: 26.25811953, dom-loss: 77.86871439, train-acc: 0.91464286, val-acc: 0.93250000 val_loss: 0.21785080, dom-acc: 0.48098214
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 103.10292667, sen-loss: 25.79145059, dom-loss: 77.31147587, train-acc: 0.91589286, val-acc: 0.92500000 val_loss: 0.22156969, dom-acc: 0.49446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.64369297, sen-loss: 25.39468560, dom-loss: 77.24900746, train-acc: 0.91750000, val-acc: 0.93250000 val_loss: 0.21684246, dom-acc: 0.51142857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.05846155, sen-loss: 25.09578463, dom-loss: 76.96267682, train-acc: 0.91964286, val-acc: 0.93250000 val_loss: 0.21540384, dom-acc: 0.52517857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.56050205, sen-loss: 24.80014944, dom-loss: 76.76035219, train-acc: 0.91839286, val-acc: 0.92750000 val_loss: 0.21408300, dom-acc: 0.52500000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.08583868, sen-loss: 24.57352718, dom-loss: 76.51231164, train-acc: 0.92321429, val-acc: 0.93000000 val_loss: 0.21537760, dom-acc: 0.53125000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.13389051, sen-loss: 24.37656359, dom-loss: 76.75732708, train-acc: 0.92125000, val-acc: 0.92750000 val_loss: 0.21264239, dom-acc: 0.54071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.76681352, sen-loss: 24.07806976, dom-loss: 76.68874389, train-acc: 0.92410714, val-acc: 0.93000000 val_loss: 0.21465278, dom-acc: 0.52812500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.33890265, sen-loss: 23.71177573, dom-loss: 76.62712705, train-acc: 0.92625000, val-acc: 0.93250000 val_loss: 0.21413124, dom-acc: 0.51901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.46968096, sen-loss: 23.50121967, dom-loss: 76.96846116, train-acc: 0.92500000, val-acc: 0.93000000 val_loss: 0.21728171, dom-acc: 0.53241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.12919080, sen-loss: 23.25304537, dom-loss: 76.87614536, train-acc: 0.92678571, val-acc: 0.92750000 val_loss: 0.21274364, dom-acc: 0.51160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.29489726, sen-loss: 23.04822252, dom-loss: 77.24667484, train-acc: 0.92875000, val-acc: 0.92500000 val_loss: 0.21165958, dom-acc: 0.52553571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.14816594, sen-loss: 22.71917997, dom-loss: 77.42898619, train-acc: 0.93089286, val-acc: 0.92250000 val_loss: 0.21105608, dom-acc: 0.50687500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.37566388, sen-loss: 22.72554801, dom-loss: 77.65011555, train-acc: 0.93053571, val-acc: 0.92250000 val_loss: 0.21166423, dom-acc: 0.48553571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.10394114, sen-loss: 22.31591028, dom-loss: 77.78803110, train-acc: 0.93178571, val-acc: 0.92250000 val_loss: 0.21121278, dom-acc: 0.46758929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.10153735, sen-loss: 22.12413108, dom-loss: 77.97740626, train-acc: 0.93285714, val-acc: 0.92250000 val_loss: 0.21168607, dom-acc: 0.45241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.10420877, sen-loss: 21.86844160, dom-loss: 78.23576736, train-acc: 0.93214286, val-acc: 0.92500000 val_loss: 0.21187779, dom-acc: 0.46142857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 99.71765786, sen-loss: 21.45743483, dom-loss: 78.26022327, train-acc: 0.93589286, val-acc: 0.92500000 val_loss: 0.21438691, dom-acc: 0.44473214
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_video_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.21105608
Testing accuracy: 0.83900000
./work/attentions/electronics_video_train.txt
./work/pivots/electronics_video_pos.txt
./work/pivots/electronics_video_neg.txt
./work/attentions/electronics_video_test.txt
loading data...
source domain:  kitchen target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 9750
vocab-size:  78006
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 17
max memory size: 20
78006
word_embedding done:  78007
5600 400 6000 19856 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78007, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.69235933, sen-loss: 74.68498003, dom-loss: 81.00737947, train-acc: 0.81107143, val-acc: 0.83000000 val_loss: 0.61627740, dom-acc: 0.77705357
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 137.20855796, sen-loss: 62.68009761, dom-loss: 74.52846020, train-acc: 0.84500000, val-acc: 0.84500000 val_loss: 0.48021832, dom-acc: 0.78419643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 119.51506054, sen-loss: 48.01962185, dom-loss: 71.49543887, train-acc: 0.85125000, val-acc: 0.84750000 val_loss: 0.38572648, dom-acc: 0.65875000
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 112.40607905, sen-loss: 41.37914616, dom-loss: 71.02693301, train-acc: 0.86660714, val-acc: 0.85750000 val_loss: 0.34635207, dom-acc: 0.65625000
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 108.63213557, sen-loss: 37.27742589, dom-loss: 71.35471010, train-acc: 0.87767857, val-acc: 0.87250000 val_loss: 0.32088026, dom-acc: 0.67678571
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 106.27952296, sen-loss: 34.03003889, dom-loss: 72.24948442, train-acc: 0.89321429, val-acc: 0.89750000 val_loss: 0.31128103, dom-acc: 0.68437500
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 104.86333025, sen-loss: 31.80286755, dom-loss: 73.06046259, train-acc: 0.89696429, val-acc: 0.89500000 val_loss: 0.30059987, dom-acc: 0.64366071
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 104.71277994, sen-loss: 30.48570536, dom-loss: 74.22707456, train-acc: 0.90035714, val-acc: 0.90000000 val_loss: 0.30044964, dom-acc: 0.62794643
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 104.79807395, sen-loss: 29.47225612, dom-loss: 75.32581764, train-acc: 0.90089286, val-acc: 0.91000000 val_loss: 0.28790641, dom-acc: 0.58678571
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 105.12581474, sen-loss: 28.62321821, dom-loss: 76.50259620, train-acc: 0.90464286, val-acc: 0.90750000 val_loss: 0.29895803, dom-acc: 0.57267857
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 105.43577713, sen-loss: 28.05822144, dom-loss: 77.37755561, train-acc: 0.90678571, val-acc: 0.91750000 val_loss: 0.29230559, dom-acc: 0.49026786
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 105.93047196, sen-loss: 27.50795773, dom-loss: 78.42251474, train-acc: 0.90946429, val-acc: 0.91500000 val_loss: 0.28412890, dom-acc: 0.44776786
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 106.03293437, sen-loss: 26.86886197, dom-loss: 79.16407174, train-acc: 0.91178571, val-acc: 0.91750000 val_loss: 0.28356490, dom-acc: 0.40544643
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 106.36249465, sen-loss: 26.60521721, dom-loss: 79.75727767, train-acc: 0.91303571, val-acc: 0.92750000 val_loss: 0.28792208, dom-acc: 0.37089286
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 106.33021110, sen-loss: 26.15774682, dom-loss: 80.17246473, train-acc: 0.91410714, val-acc: 0.92250000 val_loss: 0.27905425, dom-acc: 0.35080357
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.31240422, sen-loss: 25.77288887, dom-loss: 80.53951490, train-acc: 0.91446429, val-acc: 0.92250000 val_loss: 0.27502784, dom-acc: 0.33517857
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 106.22843105, sen-loss: 25.43159079, dom-loss: 80.79684067, train-acc: 0.91714286, val-acc: 0.92500000 val_loss: 0.28859723, dom-acc: 0.31375000
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 105.76297992, sen-loss: 25.13656232, dom-loss: 80.62641764, train-acc: 0.91785714, val-acc: 0.92500000 val_loss: 0.28511167, dom-acc: 0.32705357
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 105.27565390, sen-loss: 24.82079482, dom-loss: 80.45485920, train-acc: 0.92017857, val-acc: 0.92500000 val_loss: 0.27381232, dom-acc: 0.34294643
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 104.88218457, sen-loss: 24.61457472, dom-loss: 80.26761013, train-acc: 0.92000000, val-acc: 0.92500000 val_loss: 0.28206691, dom-acc: 0.34366071
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 104.30823064, sen-loss: 24.29240326, dom-loss: 80.01582766, train-acc: 0.92017857, val-acc: 0.92750000 val_loss: 0.27912697, dom-acc: 0.35803571
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 103.67271119, sen-loss: 24.02831539, dom-loss: 79.64439601, train-acc: 0.92125000, val-acc: 0.92000000 val_loss: 0.28887483, dom-acc: 0.36705357
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 102.87748706, sen-loss: 23.63987966, dom-loss: 79.23760736, train-acc: 0.92303571, val-acc: 0.92750000 val_loss: 0.27845615, dom-acc: 0.40151786
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 102.16593319, sen-loss: 23.41477270, dom-loss: 78.75116020, train-acc: 0.92410714, val-acc: 0.92750000 val_loss: 0.27718106, dom-acc: 0.42062500
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_books_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27381232
Testing accuracy: 0.83933333
./work/attentions/kitchen_books_train.txt
./work/pivots/kitchen_books_pos.txt
./work/pivots/kitchen_books_neg.txt
./work/attentions/kitchen_books_test.txt
loading data...
source domain:  kitchen target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 11843
vocab-size:  80685
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 17
max memory size: 20
80685
word_embedding done:  80686
5600 400 6000 19856 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(80686, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.42822456, sen-loss: 74.68355167, dom-loss: 80.74467236, train-acc: 0.81125000, val-acc: 0.83000000 val_loss: 0.61625725, dom-acc: 0.75937500
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 137.48676455, sen-loss: 62.67451340, dom-loss: 74.81225222, train-acc: 0.84500000, val-acc: 0.84500000 val_loss: 0.48020908, dom-acc: 0.74044643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 120.24360049, sen-loss: 48.02864343, dom-loss: 72.21495646, train-acc: 0.85053571, val-acc: 0.84500000 val_loss: 0.38615456, dom-acc: 0.62330357
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 113.22022998, sen-loss: 41.42560573, dom-loss: 71.79462439, train-acc: 0.86553571, val-acc: 0.85750000 val_loss: 0.34693703, dom-acc: 0.61214286
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 109.23481792, sen-loss: 37.34199499, dom-loss: 71.89282274, train-acc: 0.87696429, val-acc: 0.87250000 val_loss: 0.32129750, dom-acc: 0.61142857
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 106.96597594, sen-loss: 34.09163254, dom-loss: 72.87434292, train-acc: 0.89357143, val-acc: 0.89750000 val_loss: 0.31151626, dom-acc: 0.60464286
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 105.40084291, sen-loss: 31.86533433, dom-loss: 73.53550899, train-acc: 0.89642857, val-acc: 0.89750000 val_loss: 0.30073559, dom-acc: 0.58044643
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 105.23531771, sen-loss: 30.54217540, dom-loss: 74.69314235, train-acc: 0.90071429, val-acc: 0.90500000 val_loss: 0.30009574, dom-acc: 0.56142857
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 105.16230118, sen-loss: 29.52111278, dom-loss: 75.64118838, train-acc: 0.90142857, val-acc: 0.91250000 val_loss: 0.28754869, dom-acc: 0.52794643
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 105.51483768, sen-loss: 28.66498228, dom-loss: 76.84985566, train-acc: 0.90428571, val-acc: 0.91250000 val_loss: 0.29873598, dom-acc: 0.49321429
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 105.56894058, sen-loss: 28.10069227, dom-loss: 77.46824837, train-acc: 0.90660714, val-acc: 0.91500000 val_loss: 0.29160860, dom-acc: 0.46241071
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 105.99212909, sen-loss: 27.55014643, dom-loss: 78.44198316, train-acc: 0.90910714, val-acc: 0.91250000 val_loss: 0.28352943, dom-acc: 0.43714286
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 105.95317334, sen-loss: 26.90810597, dom-loss: 79.04506767, train-acc: 0.91071429, val-acc: 0.92000000 val_loss: 0.28294435, dom-acc: 0.42026786
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 106.04018611, sen-loss: 26.64644337, dom-loss: 79.39374280, train-acc: 0.91196429, val-acc: 0.92750000 val_loss: 0.28746578, dom-acc: 0.39133929
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 105.68048590, sen-loss: 26.19570858, dom-loss: 79.48477709, train-acc: 0.91339286, val-acc: 0.92500000 val_loss: 0.27822518, dom-acc: 0.39767857
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 105.65552330, sen-loss: 25.81423520, dom-loss: 79.84128791, train-acc: 0.91482143, val-acc: 0.92000000 val_loss: 0.27432430, dom-acc: 0.39848214
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.41117668, sen-loss: 25.47847068, dom-loss: 79.93270642, train-acc: 0.91571429, val-acc: 0.92750000 val_loss: 0.28766283, dom-acc: 0.37991071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 104.68163180, sen-loss: 25.17316779, dom-loss: 79.50846422, train-acc: 0.91767857, val-acc: 0.92750000 val_loss: 0.28465608, dom-acc: 0.38955357
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 104.13052022, sen-loss: 24.86022536, dom-loss: 79.27029520, train-acc: 0.91982143, val-acc: 0.93000000 val_loss: 0.27315131, dom-acc: 0.41330357
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 103.88255095, sen-loss: 24.65535232, dom-loss: 79.22719890, train-acc: 0.92017857, val-acc: 0.92500000 val_loss: 0.28179210, dom-acc: 0.41071429
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 103.01891100, sen-loss: 24.33737696, dom-loss: 78.68153405, train-acc: 0.92053571, val-acc: 0.92750000 val_loss: 0.27856201, dom-acc: 0.42267857
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 102.53431588, sen-loss: 24.07432511, dom-loss: 78.45999038, train-acc: 0.92071429, val-acc: 0.92500000 val_loss: 0.28833601, dom-acc: 0.42651786
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 101.82910740, sen-loss: 23.68680882, dom-loss: 78.14229858, train-acc: 0.92303571, val-acc: 0.92750000 val_loss: 0.27817047, dom-acc: 0.45000000
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 101.17080212, sen-loss: 23.46267933, dom-loss: 77.70812297, train-acc: 0.92410714, val-acc: 0.92750000 val_loss: 0.27690342, dom-acc: 0.45553571
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_dvd_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27315131
Testing accuracy: 0.84350000
./work/attentions/kitchen_dvd_train.txt
./work/pivots/kitchen_dvd_pos.txt
./work/pivots/kitchen_dvd_neg.txt
./work/attentions/kitchen_dvd_test.txt
loading data...
source domain:  kitchen target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 17009
vocab-size:  49470
max  story size: 129
mean story size: 6
max  sentence size: 440
mean sentence size: 15
max memory size: 20
49470
word_embedding done:  49471
5600 400 6000 19856 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(49471, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.02560520, sen-loss: 74.68324089, dom-loss: 80.34236407, train-acc: 0.81089286, val-acc: 0.83000000 val_loss: 0.61624092, dom-acc: 0.65642857
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 139.54327273, sen-loss: 62.66540810, dom-loss: 76.87786412, train-acc: 0.84464286, val-acc: 0.84500000 val_loss: 0.47991905, dom-acc: 0.61598214
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 124.01972115, sen-loss: 47.99949631, dom-loss: 76.02022451, train-acc: 0.85035714, val-acc: 0.84500000 val_loss: 0.38571647, dom-acc: 0.57375000
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 117.12718415, sen-loss: 41.39606935, dom-loss: 75.73111486, train-acc: 0.86571429, val-acc: 0.85500000 val_loss: 0.34630412, dom-acc: 0.63678571
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 112.89999545, sen-loss: 37.29443392, dom-loss: 75.60556191, train-acc: 0.87750000, val-acc: 0.87000000 val_loss: 0.32067266, dom-acc: 0.69008929
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 109.67086095, sen-loss: 34.03295541, dom-loss: 75.63790572, train-acc: 0.89303571, val-acc: 0.89750000 val_loss: 0.31101015, dom-acc: 0.67107143
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 107.63027823, sen-loss: 31.79499507, dom-loss: 75.83528304, train-acc: 0.89714286, val-acc: 0.89750000 val_loss: 0.29994509, dom-acc: 0.70026786
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 106.28391701, sen-loss: 30.46883417, dom-loss: 75.81508321, train-acc: 0.90125000, val-acc: 0.90250000 val_loss: 0.29999849, dom-acc: 0.69053571
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 105.47703648, sen-loss: 29.44793500, dom-loss: 76.02910161, train-acc: 0.90107143, val-acc: 0.91250000 val_loss: 0.28734684, dom-acc: 0.67500000
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 104.69850761, sen-loss: 28.59886137, dom-loss: 76.09964639, train-acc: 0.90464286, val-acc: 0.90750000 val_loss: 0.29852179, dom-acc: 0.69946429
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 104.35717899, sen-loss: 28.03854553, dom-loss: 76.31863296, train-acc: 0.90767857, val-acc: 0.91250000 val_loss: 0.29187444, dom-acc: 0.69178571
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 103.90645778, sen-loss: 27.48783563, dom-loss: 76.41862214, train-acc: 0.90946429, val-acc: 0.91750000 val_loss: 0.28373292, dom-acc: 0.69107143
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 103.42606217, sen-loss: 26.84964881, dom-loss: 76.57641315, train-acc: 0.91142857, val-acc: 0.92000000 val_loss: 0.28309897, dom-acc: 0.66339286
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 103.34014988, sen-loss: 26.58965669, dom-loss: 76.75049311, train-acc: 0.91321429, val-acc: 0.92750000 val_loss: 0.28761607, dom-acc: 0.66107143
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 103.05669755, sen-loss: 26.14074097, dom-loss: 76.91595674, train-acc: 0.91375000, val-acc: 0.92500000 val_loss: 0.27858531, dom-acc: 0.66169643
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 102.83130586, sen-loss: 25.76168155, dom-loss: 77.06962448, train-acc: 0.91517857, val-acc: 0.92000000 val_loss: 0.27456301, dom-acc: 0.67000000
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 102.59699422, sen-loss: 25.41597549, dom-loss: 77.18101865, train-acc: 0.91678571, val-acc: 0.92000000 val_loss: 0.28835383, dom-acc: 0.64839286
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 102.45560092, sen-loss: 25.12480605, dom-loss: 77.33079451, train-acc: 0.91803571, val-acc: 0.92250000 val_loss: 0.28482506, dom-acc: 0.63964286
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 102.35490865, sen-loss: 24.80974776, dom-loss: 77.54516053, train-acc: 0.92035714, val-acc: 0.93000000 val_loss: 0.27347672, dom-acc: 0.64535714
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 102.13522053, sen-loss: 24.60499117, dom-loss: 77.53022903, train-acc: 0.91982143, val-acc: 0.93000000 val_loss: 0.28176510, dom-acc: 0.63553571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 101.97142881, sen-loss: 24.28713384, dom-loss: 77.68429506, train-acc: 0.92035714, val-acc: 0.92750000 val_loss: 0.27864280, dom-acc: 0.60160714
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 101.85163587, sen-loss: 24.01974881, dom-loss: 77.83188725, train-acc: 0.92178571, val-acc: 0.91750000 val_loss: 0.28832415, dom-acc: 0.59008929
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 101.53300607, sen-loss: 23.63807780, dom-loss: 77.89492834, train-acc: 0.92196429, val-acc: 0.92500000 val_loss: 0.27803022, dom-acc: 0.61535714
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 101.44110715, sen-loss: 23.40992466, dom-loss: 78.03118277, train-acc: 0.92321429, val-acc: 0.92750000 val_loss: 0.27647164, dom-acc: 0.57017857
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_electronics_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27347672
Testing accuracy: 0.88283333
./work/attentions/kitchen_electronics_train.txt
./work/pivots/kitchen_electronics_pos.txt
./work/pivots/kitchen_electronics_neg.txt
./work/attentions/kitchen_electronics_test.txt
loading data...
source domain:  kitchen target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 30180
vocab-size:  78115
max  story size: 104
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
78115
word_embedding done:  78116
5600 400 6000 19856 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78116, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.23726439, sen-loss: 74.68301427, dom-loss: 80.55425042, train-acc: 0.81107143, val-acc: 0.83000000 val_loss: 0.61623043, dom-acc: 0.80678571
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 136.94386518, sen-loss: 62.66893721, dom-loss: 74.27492756, train-acc: 0.84500000, val-acc: 0.84500000 val_loss: 0.48001748, dom-acc: 0.78196429
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 119.60163373, sen-loss: 48.01975575, dom-loss: 71.58187860, train-acc: 0.85035714, val-acc: 0.84500000 val_loss: 0.38587987, dom-acc: 0.64883929
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 112.65489185, sen-loss: 41.42240116, dom-loss: 71.23249054, train-acc: 0.86607143, val-acc: 0.85750000 val_loss: 0.34667015, dom-acc: 0.63660714
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 108.86196327, sen-loss: 37.33725858, dom-loss: 71.52470499, train-acc: 0.87696429, val-acc: 0.87250000 val_loss: 0.32113808, dom-acc: 0.63125000
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 107.01113379, sen-loss: 34.09038465, dom-loss: 72.92074949, train-acc: 0.89321429, val-acc: 0.89750000 val_loss: 0.31143343, dom-acc: 0.62500000
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 105.67861599, sen-loss: 31.86673661, dom-loss: 73.81187946, train-acc: 0.89660714, val-acc: 0.89750000 val_loss: 0.30072507, dom-acc: 0.58491071
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 105.85727781, sen-loss: 30.54441145, dom-loss: 75.31286627, train-acc: 0.90071429, val-acc: 0.90500000 val_loss: 0.30013186, dom-acc: 0.54946429
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 106.19035459, sen-loss: 29.52319723, dom-loss: 76.66715759, train-acc: 0.90142857, val-acc: 0.91250000 val_loss: 0.28753519, dom-acc: 0.51714286
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 106.63352025, sen-loss: 28.66982721, dom-loss: 77.96369314, train-acc: 0.90428571, val-acc: 0.91000000 val_loss: 0.29881075, dom-acc: 0.47714286
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 106.81397623, sen-loss: 28.10331565, dom-loss: 78.71066022, train-acc: 0.90696429, val-acc: 0.91500000 val_loss: 0.29170540, dom-acc: 0.43258929
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 107.13417536, sen-loss: 27.55097078, dom-loss: 79.58320493, train-acc: 0.90910714, val-acc: 0.91250000 val_loss: 0.28365880, dom-acc: 0.39187500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 107.04868907, sen-loss: 26.90938916, dom-loss: 80.13930011, train-acc: 0.91160714, val-acc: 0.92000000 val_loss: 0.28316140, dom-acc: 0.38473214
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 106.94802868, sen-loss: 26.64711067, dom-loss: 80.30091763, train-acc: 0.91196429, val-acc: 0.92750000 val_loss: 0.28755397, dom-acc: 0.37535714
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 106.54887962, sen-loss: 26.19553861, dom-loss: 80.35334116, train-acc: 0.91321429, val-acc: 0.92500000 val_loss: 0.27840710, dom-acc: 0.38383929
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.04620457, sen-loss: 25.81340999, dom-loss: 80.23279434, train-acc: 0.91446429, val-acc: 0.92000000 val_loss: 0.27455378, dom-acc: 0.38687500
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.50503629, sen-loss: 25.47857475, dom-loss: 80.02646154, train-acc: 0.91571429, val-acc: 0.92750000 val_loss: 0.28790167, dom-acc: 0.38125000
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 104.57989377, sen-loss: 25.17375768, dom-loss: 79.40613645, train-acc: 0.91732143, val-acc: 0.92750000 val_loss: 0.28486121, dom-acc: 0.40973214
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 103.75202000, sen-loss: 24.86068106, dom-loss: 78.89133865, train-acc: 0.92053571, val-acc: 0.93000000 val_loss: 0.27332842, dom-acc: 0.42973214
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 103.29939246, sen-loss: 24.65581964, dom-loss: 78.64357263, train-acc: 0.92000000, val-acc: 0.92500000 val_loss: 0.28187239, dom-acc: 0.44678571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 102.43085909, sen-loss: 24.33924930, dom-loss: 78.09160972, train-acc: 0.92071429, val-acc: 0.92750000 val_loss: 0.27870920, dom-acc: 0.46151786
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 101.83305883, sen-loss: 24.07610741, dom-loss: 77.75695157, train-acc: 0.92035714, val-acc: 0.92500000 val_loss: 0.28840628, dom-acc: 0.46214286
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 101.14518869, sen-loss: 23.68760498, dom-loss: 77.45758367, train-acc: 0.92392857, val-acc: 0.93000000 val_loss: 0.27826682, dom-acc: 0.48214286
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 100.43792546, sen-loss: 23.46586522, dom-loss: 76.97206038, train-acc: 0.92482143, val-acc: 0.93000000 val_loss: 0.27692464, dom-acc: 0.48616071
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_video_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27332842
Testing accuracy: 0.84183333
./work/attentions/kitchen_video_train.txt
./work/pivots/kitchen_video_pos.txt
./work/pivots/kitchen_video_neg.txt
./work/attentions/kitchen_video_test.txt
loading data...
source domain:  video target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 9750
vocab-size:  98084
max  story size: 189
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
98084
word_embedding done:  98085
5600 400 6000 36180 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(98085, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 157.19344306, sen-loss: 76.31692302, dom-loss: 80.87652057, train-acc: 0.75607143, val-acc: 0.75750000 val_loss: 0.64893889, dom-acc: 0.57446429
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 146.44974148, sen-loss: 68.89134216, dom-loss: 77.55839920, train-acc: 0.79017857, val-acc: 0.80500000 val_loss: 0.57296383, dom-acc: 0.69473214
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 135.70826328, sen-loss: 59.07349470, dom-loss: 76.63476825, train-acc: 0.81553571, val-acc: 0.79500000 val_loss: 0.47924647, dom-acc: 0.78187500
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 125.37153292, sen-loss: 49.29854149, dom-loss: 76.07299113, train-acc: 0.84267857, val-acc: 0.81750000 val_loss: 0.40851992, dom-acc: 0.81276786
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 118.11219794, sen-loss: 42.24147552, dom-loss: 75.87072235, train-acc: 0.85750000, val-acc: 0.84250000 val_loss: 0.36150512, dom-acc: 0.78651786
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 113.30139905, sen-loss: 37.56677029, dom-loss: 75.73462880, train-acc: 0.87857143, val-acc: 0.87000000 val_loss: 0.34379911, dom-acc: 0.79151786
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 110.32947719, sen-loss: 34.79369871, dom-loss: 75.53577846, train-acc: 0.88875000, val-acc: 0.87500000 val_loss: 0.33203095, dom-acc: 0.77482143
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 108.84051204, sen-loss: 33.33817150, dom-loss: 75.50234032, train-acc: 0.89678571, val-acc: 0.88750000 val_loss: 0.31948444, dom-acc: 0.76330357
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 107.79465711, sen-loss: 32.18102378, dom-loss: 75.61363328, train-acc: 0.88750000, val-acc: 0.87500000 val_loss: 0.33489156, dom-acc: 0.73839286
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 106.90353256, sen-loss: 31.31259796, dom-loss: 75.59093505, train-acc: 0.90178571, val-acc: 0.88500000 val_loss: 0.31025052, dom-acc: 0.73616071
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 106.43513411, sen-loss: 30.73258062, dom-loss: 75.70255369, train-acc: 0.90535714, val-acc: 0.89000000 val_loss: 0.31029287, dom-acc: 0.72205357
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 105.78001475, sen-loss: 30.01648352, dom-loss: 75.76353145, train-acc: 0.90910714, val-acc: 0.89250000 val_loss: 0.30711144, dom-acc: 0.70741071
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 105.51702321, sen-loss: 29.50740559, dom-loss: 76.00961757, train-acc: 0.91125000, val-acc: 0.89500000 val_loss: 0.30513194, dom-acc: 0.69678571
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 104.64307028, sen-loss: 28.69011122, dom-loss: 75.95295930, train-acc: 0.91339286, val-acc: 0.89500000 val_loss: 0.30253342, dom-acc: 0.69589286
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 104.89836675, sen-loss: 28.59696326, dom-loss: 76.30140364, train-acc: 0.90410714, val-acc: 0.89000000 val_loss: 0.32353547, dom-acc: 0.68616071
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 104.57041138, sen-loss: 28.15164176, dom-loss: 76.41876960, train-acc: 0.91517857, val-acc: 0.89250000 val_loss: 0.29664817, dom-acc: 0.67312500
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 103.75061184, sen-loss: 27.44998548, dom-loss: 76.30062675, train-acc: 0.91892857, val-acc: 0.89750000 val_loss: 0.30200461, dom-acc: 0.67455357
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 103.75147152, sen-loss: 27.22996484, dom-loss: 76.52150667, train-acc: 0.91732143, val-acc: 0.88750000 val_loss: 0.29438826, dom-acc: 0.66553571
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 103.31386882, sen-loss: 26.55288647, dom-loss: 76.76098198, train-acc: 0.92196429, val-acc: 0.89750000 val_loss: 0.29397935, dom-acc: 0.66419643
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 103.09020597, sen-loss: 26.39918203, dom-loss: 76.69102401, train-acc: 0.92303571, val-acc: 0.90000000 val_loss: 0.29561093, dom-acc: 0.65812500
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 102.88497269, sen-loss: 25.97338565, dom-loss: 76.91158700, train-acc: 0.92446429, val-acc: 0.89500000 val_loss: 0.29471636, dom-acc: 0.65785714
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 102.82142055, sen-loss: 25.72690873, dom-loss: 77.09451163, train-acc: 0.92053571, val-acc: 0.89250000 val_loss: 0.30156347, dom-acc: 0.64973214
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 102.56427073, sen-loss: 25.25849372, dom-loss: 77.30577719, train-acc: 0.92500000, val-acc: 0.89750000 val_loss: 0.29440358, dom-acc: 0.63794643
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 102.17560494, sen-loss: 24.89641239, dom-loss: 77.27919281, train-acc: 0.92535714, val-acc: 0.90250000 val_loss: 0.28994179, dom-acc: 0.62508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.03814983, sen-loss: 24.60635660, dom-loss: 77.43179309, train-acc: 0.92732143, val-acc: 0.89750000 val_loss: 0.29162368, dom-acc: 0.62892857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.58157980, sen-loss: 24.22470799, dom-loss: 77.35687149, train-acc: 0.92678571, val-acc: 0.90000000 val_loss: 0.28885776, dom-acc: 0.61723214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.63155961, sen-loss: 24.06559855, dom-loss: 77.56596088, train-acc: 0.92857143, val-acc: 0.90000000 val_loss: 0.28753000, dom-acc: 0.60767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.37790370, sen-loss: 23.80675560, dom-loss: 77.57114816, train-acc: 0.93000000, val-acc: 0.90000000 val_loss: 0.28776613, dom-acc: 0.60508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.32468039, sen-loss: 23.55900695, dom-loss: 77.76567334, train-acc: 0.93071429, val-acc: 0.89750000 val_loss: 0.29014581, dom-acc: 0.60401786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.13146824, sen-loss: 23.37990998, dom-loss: 77.75155789, train-acc: 0.93089286, val-acc: 0.89750000 val_loss: 0.28656620, dom-acc: 0.60241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.75528497, sen-loss: 22.87176264, dom-loss: 77.88352281, train-acc: 0.93125000, val-acc: 0.88500000 val_loss: 0.28733638, dom-acc: 0.59928571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.73861277, sen-loss: 22.84126171, dom-loss: 77.89735115, train-acc: 0.93142857, val-acc: 0.89750000 val_loss: 0.28615066, dom-acc: 0.58392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.43977749, sen-loss: 22.37199793, dom-loss: 78.06778008, train-acc: 0.93321429, val-acc: 0.89500000 val_loss: 0.29221940, dom-acc: 0.58080357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.92466402, sen-loss: 22.09864714, dom-loss: 77.82601708, train-acc: 0.93500000, val-acc: 0.89250000 val_loss: 0.28962013, dom-acc: 0.58035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.84177268, sen-loss: 21.87711175, dom-loss: 77.96466076, train-acc: 0.93410714, val-acc: 0.89250000 val_loss: 0.28523237, dom-acc: 0.57482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.75905240, sen-loss: 21.52841032, dom-loss: 78.23064220, train-acc: 0.93678571, val-acc: 0.89750000 val_loss: 0.28422993, dom-acc: 0.57767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.43980837, sen-loss: 21.32868803, dom-loss: 78.11112052, train-acc: 0.93803571, val-acc: 0.89250000 val_loss: 0.28739119, dom-acc: 0.58517857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.16249138, sen-loss: 21.05061769, dom-loss: 78.11187387, train-acc: 0.93732143, val-acc: 0.89000000 val_loss: 0.28588581, dom-acc: 0.56785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 99.07280427, sen-loss: 20.83829843, dom-loss: 78.23450559, train-acc: 0.93982143, val-acc: 0.89250000 val_loss: 0.28702721, dom-acc: 0.56133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.58087564, sen-loss: 20.46700525, dom-loss: 78.11387014, train-acc: 0.94214286, val-acc: 0.89000000 val_loss: 0.28762695, dom-acc: 0.57276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 98.33156973, sen-loss: 20.26087741, dom-loss: 78.07069212, train-acc: 0.94303571, val-acc: 0.89500000 val_loss: 0.28949228, dom-acc: 0.54901786
---------------------------------------------------

Successfully load model from save path: ./work/models/video_books_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.28422993
Testing accuracy: 0.86716667
./work/attentions/video_books_train.txt
./work/pivots/video_books_pos.txt
./work/pivots/video_books_neg.txt
./work/attentions/video_books_test.txt
loading data...
source domain:  video target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 11843
vocab-size:  91852
max  story size: 226
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
91852
word_embedding done:  91853
5600 400 6000 36180 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(91853, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 157.22447252, sen-loss: 76.31681597, dom-loss: 80.90765649, train-acc: 0.75607143, val-acc: 0.75750000 val_loss: 0.64892352, dom-acc: 0.45625000
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 147.86604285, sen-loss: 68.88671023, dom-loss: 78.97933316, train-acc: 0.79035714, val-acc: 0.80500000 val_loss: 0.57283658, dom-acc: 0.43919643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 137.99660528, sen-loss: 59.06135514, dom-loss: 78.93524975, train-acc: 0.81517857, val-acc: 0.79500000 val_loss: 0.47905585, dom-acc: 0.43500000
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 128.10268867, sen-loss: 49.29841384, dom-loss: 78.80427426, train-acc: 0.84232143, val-acc: 0.81500000 val_loss: 0.40859810, dom-acc: 0.44741071
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 120.99749660, sen-loss: 42.25537333, dom-loss: 78.74212265, train-acc: 0.85803571, val-acc: 0.84250000 val_loss: 0.36166528, dom-acc: 0.45294643
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 116.31300908, sen-loss: 37.56848295, dom-loss: 78.74452621, train-acc: 0.87910714, val-acc: 0.87000000 val_loss: 0.34367293, dom-acc: 0.52258929
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 113.39622313, sen-loss: 34.78139187, dom-loss: 78.61483145, train-acc: 0.88892857, val-acc: 0.87500000 val_loss: 0.33187053, dom-acc: 0.57580357
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 111.87239939, sen-loss: 33.32904960, dom-loss: 78.54335004, train-acc: 0.89589286, val-acc: 0.88500000 val_loss: 0.31959954, dom-acc: 0.58964286
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 110.72939360, sen-loss: 32.16755775, dom-loss: 78.56183583, train-acc: 0.88714286, val-acc: 0.87500000 val_loss: 0.33488816, dom-acc: 0.57500000
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 109.70722139, sen-loss: 31.29127201, dom-loss: 78.41594940, train-acc: 0.90178571, val-acc: 0.88750000 val_loss: 0.31014702, dom-acc: 0.59205357
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 109.15241051, sen-loss: 30.71258993, dom-loss: 78.43982053, train-acc: 0.90500000, val-acc: 0.89000000 val_loss: 0.31025240, dom-acc: 0.56035714
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 108.44317454, sen-loss: 29.99153624, dom-loss: 78.45163780, train-acc: 0.90803571, val-acc: 0.89250000 val_loss: 0.30692694, dom-acc: 0.56401786
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 107.83171213, sen-loss: 29.47476091, dom-loss: 78.35695124, train-acc: 0.91142857, val-acc: 0.89500000 val_loss: 0.30496240, dom-acc: 0.59678571
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 107.00273621, sen-loss: 28.66254219, dom-loss: 78.34019405, train-acc: 0.91410714, val-acc: 0.89500000 val_loss: 0.30235237, dom-acc: 0.55562500
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 106.84619689, sen-loss: 28.55786283, dom-loss: 78.28833425, train-acc: 0.90392857, val-acc: 0.89000000 val_loss: 0.32291836, dom-acc: 0.51571429
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.39444453, sen-loss: 28.11707214, dom-loss: 78.27737236, train-acc: 0.91589286, val-acc: 0.89000000 val_loss: 0.29653084, dom-acc: 0.53714286
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.68710089, sen-loss: 27.42678923, dom-loss: 78.26031184, train-acc: 0.91857143, val-acc: 0.89750000 val_loss: 0.30163118, dom-acc: 0.58455357
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 105.38366568, sen-loss: 27.20823270, dom-loss: 78.17543346, train-acc: 0.91767857, val-acc: 0.89000000 val_loss: 0.29430351, dom-acc: 0.57133929
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 104.68547690, sen-loss: 26.52498932, dom-loss: 78.16048735, train-acc: 0.92196429, val-acc: 0.89500000 val_loss: 0.29384643, dom-acc: 0.59169643
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 104.48819083, sen-loss: 26.38200238, dom-loss: 78.10618848, train-acc: 0.92196429, val-acc: 0.89500000 val_loss: 0.29544708, dom-acc: 0.60107143
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 104.03020698, sen-loss: 25.94694556, dom-loss: 78.08326137, train-acc: 0.92321429, val-acc: 0.89500000 val_loss: 0.29416892, dom-acc: 0.59696429
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 103.77422321, sen-loss: 25.69813154, dom-loss: 78.07609171, train-acc: 0.92160714, val-acc: 0.89250000 val_loss: 0.30147383, dom-acc: 0.61080357
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 103.33973181, sen-loss: 25.22803746, dom-loss: 78.11169422, train-acc: 0.92535714, val-acc: 0.89500000 val_loss: 0.29373500, dom-acc: 0.59089286
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 102.96080369, sen-loss: 24.86328330, dom-loss: 78.09752041, train-acc: 0.92607143, val-acc: 0.90000000 val_loss: 0.28964621, dom-acc: 0.55901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.54411584, sen-loss: 24.58640670, dom-loss: 77.95770931, train-acc: 0.92660714, val-acc: 0.89750000 val_loss: 0.29111555, dom-acc: 0.57589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.29740572, sen-loss: 24.20125038, dom-loss: 78.09615529, train-acc: 0.92785714, val-acc: 0.89750000 val_loss: 0.28852332, dom-acc: 0.58098214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.06338930, sen-loss: 24.03110237, dom-loss: 78.03228688, train-acc: 0.92892857, val-acc: 0.89750000 val_loss: 0.28740123, dom-acc: 0.57910714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.69210249, sen-loss: 23.76143256, dom-loss: 77.93066967, train-acc: 0.92982143, val-acc: 0.89250000 val_loss: 0.28769279, dom-acc: 0.60276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.50371361, sen-loss: 23.51525527, dom-loss: 77.98845834, train-acc: 0.92910714, val-acc: 0.89500000 val_loss: 0.29012701, dom-acc: 0.59026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.31035578, sen-loss: 23.34069192, dom-loss: 77.96966398, train-acc: 0.93071429, val-acc: 0.88750000 val_loss: 0.28665638, dom-acc: 0.56151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.75560963, sen-loss: 22.82141482, dom-loss: 77.93419462, train-acc: 0.93071429, val-acc: 0.88250000 val_loss: 0.28742173, dom-acc: 0.59035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.67175210, sen-loss: 22.78656707, dom-loss: 77.88518518, train-acc: 0.93125000, val-acc: 0.89500000 val_loss: 0.28637257, dom-acc: 0.59026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.19591922, sen-loss: 22.31807921, dom-loss: 77.87783998, train-acc: 0.93321429, val-acc: 0.89500000 val_loss: 0.29257086, dom-acc: 0.59919643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.98409623, sen-loss: 22.04023331, dom-loss: 77.94386286, train-acc: 0.93500000, val-acc: 0.89500000 val_loss: 0.28972545, dom-acc: 0.55107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.71471387, sen-loss: 21.81888191, dom-loss: 77.89583182, train-acc: 0.93321429, val-acc: 0.89500000 val_loss: 0.28579441, dom-acc: 0.54089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.34520888, sen-loss: 21.47780408, dom-loss: 77.86740470, train-acc: 0.93553571, val-acc: 0.89000000 val_loss: 0.28499377, dom-acc: 0.61375000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.10717690, sen-loss: 21.26664668, dom-loss: 77.84053034, train-acc: 0.93571429, val-acc: 0.89500000 val_loss: 0.28832114, dom-acc: 0.60642857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 98.79645634, sen-loss: 20.98205219, dom-loss: 77.81440389, train-acc: 0.93767857, val-acc: 0.89250000 val_loss: 0.28690410, dom-acc: 0.57348214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 98.56347251, sen-loss: 20.76449242, dom-loss: 77.79898012, train-acc: 0.93821429, val-acc: 0.89500000 val_loss: 0.28833538, dom-acc: 0.54026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.22944736, sen-loss: 20.40760998, dom-loss: 77.82183754, train-acc: 0.94071429, val-acc: 0.89750000 val_loss: 0.28894764, dom-acc: 0.59392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 98.02485317, sen-loss: 20.19503761, dom-loss: 77.82981539, train-acc: 0.94160714, val-acc: 0.89500000 val_loss: 0.29139674, dom-acc: 0.57116071
---------------------------------------------------

Successfully load model from save path: ./work/models/video_dvd_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.28499377
Testing accuracy: 0.87700000
./work/attentions/video_dvd_train.txt
./work/pivots/video_dvd_pos.txt
./work/pivots/video_dvd_neg.txt
./work/attentions/video_dvd_test.txt
loading data...
source domain:  video target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 17009
vocab-size:  83059
max  story size: 129
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
83059
word_embedding done:  83060
5600 400 6000 36180 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83060, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 153.71538758, sen-loss: 76.31645685, dom-loss: 77.39893073, train-acc: 0.75607143, val-acc: 0.75750000 val_loss: 0.64891279, dom-acc: 0.85125000
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.56276631, sen-loss: 68.89810908, dom-loss: 71.66465724, train-acc: 0.79000000, val-acc: 0.80500000 val_loss: 0.57305396, dom-acc: 0.82714286
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 128.61696267, sen-loss: 59.09865233, dom-loss: 69.51831013, train-acc: 0.81821429, val-acc: 0.81250000 val_loss: 0.47914940, dom-acc: 0.69464286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 119.65945983, sen-loss: 49.26619720, dom-loss: 70.39326298, train-acc: 0.84339286, val-acc: 0.81750000 val_loss: 0.40798435, dom-acc: 0.59116071
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 114.49292666, sen-loss: 42.21475497, dom-loss: 72.27817148, train-acc: 0.85660714, val-acc: 0.84250000 val_loss: 0.36112547, dom-acc: 0.58250000
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.38066590, sen-loss: 37.62195081, dom-loss: 73.75871491, train-acc: 0.87803571, val-acc: 0.87000000 val_loss: 0.34555590, dom-acc: 0.58589286
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 110.34668523, sen-loss: 34.90442584, dom-loss: 75.44225949, train-acc: 0.88785714, val-acc: 0.87500000 val_loss: 0.33349922, dom-acc: 0.61187500
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.28002882, sen-loss: 33.43048058, dom-loss: 76.84954822, train-acc: 0.89482143, val-acc: 0.88250000 val_loss: 0.32064378, dom-acc: 0.51276786
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 110.83145553, sen-loss: 32.27508612, dom-loss: 78.55636919, train-acc: 0.88785714, val-acc: 0.87500000 val_loss: 0.33661094, dom-acc: 0.42250000
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 111.40086079, sen-loss: 31.39289209, dom-loss: 80.00796866, train-acc: 0.89964286, val-acc: 0.88250000 val_loss: 0.31122243, dom-acc: 0.36776786
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 111.79064536, sen-loss: 30.80267685, dom-loss: 80.98796785, train-acc: 0.90339286, val-acc: 0.89000000 val_loss: 0.31130117, dom-acc: 0.33741071
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 111.54778463, sen-loss: 30.09742422, dom-loss: 81.45035988, train-acc: 0.90892857, val-acc: 0.89500000 val_loss: 0.30807957, dom-acc: 0.33401786
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 110.93069667, sen-loss: 29.56983174, dom-loss: 81.36086470, train-acc: 0.91000000, val-acc: 0.89500000 val_loss: 0.30643597, dom-acc: 0.34160714
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 109.75344580, sen-loss: 28.76248264, dom-loss: 80.99096328, train-acc: 0.91357143, val-acc: 0.90000000 val_loss: 0.30359620, dom-acc: 0.35875000
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.08063459, sen-loss: 28.66997768, dom-loss: 80.41065723, train-acc: 0.90410714, val-acc: 0.88750000 val_loss: 0.32487810, dom-acc: 0.36991071
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 107.51581794, sen-loss: 28.22562547, dom-loss: 79.29019237, train-acc: 0.91410714, val-acc: 0.89750000 val_loss: 0.29753181, dom-acc: 0.41160714
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.95792532, sen-loss: 27.52942177, dom-loss: 78.42850316, train-acc: 0.91857143, val-acc: 0.89500000 val_loss: 0.30267799, dom-acc: 0.42741071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 105.00248498, sen-loss: 27.31445409, dom-loss: 77.68803084, train-acc: 0.91642857, val-acc: 0.89250000 val_loss: 0.29500934, dom-acc: 0.46741071
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 103.53214860, sen-loss: 26.62824926, dom-loss: 76.90389949, train-acc: 0.92035714, val-acc: 0.90000000 val_loss: 0.29444581, dom-acc: 0.48241071
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 102.73747033, sen-loss: 26.48792312, dom-loss: 76.24954724, train-acc: 0.92232143, val-acc: 0.90000000 val_loss: 0.29648653, dom-acc: 0.49892857
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 101.97229153, sen-loss: 26.05851798, dom-loss: 75.91377354, train-acc: 0.92285714, val-acc: 0.90250000 val_loss: 0.29533786, dom-acc: 0.51598214
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 101.70973742, sen-loss: 25.82104748, dom-loss: 75.88868970, train-acc: 0.92089286, val-acc: 0.89500000 val_loss: 0.30410832, dom-acc: 0.51937500
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 100.82338607, sen-loss: 25.35657593, dom-loss: 75.46680981, train-acc: 0.92517857, val-acc: 0.90000000 val_loss: 0.29513660, dom-acc: 0.52526786
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 100.29164833, sen-loss: 24.99322587, dom-loss: 75.29842204, train-acc: 0.92428571, val-acc: 0.90250000 val_loss: 0.29036134, dom-acc: 0.50357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 100.27990073, sen-loss: 24.70536110, dom-loss: 75.57453918, train-acc: 0.92625000, val-acc: 0.90250000 val_loss: 0.29203346, dom-acc: 0.49866071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 100.03580701, sen-loss: 24.31216033, dom-loss: 75.72364682, train-acc: 0.92589286, val-acc: 0.90000000 val_loss: 0.28900892, dom-acc: 0.49875000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 100.15113503, sen-loss: 24.15402961, dom-loss: 75.99710590, train-acc: 0.92589286, val-acc: 0.90250000 val_loss: 0.28755403, dom-acc: 0.48241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 100.29512680, sen-loss: 23.89464717, dom-loss: 76.40047967, train-acc: 0.92803571, val-acc: 0.90250000 val_loss: 0.28782469, dom-acc: 0.47321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.50529963, sen-loss: 23.63960308, dom-loss: 76.86569679, train-acc: 0.92875000, val-acc: 0.90000000 val_loss: 0.29059386, dom-acc: 0.45125000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.62387383, sen-loss: 23.46250632, dom-loss: 77.16136760, train-acc: 0.92857143, val-acc: 0.89750000 val_loss: 0.28685230, dom-acc: 0.44901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.37699974, sen-loss: 22.95189697, dom-loss: 77.42510265, train-acc: 0.92982143, val-acc: 0.88500000 val_loss: 0.28732163, dom-acc: 0.44366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.74129838, sen-loss: 22.93525361, dom-loss: 77.80604506, train-acc: 0.92964286, val-acc: 0.89500000 val_loss: 0.28636733, dom-acc: 0.43053571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.65736878, sen-loss: 22.45717794, dom-loss: 78.20019078, train-acc: 0.93232143, val-acc: 0.90250000 val_loss: 0.29303131, dom-acc: 0.40964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.61463779, sen-loss: 22.17479953, dom-loss: 78.43983793, train-acc: 0.93339286, val-acc: 0.89250000 val_loss: 0.29053998, dom-acc: 0.40017857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.37573767, sen-loss: 21.95699082, dom-loss: 78.41874713, train-acc: 0.93482143, val-acc: 0.89500000 val_loss: 0.28573072, dom-acc: 0.41071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.12611389, sen-loss: 21.62757980, dom-loss: 78.49853426, train-acc: 0.93500000, val-acc: 0.89000000 val_loss: 0.28494030, dom-acc: 0.41357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.95232397, sen-loss: 21.40898552, dom-loss: 78.54333842, train-acc: 0.93428571, val-acc: 0.89500000 val_loss: 0.28851202, dom-acc: 0.41696429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.23608929, sen-loss: 21.14130518, dom-loss: 78.09478414, train-acc: 0.93571429, val-acc: 0.89250000 val_loss: 0.28723583, dom-acc: 0.42133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 98.89386356, sen-loss: 20.93207541, dom-loss: 77.96178770, train-acc: 0.93660714, val-acc: 0.89250000 val_loss: 0.28830916, dom-acc: 0.42508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.60394186, sen-loss: 20.57552849, dom-loss: 78.02841383, train-acc: 0.93946429, val-acc: 0.89500000 val_loss: 0.28900090, dom-acc: 0.44008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 97.76574272, sen-loss: 20.36981390, dom-loss: 77.39592898, train-acc: 0.94089286, val-acc: 0.89750000 val_loss: 0.29167736, dom-acc: 0.44187500
---------------------------------------------------

Successfully load model from save path: ./work/models/video_electronics_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.28494030
Testing accuracy: 0.84383333
./work/attentions/video_electronics_train.txt
./work/pivots/video_electronics_pos.txt
./work/pivots/video_electronics_neg.txt
./work/attentions/video_electronics_test.txt
loading data...
source domain:  video target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 13856
vocab-size:  78115
max  story size: 104
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
78115
word_embedding done:  78116
5600 400 6000 36180 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78116, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 153.28524387, sen-loss: 76.31626207, dom-loss: 76.96898204, train-acc: 0.75625000, val-acc: 0.75750000 val_loss: 0.64891529, dom-acc: 0.87250000
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.64329708, sen-loss: 68.89209878, dom-loss: 71.75119841, train-acc: 0.79017857, val-acc: 0.80500000 val_loss: 0.57296640, dom-acc: 0.87437500
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 129.58229053, sen-loss: 59.06541735, dom-loss: 70.51687330, train-acc: 0.81535714, val-acc: 0.79750000 val_loss: 0.47904414, dom-acc: 0.80392857
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 120.40896046, sen-loss: 49.24549007, dom-loss: 71.16347009, train-acc: 0.84267857, val-acc: 0.81750000 val_loss: 0.40808019, dom-acc: 0.75964286
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 114.72244364, sen-loss: 42.17097598, dom-loss: 72.55146718, train-acc: 0.85732143, val-acc: 0.84000000 val_loss: 0.36120766, dom-acc: 0.83473214
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.65328002, sen-loss: 37.55636500, dom-loss: 74.09691519, train-acc: 0.87839286, val-acc: 0.87000000 val_loss: 0.34452629, dom-acc: 0.81330357
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 110.40199316, sen-loss: 34.83342907, dom-loss: 75.56856394, train-acc: 0.88821429, val-acc: 0.87500000 val_loss: 0.33274966, dom-acc: 0.72901786
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.78705364, sen-loss: 33.38046062, dom-loss: 77.40659302, train-acc: 0.89660714, val-acc: 0.88750000 val_loss: 0.32002962, dom-acc: 0.62625000
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 111.54365468, sen-loss: 32.21503727, dom-loss: 79.32861739, train-acc: 0.88714286, val-acc: 0.87500000 val_loss: 0.33552611, dom-acc: 0.55946429
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 112.07278407, sen-loss: 31.34254818, dom-loss: 80.73023611, train-acc: 0.90142857, val-acc: 0.88000000 val_loss: 0.31059831, dom-acc: 0.49276786
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 112.64698309, sen-loss: 30.75792629, dom-loss: 81.88905698, train-acc: 0.90482143, val-acc: 0.89000000 val_loss: 0.31052038, dom-acc: 0.43500000
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 112.58726662, sen-loss: 30.03498729, dom-loss: 82.55227983, train-acc: 0.90946429, val-acc: 0.89750000 val_loss: 0.30723092, dom-acc: 0.34678571
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 112.15225524, sen-loss: 29.51895051, dom-loss: 82.63330507, train-acc: 0.91107143, val-acc: 0.89500000 val_loss: 0.30550128, dom-acc: 0.33696429
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 110.72481412, sen-loss: 28.70577218, dom-loss: 82.01904225, train-acc: 0.91321429, val-acc: 0.89750000 val_loss: 0.30272061, dom-acc: 0.35571429
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.84178728, sen-loss: 28.60309061, dom-loss: 81.23869675, train-acc: 0.90446429, val-acc: 0.89250000 val_loss: 0.32363078, dom-acc: 0.39008929
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 108.35873979, sen-loss: 28.15424076, dom-loss: 80.20449847, train-acc: 0.91482143, val-acc: 0.89000000 val_loss: 0.29696575, dom-acc: 0.43901786
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 106.65447521, sen-loss: 27.45953986, dom-loss: 79.19493550, train-acc: 0.91767857, val-acc: 0.89750000 val_loss: 0.30202681, dom-acc: 0.50428571
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 105.45566684, sen-loss: 27.24213738, dom-loss: 78.21352899, train-acc: 0.91714286, val-acc: 0.88750000 val_loss: 0.29454991, dom-acc: 0.55812500
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 104.00227565, sen-loss: 26.56053651, dom-loss: 77.44173902, train-acc: 0.92196429, val-acc: 0.90000000 val_loss: 0.29418617, dom-acc: 0.59375000
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 103.23141080, sen-loss: 26.41208676, dom-loss: 76.81932408, train-acc: 0.92250000, val-acc: 0.90000000 val_loss: 0.29579261, dom-acc: 0.62410714
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 102.38257992, sen-loss: 25.98511887, dom-loss: 76.39746100, train-acc: 0.92321429, val-acc: 0.90000000 val_loss: 0.29487047, dom-acc: 0.64142857
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 102.02188408, sen-loss: 25.74110746, dom-loss: 76.28077644, train-acc: 0.91964286, val-acc: 0.89250000 val_loss: 0.30235812, dom-acc: 0.64008929
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 101.37453324, sen-loss: 25.28067272, dom-loss: 76.09386075, train-acc: 0.92482143, val-acc: 0.89750000 val_loss: 0.29474878, dom-acc: 0.62955357
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 101.12446362, sen-loss: 24.91791613, dom-loss: 76.20654732, train-acc: 0.92517857, val-acc: 0.90000000 val_loss: 0.29021716, dom-acc: 0.61375000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 101.10460585, sen-loss: 24.63290837, dom-loss: 76.47169733, train-acc: 0.92607143, val-acc: 0.90000000 val_loss: 0.29177803, dom-acc: 0.60705357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.01721489, sen-loss: 24.25183074, dom-loss: 76.76538402, train-acc: 0.92767857, val-acc: 0.90000000 val_loss: 0.28908417, dom-acc: 0.57660714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.32439899, sen-loss: 24.08688351, dom-loss: 77.23751551, train-acc: 0.92785714, val-acc: 0.89750000 val_loss: 0.28780192, dom-acc: 0.55589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.40279436, sen-loss: 23.82752628, dom-loss: 77.57526797, train-acc: 0.92857143, val-acc: 0.89250000 val_loss: 0.28801784, dom-acc: 0.51723214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.66923386, sen-loss: 23.58086951, dom-loss: 78.08836406, train-acc: 0.92964286, val-acc: 0.89500000 val_loss: 0.29050007, dom-acc: 0.46839286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.87437379, sen-loss: 23.41047564, dom-loss: 78.46389812, train-acc: 0.93053571, val-acc: 0.89000000 val_loss: 0.28696385, dom-acc: 0.44419643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 101.64744020, sen-loss: 22.89877962, dom-loss: 78.74866050, train-acc: 0.93035714, val-acc: 0.88500000 val_loss: 0.28769195, dom-acc: 0.40946429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 101.93098044, sen-loss: 22.87536740, dom-loss: 79.05561286, train-acc: 0.93000000, val-acc: 0.89500000 val_loss: 0.28648004, dom-acc: 0.38857143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.45976496, sen-loss: 22.40062154, dom-loss: 79.05914354, train-acc: 0.93303571, val-acc: 0.89500000 val_loss: 0.29259288, dom-acc: 0.38723214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 101.21321201, sen-loss: 22.12237936, dom-loss: 79.09083283, train-acc: 0.93303571, val-acc: 0.89250000 val_loss: 0.28972271, dom-acc: 0.38392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.65557557, sen-loss: 21.90838976, dom-loss: 78.74718535, train-acc: 0.93285714, val-acc: 0.89750000 val_loss: 0.28561059, dom-acc: 0.40116071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.16133666, sen-loss: 21.56701156, dom-loss: 78.59432524, train-acc: 0.93482143, val-acc: 0.89500000 val_loss: 0.28464091, dom-acc: 0.42767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.79861838, sen-loss: 21.36498770, dom-loss: 78.43363041, train-acc: 0.93535714, val-acc: 0.89250000 val_loss: 0.28795889, dom-acc: 0.45214286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.02363390, sen-loss: 21.09134635, dom-loss: 77.93228745, train-acc: 0.93660714, val-acc: 0.89750000 val_loss: 0.28648311, dom-acc: 0.45625000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 98.51192069, sen-loss: 20.87275348, dom-loss: 77.63916731, train-acc: 0.93660714, val-acc: 0.89500000 val_loss: 0.28785574, dom-acc: 0.47410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 97.96792841, sen-loss: 20.52417125, dom-loss: 77.44375706, train-acc: 0.94000000, val-acc: 0.89500000 val_loss: 0.28833315, dom-acc: 0.49669643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 97.61022013, sen-loss: 20.31475213, dom-loss: 77.29546815, train-acc: 0.94160714, val-acc: 0.89500000 val_loss: 0.29091543, dom-acc: 0.49553571
---------------------------------------------------

Successfully load model from save path: ./work/models/video_kitchen_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.28464091
Testing accuracy: 0.84550000
./work/attentions/video_kitchen_train.txt
./work/pivots/video_kitchen_pos.txt
./work/pivots/video_kitchen_neg.txt
./work/attentions/video_kitchen_test.txt
loading data...
source domain:  books target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 11843
vocab-size:  100530
max  story size: 226
mean story size: 8
max  sentence size: 783
mean sentence size: 19
max memory size: 20
100530
word_embedding done:  100531
5600 400 6000 15750 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(100531, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 156.28133333, sen-loss: 76.63467342, dom-loss: 79.64665997, train-acc: 0.76571429, val-acc: 0.77000000 val_loss: 0.65244049, dom-acc: 0.67830357
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 146.14484465, sen-loss: 69.89169192, dom-loss: 76.25315338, train-acc: 0.77589286, val-acc: 0.75250000 val_loss: 0.58330578, dom-acc: 0.67785714
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 136.50793993, sen-loss: 60.73104700, dom-loss: 75.77689207, train-acc: 0.83196429, val-acc: 0.83250000 val_loss: 0.48634887, dom-acc: 0.61839286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 125.81687617, sen-loss: 50.08047858, dom-loss: 75.73639703, train-acc: 0.86000000, val-acc: 0.85750000 val_loss: 0.39661223, dom-acc: 0.56883929
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 117.41638947, sen-loss: 41.25187983, dom-loss: 76.16450936, train-acc: 0.87250000, val-acc: 0.87000000 val_loss: 0.34595388, dom-acc: 0.59812500
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 112.95476848, sen-loss: 36.85086298, dom-loss: 76.10390544, train-acc: 0.87642857, val-acc: 0.86250000 val_loss: 0.33373284, dom-acc: 0.67267857
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.22507620, sen-loss: 35.29244204, dom-loss: 75.93263400, train-acc: 0.88214286, val-acc: 0.86500000 val_loss: 0.33948717, dom-acc: 0.67062500
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.40213871, sen-loss: 34.24239349, dom-loss: 76.15974516, train-acc: 0.88232143, val-acc: 0.87500000 val_loss: 0.32713574, dom-acc: 0.67250000
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 109.79867089, sen-loss: 33.52661496, dom-loss: 76.27205592, train-acc: 0.88803571, val-acc: 0.87500000 val_loss: 0.32785973, dom-acc: 0.66607143
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 108.82030648, sen-loss: 32.63570364, dom-loss: 76.18460304, train-acc: 0.88857143, val-acc: 0.88000000 val_loss: 0.32158798, dom-acc: 0.66455357
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.94713485, sen-loss: 32.48951407, dom-loss: 76.45762068, train-acc: 0.89089286, val-acc: 0.88250000 val_loss: 0.32193851, dom-acc: 0.66669643
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 108.09773165, sen-loss: 31.67505528, dom-loss: 76.42267656, train-acc: 0.89321429, val-acc: 0.88500000 val_loss: 0.32138315, dom-acc: 0.66687500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 107.64859247, sen-loss: 31.15581250, dom-loss: 76.49277985, train-acc: 0.89125000, val-acc: 0.87250000 val_loss: 0.32840154, dom-acc: 0.66616071
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 107.62389398, sen-loss: 30.89409386, dom-loss: 76.72980028, train-acc: 0.89500000, val-acc: 0.87250000 val_loss: 0.31330171, dom-acc: 0.64303571
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 107.30763924, sen-loss: 30.48562824, dom-loss: 76.82201087, train-acc: 0.89089286, val-acc: 0.87500000 val_loss: 0.33531117, dom-acc: 0.64946429
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.80599016, sen-loss: 29.91933951, dom-loss: 76.88665110, train-acc: 0.90071429, val-acc: 0.89250000 val_loss: 0.31013474, dom-acc: 0.64883929
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 106.73244727, sen-loss: 29.69558686, dom-loss: 77.03686059, train-acc: 0.89910714, val-acc: 0.88000000 val_loss: 0.30901411, dom-acc: 0.65473214
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 106.20495975, sen-loss: 29.16814905, dom-loss: 77.03681052, train-acc: 0.90232143, val-acc: 0.89500000 val_loss: 0.30837277, dom-acc: 0.64428571
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 106.09139794, sen-loss: 28.87822962, dom-loss: 77.21316803, train-acc: 0.90428571, val-acc: 0.89000000 val_loss: 0.30922946, dom-acc: 0.64812500
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 105.91780627, sen-loss: 28.59725862, dom-loss: 77.32054782, train-acc: 0.90517857, val-acc: 0.88750000 val_loss: 0.31260306, dom-acc: 0.64892857
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 105.67122245, sen-loss: 28.32578143, dom-loss: 77.34544080, train-acc: 0.90678571, val-acc: 0.89000000 val_loss: 0.30869302, dom-acc: 0.64839286
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 105.56913519, sen-loss: 28.14229799, dom-loss: 77.42683685, train-acc: 0.90750000, val-acc: 0.89250000 val_loss: 0.30985770, dom-acc: 0.64705357
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 105.17695659, sen-loss: 27.62886591, dom-loss: 77.54809040, train-acc: 0.90857143, val-acc: 0.89000000 val_loss: 0.30841792, dom-acc: 0.64553571
---------------------------------------------------

Successfully load model from save path: ./work/models/books_dvd_PNet.ckpt
Best Epoch: [ 18] best val accuracy: 0.00000000 best val loss: 0.30837277
Testing accuracy: 0.87033333
./work/attentions/books_dvd_train.txt
./work/pivots/books_dvd_pos.txt
./work/pivots/books_dvd_neg.txt
./work/attentions/books_dvd_test.txt
loading data...
source domain:  books target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 17009
vocab-size:  83050
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 18
max memory size: 20
83050
word_embedding done:  83051
5600 400 6000 15750 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83051, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 153.35655773, sen-loss: 76.63379484, dom-loss: 76.72276229, train-acc: 0.76571429, val-acc: 0.77000000 val_loss: 0.65241426, dom-acc: 0.89714286
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.90607452, sen-loss: 69.88640702, dom-loss: 71.01966733, train-acc: 0.77571429, val-acc: 0.75250000 val_loss: 0.58317792, dom-acc: 0.90544643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 130.46996820, sen-loss: 60.71563986, dom-loss: 69.75432724, train-acc: 0.83232143, val-acc: 0.83250000 val_loss: 0.48609090, dom-acc: 0.84071429
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 120.43441492, sen-loss: 50.05527753, dom-loss: 70.37913769, train-acc: 0.85928571, val-acc: 0.85750000 val_loss: 0.39613965, dom-acc: 0.78008929
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 112.84130776, sen-loss: 41.25685269, dom-loss: 71.58445519, train-acc: 0.87160714, val-acc: 0.87000000 val_loss: 0.34574178, dom-acc: 0.84991071
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 109.49409425, sen-loss: 36.90204825, dom-loss: 72.59204632, train-acc: 0.87607143, val-acc: 0.86750000 val_loss: 0.33337396, dom-acc: 0.84723214
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 109.16971165, sen-loss: 35.33685729, dom-loss: 73.83285445, train-acc: 0.88232143, val-acc: 0.86500000 val_loss: 0.33890665, dom-acc: 0.79571429
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 109.66509801, sen-loss: 34.27627043, dom-loss: 75.38882774, train-acc: 0.88196429, val-acc: 0.87250000 val_loss: 0.32648805, dom-acc: 0.70696429
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 110.69405669, sen-loss: 33.55990836, dom-loss: 77.13414931, train-acc: 0.88803571, val-acc: 0.87750000 val_loss: 0.32701427, dom-acc: 0.62660714
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 111.43642610, sen-loss: 32.66341738, dom-loss: 78.77300882, train-acc: 0.88839286, val-acc: 0.88000000 val_loss: 0.32095429, dom-acc: 0.56857143
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 112.67779285, sen-loss: 32.51677701, dom-loss: 80.16101599, train-acc: 0.89107143, val-acc: 0.88500000 val_loss: 0.32114679, dom-acc: 0.51830357
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 112.87278414, sen-loss: 31.69676538, dom-loss: 81.17601871, train-acc: 0.89303571, val-acc: 0.88750000 val_loss: 0.32097709, dom-acc: 0.45821429
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 113.16707408, sen-loss: 31.18298265, dom-loss: 81.98409146, train-acc: 0.89178571, val-acc: 0.87250000 val_loss: 0.32795668, dom-acc: 0.40312500
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 113.24575597, sen-loss: 30.91497909, dom-loss: 82.33077645, train-acc: 0.89410714, val-acc: 0.87500000 val_loss: 0.31269115, dom-acc: 0.35919643
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 112.85793161, sen-loss: 30.51205147, dom-loss: 82.34588015, train-acc: 0.89017857, val-acc: 0.87500000 val_loss: 0.33526146, dom-acc: 0.36223214
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 111.91343212, sen-loss: 29.94477913, dom-loss: 81.96865308, train-acc: 0.90053571, val-acc: 0.89500000 val_loss: 0.30955637, dom-acc: 0.36821429
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 111.26435459, sen-loss: 29.71973324, dom-loss: 81.54462147, train-acc: 0.90000000, val-acc: 0.88000000 val_loss: 0.30830362, dom-acc: 0.33767857
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 109.98622638, sen-loss: 29.19075051, dom-loss: 80.79547578, train-acc: 0.90232143, val-acc: 0.89500000 val_loss: 0.30762309, dom-acc: 0.39776786
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 108.89205295, sen-loss: 28.90441701, dom-loss: 79.98763591, train-acc: 0.90339286, val-acc: 0.89000000 val_loss: 0.30829591, dom-acc: 0.47803571
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 107.95037001, sen-loss: 28.62304147, dom-loss: 79.32732838, train-acc: 0.90464286, val-acc: 0.88750000 val_loss: 0.31162739, dom-acc: 0.53714286
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 106.99635828, sen-loss: 28.35589223, dom-loss: 78.64046603, train-acc: 0.90714286, val-acc: 0.88750000 val_loss: 0.30772749, dom-acc: 0.60062500
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 106.09970522, sen-loss: 28.17620078, dom-loss: 77.92350411, train-acc: 0.90767857, val-acc: 0.89000000 val_loss: 0.30855796, dom-acc: 0.65901786
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 105.00366080, sen-loss: 27.65455346, dom-loss: 77.34910733, train-acc: 0.90892857, val-acc: 0.89000000 val_loss: 0.30709100, dom-acc: 0.69580357
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 104.24570119, sen-loss: 27.29519525, dom-loss: 76.95050573, train-acc: 0.90964286, val-acc: 0.89000000 val_loss: 0.31043485, dom-acc: 0.70776786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.84307826, sen-loss: 27.12043824, dom-loss: 76.72264034, train-acc: 0.91000000, val-acc: 0.89000000 val_loss: 0.30649593, dom-acc: 0.72312500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 103.29386866, sen-loss: 26.89231236, dom-loss: 76.40155607, train-acc: 0.91214286, val-acc: 0.89000000 val_loss: 0.30152360, dom-acc: 0.73107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 103.01171029, sen-loss: 26.73506825, dom-loss: 76.27664173, train-acc: 0.91339286, val-acc: 0.89000000 val_loss: 0.30151230, dom-acc: 0.72794643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.64932323, sen-loss: 26.28083090, dom-loss: 76.36849236, train-acc: 0.91125000, val-acc: 0.88500000 val_loss: 0.30298471, dom-acc: 0.72285714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 102.42450106, sen-loss: 26.05152120, dom-loss: 76.37297958, train-acc: 0.91750000, val-acc: 0.89000000 val_loss: 0.30103695, dom-acc: 0.71250000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 102.47789139, sen-loss: 25.84816611, dom-loss: 76.62972504, train-acc: 0.91857143, val-acc: 0.88750000 val_loss: 0.30060157, dom-acc: 0.70276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 102.32115763, sen-loss: 25.55172992, dom-loss: 76.76942766, train-acc: 0.91875000, val-acc: 0.89000000 val_loss: 0.30255836, dom-acc: 0.68276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.38932985, sen-loss: 25.23286470, dom-loss: 77.15646517, train-acc: 0.92053571, val-acc: 0.89000000 val_loss: 0.30064332, dom-acc: 0.65937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.49311793, sen-loss: 25.10466228, dom-loss: 77.38845551, train-acc: 0.92160714, val-acc: 0.88750000 val_loss: 0.30084157, dom-acc: 0.62625000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.68538761, sen-loss: 24.78089355, dom-loss: 77.90449405, train-acc: 0.92250000, val-acc: 0.89000000 val_loss: 0.30153069, dom-acc: 0.60883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 102.87289685, sen-loss: 24.74110761, dom-loss: 78.13178921, train-acc: 0.92250000, val-acc: 0.88750000 val_loss: 0.29949293, dom-acc: 0.58741071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 102.83792144, sen-loss: 24.31681945, dom-loss: 78.52110171, train-acc: 0.92285714, val-acc: 0.88500000 val_loss: 0.30650583, dom-acc: 0.55535714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 102.98541379, sen-loss: 24.20316068, dom-loss: 78.78225321, train-acc: 0.92482143, val-acc: 0.88250000 val_loss: 0.30348524, dom-acc: 0.54133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 102.76947325, sen-loss: 23.81108987, dom-loss: 78.95838362, train-acc: 0.92500000, val-acc: 0.88750000 val_loss: 0.29986125, dom-acc: 0.50642857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 102.91794163, sen-loss: 23.63798939, dom-loss: 79.27995247, train-acc: 0.92625000, val-acc: 0.89000000 val_loss: 0.30050159, dom-acc: 0.47008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 102.69250035, sen-loss: 23.25568705, dom-loss: 79.43681312, train-acc: 0.92785714, val-acc: 0.88250000 val_loss: 0.30297786, dom-acc: 0.48901786
---------------------------------------------------

Successfully load model from save path: ./work/models/books_electronics_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.29949293
Testing accuracy: 0.84366667
./work/attentions/books_electronics_train.txt
./work/pivots/books_electronics_pos.txt
./work/pivots/books_electronics_neg.txt
./work/attentions/books_electronics_test.txt
loading data...
source domain:  books target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 13856
vocab-size:  78006
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 17
max memory size: 20
78006
word_embedding done:  78007
5600 400 6000 15750 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78007, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 152.98876226, sen-loss: 76.63442153, dom-loss: 76.35434026, train-acc: 0.76500000, val-acc: 0.77000000 val_loss: 0.65242052, dom-acc: 0.88928571
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.86219358, sen-loss: 69.88717276, dom-loss: 70.97502017, train-acc: 0.77625000, val-acc: 0.75500000 val_loss: 0.58320981, dom-acc: 0.90062500
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 130.76751208, sen-loss: 60.71894100, dom-loss: 70.04857117, train-acc: 0.83232143, val-acc: 0.83250000 val_loss: 0.48616609, dom-acc: 0.86714286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 120.69124764, sen-loss: 50.06901574, dom-loss: 70.62223178, train-acc: 0.85928571, val-acc: 0.85750000 val_loss: 0.39636871, dom-acc: 0.84705357
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 112.87019575, sen-loss: 41.27554008, dom-loss: 71.59465587, train-acc: 0.87160714, val-acc: 0.87000000 val_loss: 0.34591472, dom-acc: 0.86303571
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 109.21085209, sen-loss: 36.91324212, dom-loss: 72.29760933, train-acc: 0.87642857, val-acc: 0.87000000 val_loss: 0.33338070, dom-acc: 0.80294643
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 108.74448377, sen-loss: 35.34592663, dom-loss: 73.39855731, train-acc: 0.88160714, val-acc: 0.86500000 val_loss: 0.33890787, dom-acc: 0.75598214
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 109.12211514, sen-loss: 34.27006383, dom-loss: 74.85205072, train-acc: 0.88250000, val-acc: 0.87500000 val_loss: 0.32630557, dom-acc: 0.70008929
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 110.10739911, sen-loss: 33.55493505, dom-loss: 76.55246359, train-acc: 0.88785714, val-acc: 0.87750000 val_loss: 0.32677364, dom-acc: 0.66062500
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 110.17295682, sen-loss: 32.65665942, dom-loss: 77.51629722, train-acc: 0.88803571, val-acc: 0.88000000 val_loss: 0.32070595, dom-acc: 0.61187500
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 111.68933618, sen-loss: 32.51475669, dom-loss: 79.17457914, train-acc: 0.89125000, val-acc: 0.88250000 val_loss: 0.32083559, dom-acc: 0.57178571
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 112.12483889, sen-loss: 31.69635347, dom-loss: 80.42848516, train-acc: 0.89232143, val-acc: 0.88250000 val_loss: 0.32069254, dom-acc: 0.53062500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 112.37455958, sen-loss: 31.17259359, dom-loss: 81.20196581, train-acc: 0.89178571, val-acc: 0.87500000 val_loss: 0.32767436, dom-acc: 0.51660714
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 112.75905275, sen-loss: 30.91335359, dom-loss: 81.84569955, train-acc: 0.89464286, val-acc: 0.87500000 val_loss: 0.31211972, dom-acc: 0.48214286
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 112.36515355, sen-loss: 30.50894018, dom-loss: 81.85621381, train-acc: 0.89035714, val-acc: 0.87500000 val_loss: 0.33557230, dom-acc: 0.49080357
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 111.74956548, sen-loss: 29.94710070, dom-loss: 81.80246514, train-acc: 0.90089286, val-acc: 0.89000000 val_loss: 0.30909002, dom-acc: 0.47598214
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 111.07212967, sen-loss: 29.71986997, dom-loss: 81.35225981, train-acc: 0.90053571, val-acc: 0.88250000 val_loss: 0.30756187, dom-acc: 0.49803571
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 109.87241197, sen-loss: 29.18675227, dom-loss: 80.68566006, train-acc: 0.90232143, val-acc: 0.89000000 val_loss: 0.30711716, dom-acc: 0.51383929
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 108.83672011, sen-loss: 28.90082957, dom-loss: 79.93589067, train-acc: 0.90410714, val-acc: 0.88750000 val_loss: 0.30785978, dom-acc: 0.54696429
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 107.69298673, sen-loss: 28.61876942, dom-loss: 79.07421756, train-acc: 0.90321429, val-acc: 0.88750000 val_loss: 0.31103832, dom-acc: 0.57741071
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 106.82719302, sen-loss: 28.35112579, dom-loss: 78.47606707, train-acc: 0.90750000, val-acc: 0.88750000 val_loss: 0.30747220, dom-acc: 0.60955357
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 105.86304402, sen-loss: 28.17812481, dom-loss: 77.68491864, train-acc: 0.90803571, val-acc: 0.89000000 val_loss: 0.30816990, dom-acc: 0.63892857
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 104.70037448, sen-loss: 27.64661506, dom-loss: 77.05375934, train-acc: 0.90857143, val-acc: 0.89000000 val_loss: 0.30681649, dom-acc: 0.66767857
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 103.97528088, sen-loss: 27.28639391, dom-loss: 76.68888706, train-acc: 0.90982143, val-acc: 0.89000000 val_loss: 0.31015852, dom-acc: 0.68491071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.35241044, sen-loss: 27.11745846, dom-loss: 76.23495173, train-acc: 0.91053571, val-acc: 0.89000000 val_loss: 0.30631003, dom-acc: 0.69258929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.98190343, sen-loss: 26.88409997, dom-loss: 76.09780383, train-acc: 0.91250000, val-acc: 0.89000000 val_loss: 0.30116734, dom-acc: 0.69401786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.67947352, sen-loss: 26.72367912, dom-loss: 75.95579457, train-acc: 0.91321429, val-acc: 0.89000000 val_loss: 0.30108935, dom-acc: 0.69410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.29116553, sen-loss: 26.27500273, dom-loss: 76.01616281, train-acc: 0.91160714, val-acc: 0.88500000 val_loss: 0.30241397, dom-acc: 0.67964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 102.10321116, sen-loss: 26.04045634, dom-loss: 76.06275505, train-acc: 0.91785714, val-acc: 0.88750000 val_loss: 0.30067325, dom-acc: 0.68616071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 102.15154183, sen-loss: 25.83347852, dom-loss: 76.31806296, train-acc: 0.91839286, val-acc: 0.88750000 val_loss: 0.30013648, dom-acc: 0.66750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 102.10154510, sen-loss: 25.54308867, dom-loss: 76.55845672, train-acc: 0.91964286, val-acc: 0.89000000 val_loss: 0.30216625, dom-acc: 0.65410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 102.14490992, sen-loss: 25.22152612, dom-loss: 76.92338353, train-acc: 0.92053571, val-acc: 0.89000000 val_loss: 0.30010262, dom-acc: 0.62883929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.49434847, sen-loss: 25.09676441, dom-loss: 77.39758396, train-acc: 0.92071429, val-acc: 0.89000000 val_loss: 0.30028862, dom-acc: 0.61062500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.56388801, sen-loss: 24.76732974, dom-loss: 77.79655838, train-acc: 0.92089286, val-acc: 0.88750000 val_loss: 0.30095410, dom-acc: 0.59366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 102.81732327, sen-loss: 24.73560768, dom-loss: 78.08171540, train-acc: 0.92232143, val-acc: 0.88750000 val_loss: 0.29915029, dom-acc: 0.58357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 102.88675719, sen-loss: 24.30122326, dom-loss: 78.58553410, train-acc: 0.92196429, val-acc: 0.88500000 val_loss: 0.30626309, dom-acc: 0.57625000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 102.93403459, sen-loss: 24.18575598, dom-loss: 78.74827862, train-acc: 0.92607143, val-acc: 0.88250000 val_loss: 0.30292568, dom-acc: 0.56571429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 102.68070185, sen-loss: 23.79906312, dom-loss: 78.88163871, train-acc: 0.92500000, val-acc: 0.89000000 val_loss: 0.29911104, dom-acc: 0.55000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 102.80287719, sen-loss: 23.62313277, dom-loss: 79.17974460, train-acc: 0.92660714, val-acc: 0.88750000 val_loss: 0.29975098, dom-acc: 0.54741071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 102.46088332, sen-loss: 23.24196406, dom-loss: 79.21891928, train-acc: 0.92714286, val-acc: 0.88250000 val_loss: 0.30228981, dom-acc: 0.55705357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 102.23082232, sen-loss: 23.02479568, dom-loss: 79.20602649, train-acc: 0.92964286, val-acc: 0.88250000 val_loss: 0.30000055, dom-acc: 0.54517857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [42 ] loss: 101.97923845, sen-loss: 22.91345711, dom-loss: 79.06578112, train-acc: 0.92910714, val-acc: 0.87750000 val_loss: 0.30452275, dom-acc: 0.54687500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [43 ] loss: 101.21242636, sen-loss: 22.50666779, dom-loss: 78.70575863, train-acc: 0.92892857, val-acc: 0.88750000 val_loss: 0.30903947, dom-acc: 0.56875000
---------------------------------------------------

Successfully load model from save path: ./work/models/books_kitchen_PNet.ckpt
Best Epoch: [ 38] best val accuracy: 0.00000000 best val loss: 0.29911104
Testing accuracy: 0.85550000
./work/attentions/books_kitchen_train.txt
./work/pivots/books_kitchen_pos.txt
./work/pivots/books_kitchen_neg.txt
./work/attentions/books_kitchen_test.txt
loading data...
source domain:  books target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  9750 30180
vocab-size:  98084
max  story size: 189
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
98084
word_embedding done:  98085
5600 400 6000 15750 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(98085, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 156.34039152, sen-loss: 76.63415653, dom-loss: 79.70623493, train-acc: 0.76517857, val-acc: 0.77000000 val_loss: 0.65243375, dom-acc: 0.67964286
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 146.17690504, sen-loss: 69.88859415, dom-loss: 76.28831077, train-acc: 0.77571429, val-acc: 0.75250000 val_loss: 0.58323938, dom-acc: 0.69366071
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 136.63645840, sen-loss: 60.72171676, dom-loss: 75.91474169, train-acc: 0.83178571, val-acc: 0.83250000 val_loss: 0.48626876, dom-acc: 0.64687500
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 125.95355380, sen-loss: 50.07163772, dom-loss: 75.88191617, train-acc: 0.85982143, val-acc: 0.85500000 val_loss: 0.39658263, dom-acc: 0.61214286
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 117.52171177, sen-loss: 41.25450365, dom-loss: 76.26720756, train-acc: 0.87250000, val-acc: 0.87000000 val_loss: 0.34597391, dom-acc: 0.68464286
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 112.88367027, sen-loss: 36.85725309, dom-loss: 76.02641720, train-acc: 0.87607143, val-acc: 0.86250000 val_loss: 0.33378005, dom-acc: 0.71348214
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.28194356, sen-loss: 35.29649748, dom-loss: 75.98544669, train-acc: 0.88267857, val-acc: 0.86500000 val_loss: 0.33955657, dom-acc: 0.70937500
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.38121152, sen-loss: 34.24907015, dom-loss: 76.13214159, train-acc: 0.88196429, val-acc: 0.87500000 val_loss: 0.32719994, dom-acc: 0.69794643
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 109.72192603, sen-loss: 33.53556989, dom-loss: 76.18635589, train-acc: 0.88803571, val-acc: 0.87750000 val_loss: 0.32799476, dom-acc: 0.69044643
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 108.60421646, sen-loss: 32.64587249, dom-loss: 75.95834428, train-acc: 0.88875000, val-acc: 0.88000000 val_loss: 0.32166168, dom-acc: 0.68625000
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.73639214, sen-loss: 32.49638630, dom-loss: 76.24000645, train-acc: 0.89071429, val-acc: 0.88500000 val_loss: 0.32190037, dom-acc: 0.68732143
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 108.08328247, sen-loss: 31.68154445, dom-loss: 76.40173775, train-acc: 0.89303571, val-acc: 0.89000000 val_loss: 0.32132110, dom-acc: 0.68062500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 107.61535215, sen-loss: 31.16355951, dom-loss: 76.45179290, train-acc: 0.89178571, val-acc: 0.87250000 val_loss: 0.32840633, dom-acc: 0.68071429
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 107.58769226, sen-loss: 30.90216026, dom-loss: 76.68553168, train-acc: 0.89500000, val-acc: 0.87250000 val_loss: 0.31324071, dom-acc: 0.67062500
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 107.03680682, sen-loss: 30.49243817, dom-loss: 76.54436821, train-acc: 0.89035714, val-acc: 0.87250000 val_loss: 0.33531243, dom-acc: 0.68169643
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.74891359, sen-loss: 29.92582667, dom-loss: 76.82308728, train-acc: 0.90107143, val-acc: 0.89500000 val_loss: 0.31004491, dom-acc: 0.66098214
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 106.67660540, sen-loss: 29.70205206, dom-loss: 76.97455311, train-acc: 0.89982143, val-acc: 0.88000000 val_loss: 0.30886370, dom-acc: 0.65812500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 106.14040333, sen-loss: 29.17538367, dom-loss: 76.96501982, train-acc: 0.90232143, val-acc: 0.89500000 val_loss: 0.30823335, dom-acc: 0.65642857
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 106.00148696, sen-loss: 28.88487971, dom-loss: 77.11660725, train-acc: 0.90535714, val-acc: 0.89000000 val_loss: 0.30901268, dom-acc: 0.65339286
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 105.78639233, sen-loss: 28.60671357, dom-loss: 77.17967874, train-acc: 0.90535714, val-acc: 0.88750000 val_loss: 0.31243220, dom-acc: 0.65687500
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 105.60220701, sen-loss: 28.33280560, dom-loss: 77.26940143, train-acc: 0.90750000, val-acc: 0.89000000 val_loss: 0.30862251, dom-acc: 0.65696429
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 105.41198736, sen-loss: 28.14992904, dom-loss: 77.26205760, train-acc: 0.90785714, val-acc: 0.89000000 val_loss: 0.30951762, dom-acc: 0.64812500
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 105.13012779, sen-loss: 27.63529452, dom-loss: 77.49483359, train-acc: 0.90910714, val-acc: 0.89000000 val_loss: 0.30814010, dom-acc: 0.64500000
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 104.85098130, sen-loss: 27.28005096, dom-loss: 77.57093036, train-acc: 0.91000000, val-acc: 0.89250000 val_loss: 0.31172028, dom-acc: 0.64767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 104.55511779, sen-loss: 27.10414720, dom-loss: 77.45097065, train-acc: 0.91089286, val-acc: 0.89000000 val_loss: 0.30749071, dom-acc: 0.64026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 104.42165780, sen-loss: 26.88043211, dom-loss: 77.54122561, train-acc: 0.91285714, val-acc: 0.89000000 val_loss: 0.30251658, dom-acc: 0.63196429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 104.36341161, sen-loss: 26.72202843, dom-loss: 77.64138323, train-acc: 0.91464286, val-acc: 0.88750000 val_loss: 0.30261156, dom-acc: 0.62428571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 104.02846909, sen-loss: 26.26757061, dom-loss: 77.76089883, train-acc: 0.91160714, val-acc: 0.88500000 val_loss: 0.30398661, dom-acc: 0.62241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 103.70198148, sen-loss: 26.04131753, dom-loss: 77.66066378, train-acc: 0.91750000, val-acc: 0.89250000 val_loss: 0.30191985, dom-acc: 0.62875000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 103.67885739, sen-loss: 25.84394943, dom-loss: 77.83490837, train-acc: 0.91714286, val-acc: 0.89250000 val_loss: 0.30134836, dom-acc: 0.62392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 103.30673182, sen-loss: 25.54130144, dom-loss: 77.76543081, train-acc: 0.91839286, val-acc: 0.89000000 val_loss: 0.30326879, dom-acc: 0.62937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 103.08855367, sen-loss: 25.22206523, dom-loss: 77.86648858, train-acc: 0.91982143, val-acc: 0.89250000 val_loss: 0.30140558, dom-acc: 0.61571429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 102.86810249, sen-loss: 25.09601714, dom-loss: 77.77208477, train-acc: 0.92142857, val-acc: 0.88750000 val_loss: 0.30154100, dom-acc: 0.61035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 102.77580810, sen-loss: 24.76839989, dom-loss: 78.00740856, train-acc: 0.92142857, val-acc: 0.89000000 val_loss: 0.30203405, dom-acc: 0.61223214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 102.59872442, sen-loss: 24.72786617, dom-loss: 77.87085855, train-acc: 0.92267857, val-acc: 0.89000000 val_loss: 0.30003065, dom-acc: 0.61973214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 102.20888388, sen-loss: 24.30582692, dom-loss: 77.90305704, train-acc: 0.92232143, val-acc: 0.88250000 val_loss: 0.30710652, dom-acc: 0.62107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 102.10236257, sen-loss: 24.20063117, dom-loss: 77.90173155, train-acc: 0.92535714, val-acc: 0.88500000 val_loss: 0.30380097, dom-acc: 0.62437500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 101.96145356, sen-loss: 23.80826654, dom-loss: 78.15318686, train-acc: 0.92428571, val-acc: 0.88750000 val_loss: 0.30020329, dom-acc: 0.59982143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 101.59023672, sen-loss: 23.63360135, dom-loss: 77.95663518, train-acc: 0.92732143, val-acc: 0.88750000 val_loss: 0.30081943, dom-acc: 0.60803571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 101.31539977, sen-loss: 23.25156390, dom-loss: 78.06383592, train-acc: 0.92875000, val-acc: 0.88500000 val_loss: 0.30308041, dom-acc: 0.61866071
---------------------------------------------------

Successfully load model from save path: ./work/models/books_video_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.30003065
Testing accuracy: 0.87816667
./work/attentions/books_video_train.txt
./work/pivots/books_video_pos.txt
./work/pivots/books_video_neg.txt
./work/attentions/books_video_test.txt
loading data...
source domain:  dvd target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 9750
vocab-size:  100530
max  story size: 226
mean story size: 8
max  sentence size: 783
mean sentence size: 19
max memory size: 20
100530
word_embedding done:  100531
5600 400 6000 17843 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(100531, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 157.88473225, sen-loss: 76.95861518, dom-loss: 80.92611700, train-acc: 0.75482143, val-acc: 0.75500000 val_loss: 0.65731001, dom-acc: 0.62196429
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 148.64806426, sen-loss: 71.18148249, dom-loss: 77.46658188, train-acc: 0.76910714, val-acc: 0.79250000 val_loss: 0.59568924, dom-acc: 0.77294643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 139.51232493, sen-loss: 63.13128701, dom-loss: 76.38103658, train-acc: 0.82035714, val-acc: 0.83250000 val_loss: 0.50309670, dom-acc: 0.79964286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 129.07900071, sen-loss: 53.57855988, dom-loss: 75.50044084, train-acc: 0.84410714, val-acc: 0.86250000 val_loss: 0.40945941, dom-acc: 0.76258929
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 119.60776854, sen-loss: 44.48156342, dom-loss: 75.12620455, train-acc: 0.85053571, val-acc: 0.87500000 val_loss: 0.33992282, dom-acc: 0.72803571
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 113.86680084, sen-loss: 39.05126108, dom-loss: 74.81553990, train-acc: 0.86696429, val-acc: 0.88000000 val_loss: 0.31736088, dom-acc: 0.74151786
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.68652105, sen-loss: 37.16172306, dom-loss: 74.52479762, train-acc: 0.87607143, val-acc: 0.90000000 val_loss: 0.30126476, dom-acc: 0.74080357
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.98214930, sen-loss: 36.41069889, dom-loss: 74.57145023, train-acc: 0.87750000, val-acc: 0.89750000 val_loss: 0.29713839, dom-acc: 0.73500000
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 109.94984436, sen-loss: 35.39354591, dom-loss: 74.55629838, train-acc: 0.88196429, val-acc: 0.90250000 val_loss: 0.29667574, dom-acc: 0.73937500
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 109.34828764, sen-loss: 34.59594864, dom-loss: 74.75233811, train-acc: 0.87464286, val-acc: 0.89750000 val_loss: 0.30813420, dom-acc: 0.73401786
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.71205401, sen-loss: 34.08444202, dom-loss: 74.62761217, train-acc: 0.88214286, val-acc: 0.89750000 val_loss: 0.29645136, dom-acc: 0.73053571
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 108.46752977, sen-loss: 33.62183074, dom-loss: 74.84569854, train-acc: 0.88678571, val-acc: 0.89500000 val_loss: 0.29328069, dom-acc: 0.72750000
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 108.42706507, sen-loss: 33.28180757, dom-loss: 75.14525765, train-acc: 0.87892857, val-acc: 0.89000000 val_loss: 0.31117266, dom-acc: 0.72142857
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 108.02070361, sen-loss: 32.94779812, dom-loss: 75.07290542, train-acc: 0.88857143, val-acc: 0.90000000 val_loss: 0.29314715, dom-acc: 0.71937500
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 107.43336910, sen-loss: 32.29644613, dom-loss: 75.13692302, train-acc: 0.88875000, val-acc: 0.90750000 val_loss: 0.29014295, dom-acc: 0.71651786
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 107.38357729, sen-loss: 31.93848027, dom-loss: 75.44509679, train-acc: 0.89053571, val-acc: 0.90250000 val_loss: 0.28930247, dom-acc: 0.71375000
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 107.17322522, sen-loss: 31.70318988, dom-loss: 75.47003573, train-acc: 0.89285714, val-acc: 0.90500000 val_loss: 0.28893477, dom-acc: 0.71000000
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 106.86740792, sen-loss: 31.28287727, dom-loss: 75.58453059, train-acc: 0.89553571, val-acc: 0.90750000 val_loss: 0.29073119, dom-acc: 0.70651786
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 106.78954047, sen-loss: 30.95787697, dom-loss: 75.83166355, train-acc: 0.89642857, val-acc: 0.90500000 val_loss: 0.28965548, dom-acc: 0.70517857
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 106.59455794, sen-loss: 30.77015661, dom-loss: 75.82440168, train-acc: 0.89125000, val-acc: 0.89000000 val_loss: 0.30051735, dom-acc: 0.70062500
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 106.46980268, sen-loss: 30.43695668, dom-loss: 76.03284615, train-acc: 0.89696429, val-acc: 0.90750000 val_loss: 0.29299304, dom-acc: 0.70098214
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 106.22370917, sen-loss: 30.23301917, dom-loss: 75.99068981, train-acc: 0.89446429, val-acc: 0.88500000 val_loss: 0.30384234, dom-acc: 0.69482143
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_books_PNet.ckpt
Best Epoch: [ 17] best val accuracy: 0.00000000 best val loss: 0.28893477
Testing accuracy: 0.87350000
./work/attentions/dvd_books_train.txt
./work/pivots/dvd_books_pos.txt
./work/pivots/dvd_books_neg.txt
./work/attentions/dvd_books_test.txt
loading data...
source domain:  dvd target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 17009
vocab-size:  85442
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 18
max memory size: 20
85442
word_embedding done:  85443
5600 400 6000 17843 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(85443, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.54160392, sen-loss: 76.95906717, dom-loss: 77.58253771, train-acc: 0.75464286, val-acc: 0.75750000 val_loss: 0.65733904, dom-acc: 0.87500000
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 143.66043019, sen-loss: 71.18561387, dom-loss: 72.47481686, train-acc: 0.76910714, val-acc: 0.79250000 val_loss: 0.59571731, dom-acc: 0.89089286
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 134.34984601, sen-loss: 63.12989295, dom-loss: 71.21995360, train-acc: 0.82053571, val-acc: 0.83500000 val_loss: 0.50283712, dom-acc: 0.85535714
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 125.05489874, sen-loss: 53.53904384, dom-loss: 71.51585442, train-acc: 0.84517857, val-acc: 0.86500000 val_loss: 0.40830067, dom-acc: 0.84053571
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 116.63821220, sen-loss: 44.39170107, dom-loss: 72.24651074, train-acc: 0.85017857, val-acc: 0.87500000 val_loss: 0.33868554, dom-acc: 0.87776786
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 112.23837173, sen-loss: 39.02717340, dom-loss: 73.21119857, train-acc: 0.86642857, val-acc: 0.88250000 val_loss: 0.31711629, dom-acc: 0.83535714
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.55764705, sen-loss: 37.15532948, dom-loss: 74.40231729, train-acc: 0.87660714, val-acc: 0.89750000 val_loss: 0.30105394, dom-acc: 0.76964286
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 112.49145418, sen-loss: 36.40038782, dom-loss: 76.09106636, train-acc: 0.87625000, val-acc: 0.89750000 val_loss: 0.29703486, dom-acc: 0.68357143
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 113.06213063, sen-loss: 35.38063575, dom-loss: 77.68149459, train-acc: 0.88232143, val-acc: 0.90000000 val_loss: 0.29663923, dom-acc: 0.61062500
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 113.98564792, sen-loss: 34.57835355, dom-loss: 79.40729392, train-acc: 0.87446429, val-acc: 0.89750000 val_loss: 0.30834448, dom-acc: 0.54008929
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 114.42286724, sen-loss: 34.06747937, dom-loss: 80.35538775, train-acc: 0.88321429, val-acc: 0.89750000 val_loss: 0.29634070, dom-acc: 0.49142857
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 114.92439103, sen-loss: 33.60296076, dom-loss: 81.32143015, train-acc: 0.88678571, val-acc: 0.89750000 val_loss: 0.29329172, dom-acc: 0.43857143
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 115.18052387, sen-loss: 33.26030049, dom-loss: 81.92022359, train-acc: 0.87857143, val-acc: 0.89000000 val_loss: 0.31142575, dom-acc: 0.39660714
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 114.99591106, sen-loss: 32.93279825, dom-loss: 82.06311303, train-acc: 0.88714286, val-acc: 0.90000000 val_loss: 0.29328778, dom-acc: 0.38375000
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 114.12474346, sen-loss: 32.28264804, dom-loss: 81.84209549, train-acc: 0.88946429, val-acc: 0.90500000 val_loss: 0.28999653, dom-acc: 0.37955357
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 113.24127787, sen-loss: 31.92760029, dom-loss: 81.31367767, train-acc: 0.89017857, val-acc: 0.90000000 val_loss: 0.28924936, dom-acc: 0.41812500
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 112.45866013, sen-loss: 31.68806207, dom-loss: 80.77059782, train-acc: 0.89178571, val-acc: 0.90000000 val_loss: 0.28867969, dom-acc: 0.39794643
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 111.28078574, sen-loss: 31.27048230, dom-loss: 80.01030350, train-acc: 0.89517857, val-acc: 0.90250000 val_loss: 0.29042760, dom-acc: 0.46892857
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 110.31616282, sen-loss: 30.94870713, dom-loss: 79.36745584, train-acc: 0.89660714, val-acc: 0.89750000 val_loss: 0.28917137, dom-acc: 0.51982143
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 109.41029930, sen-loss: 30.75913008, dom-loss: 78.65116948, train-acc: 0.89446429, val-acc: 0.89500000 val_loss: 0.30018786, dom-acc: 0.57991071
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 108.48963845, sen-loss: 30.43193891, dom-loss: 78.05769938, train-acc: 0.89732143, val-acc: 0.90750000 val_loss: 0.29243487, dom-acc: 0.61866071
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 107.70255357, sen-loss: 30.23604412, dom-loss: 77.46650982, train-acc: 0.89410714, val-acc: 0.89000000 val_loss: 0.30361891, dom-acc: 0.65187500
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_electronics_PNet.ckpt
Best Epoch: [ 17] best val accuracy: 0.00000000 best val loss: 0.28867969
Testing accuracy: 0.85000000
./work/attentions/dvd_electronics_train.txt
./work/pivots/dvd_electronics_pos.txt
./work/pivots/dvd_electronics_neg.txt
./work/attentions/dvd_electronics_test.txt
loading data...
source domain:  dvd target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 13856
vocab-size:  80685
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 17
max memory size: 20
80685
word_embedding done:  80686
5600 400 6000 17843 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(80686, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.07819557, sen-loss: 76.95870864, dom-loss: 77.11948752, train-acc: 0.75482143, val-acc: 0.75500000 val_loss: 0.65731168, dom-acc: 0.87910714
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 143.38705909, sen-loss: 71.18202865, dom-loss: 72.20503080, train-acc: 0.76910714, val-acc: 0.79250000 val_loss: 0.59568900, dom-acc: 0.90285714
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 134.13811946, sen-loss: 63.12209967, dom-loss: 71.01601964, train-acc: 0.82125000, val-acc: 0.83250000 val_loss: 0.50291616, dom-acc: 0.89839286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 124.78656960, sen-loss: 53.53380316, dom-loss: 71.25276619, train-acc: 0.84446429, val-acc: 0.86500000 val_loss: 0.40868264, dom-acc: 0.89383929
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 116.05599773, sen-loss: 44.38931334, dom-loss: 71.66668391, train-acc: 0.84982143, val-acc: 0.87500000 val_loss: 0.33924490, dom-acc: 0.81910714
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.54002810, sen-loss: 39.01839244, dom-loss: 72.52163577, train-acc: 0.86678571, val-acc: 0.88250000 val_loss: 0.31723627, dom-acc: 0.78142857
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 110.64976412, sen-loss: 37.15015125, dom-loss: 73.49961299, train-acc: 0.87696429, val-acc: 0.89750000 val_loss: 0.30121472, dom-acc: 0.73241071
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 111.68160301, sen-loss: 36.39356272, dom-loss: 75.28804034, train-acc: 0.87660714, val-acc: 0.89750000 val_loss: 0.29706883, dom-acc: 0.67883929
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 112.23721164, sen-loss: 35.37427430, dom-loss: 76.86293739, train-acc: 0.88178571, val-acc: 0.90000000 val_loss: 0.29653314, dom-acc: 0.64392857
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 112.84496886, sen-loss: 34.57811950, dom-loss: 78.26684934, train-acc: 0.87392857, val-acc: 0.89500000 val_loss: 0.30830646, dom-acc: 0.60812500
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 113.31996727, sen-loss: 34.06512403, dom-loss: 79.25484341, train-acc: 0.88160714, val-acc: 0.89750000 val_loss: 0.29625043, dom-acc: 0.56526786
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 114.27979761, sen-loss: 33.60569745, dom-loss: 80.67409992, train-acc: 0.88696429, val-acc: 0.89750000 val_loss: 0.29341117, dom-acc: 0.52276786
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 114.61506975, sen-loss: 33.26031016, dom-loss: 81.35475934, train-acc: 0.87803571, val-acc: 0.88750000 val_loss: 0.31214967, dom-acc: 0.51553571
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 114.59801525, sen-loss: 32.93686835, dom-loss: 81.66114712, train-acc: 0.88821429, val-acc: 0.89750000 val_loss: 0.29327798, dom-acc: 0.48928571
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 113.90155321, sen-loss: 32.28029813, dom-loss: 81.62125510, train-acc: 0.88964286, val-acc: 0.90250000 val_loss: 0.29026258, dom-acc: 0.47491071
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 113.28383988, sen-loss: 31.93095243, dom-loss: 81.35288769, train-acc: 0.89035714, val-acc: 0.89750000 val_loss: 0.28947490, dom-acc: 0.49044643
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 112.50686973, sen-loss: 31.68723576, dom-loss: 80.81963372, train-acc: 0.89250000, val-acc: 0.90000000 val_loss: 0.28908166, dom-acc: 0.49544643
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 111.33470339, sen-loss: 31.27244172, dom-loss: 80.06226182, train-acc: 0.89607143, val-acc: 0.90750000 val_loss: 0.29103979, dom-acc: 0.52366071
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 110.37102580, sen-loss: 30.94792415, dom-loss: 79.42310202, train-acc: 0.89660714, val-acc: 0.90500000 val_loss: 0.28987196, dom-acc: 0.55732143
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 109.31689024, sen-loss: 30.76234606, dom-loss: 78.55454409, train-acc: 0.89321429, val-acc: 0.89500000 val_loss: 0.30048802, dom-acc: 0.60178571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 108.51965606, sen-loss: 30.43189174, dom-loss: 78.08776468, train-acc: 0.89803571, val-acc: 0.90500000 val_loss: 0.29305679, dom-acc: 0.62125000
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 107.62213570, sen-loss: 30.23264198, dom-loss: 77.38949394, train-acc: 0.89446429, val-acc: 0.88750000 val_loss: 0.30414990, dom-acc: 0.65446429
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_kitchen_PNet.ckpt
Best Epoch: [ 17] best val accuracy: 0.00000000 best val loss: 0.28908166
Testing accuracy: 0.85300000
./work/attentions/dvd_kitchen_train.txt
./work/pivots/dvd_kitchen_pos.txt
./work/pivots/dvd_kitchen_neg.txt
./work/attentions/dvd_kitchen_test.txt
loading data...
source domain:  dvd target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  11843 30180
vocab-size:  91852
max  story size: 226
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
91852
word_embedding done:  91853
5600 400 6000 17843 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(91853, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 158.03327847, sen-loss: 76.95882028, dom-loss: 81.07445782, train-acc: 0.75410714, val-acc: 0.75250000 val_loss: 0.65731931, dom-acc: 0.46392857
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 150.21649158, sen-loss: 71.18242335, dom-loss: 79.03406876, train-acc: 0.76928571, val-acc: 0.79000000 val_loss: 0.59570330, dom-acc: 0.49705357
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 141.99051690, sen-loss: 63.13328969, dom-loss: 78.85722750, train-acc: 0.82053571, val-acc: 0.83250000 val_loss: 0.50312060, dom-acc: 0.59330357
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 131.98472369, sen-loss: 53.58166519, dom-loss: 78.40305853, train-acc: 0.84375000, val-acc: 0.86250000 val_loss: 0.40939847, dom-acc: 0.64723214
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 122.48634338, sen-loss: 44.47412458, dom-loss: 78.01221859, train-acc: 0.85035714, val-acc: 0.87500000 val_loss: 0.33989114, dom-acc: 0.63500000
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 116.72096187, sen-loss: 39.04914683, dom-loss: 77.67181480, train-acc: 0.86803571, val-acc: 0.88000000 val_loss: 0.31718174, dom-acc: 0.65348214
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 114.67657882, sen-loss: 37.16187754, dom-loss: 77.51470131, train-acc: 0.87732143, val-acc: 0.90000000 val_loss: 0.30101717, dom-acc: 0.65714286
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 113.88635647, sen-loss: 36.42089956, dom-loss: 77.46545732, train-acc: 0.87589286, val-acc: 0.89750000 val_loss: 0.29682517, dom-acc: 0.65071429
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 112.63195372, sen-loss: 35.39781058, dom-loss: 77.23414308, train-acc: 0.88214286, val-acc: 0.90000000 val_loss: 0.29643139, dom-acc: 0.65696429
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 111.85072505, sen-loss: 34.59858407, dom-loss: 77.25214112, train-acc: 0.87428571, val-acc: 0.89750000 val_loss: 0.30809608, dom-acc: 0.66803571
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 111.20759159, sen-loss: 34.08445731, dom-loss: 77.12313479, train-acc: 0.88267857, val-acc: 0.90000000 val_loss: 0.29602545, dom-acc: 0.66776786
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 110.72839582, sen-loss: 33.61467528, dom-loss: 77.11372024, train-acc: 0.88785714, val-acc: 0.89750000 val_loss: 0.29290837, dom-acc: 0.66017857
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 110.35209435, sen-loss: 33.27131449, dom-loss: 77.08078015, train-acc: 0.87946429, val-acc: 0.89000000 val_loss: 0.31083378, dom-acc: 0.67535714
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 110.11391711, sen-loss: 32.94135720, dom-loss: 77.17256010, train-acc: 0.88732143, val-acc: 0.90000000 val_loss: 0.29298466, dom-acc: 0.66473214
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.03081506, sen-loss: 32.29609554, dom-loss: 76.73471969, train-acc: 0.88910714, val-acc: 0.90500000 val_loss: 0.29001138, dom-acc: 0.65625000
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 108.88458341, sen-loss: 31.94174885, dom-loss: 76.94283497, train-acc: 0.89196429, val-acc: 0.90250000 val_loss: 0.28924131, dom-acc: 0.66482143
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 108.55059570, sen-loss: 31.70143023, dom-loss: 76.84916604, train-acc: 0.89285714, val-acc: 0.90250000 val_loss: 0.28890660, dom-acc: 0.65812500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 108.18198758, sen-loss: 31.28150088, dom-loss: 76.90048695, train-acc: 0.89553571, val-acc: 0.90500000 val_loss: 0.29063118, dom-acc: 0.66687500
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 107.84393871, sen-loss: 30.96145901, dom-loss: 76.88247949, train-acc: 0.89785714, val-acc: 0.90000000 val_loss: 0.28975564, dom-acc: 0.66285714
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 107.35644948, sen-loss: 30.77647748, dom-loss: 76.57997227, train-acc: 0.89142857, val-acc: 0.89000000 val_loss: 0.30064788, dom-acc: 0.67303571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 107.34863329, sen-loss: 30.44164678, dom-loss: 76.90698647, train-acc: 0.89642857, val-acc: 0.90750000 val_loss: 0.29315370, dom-acc: 0.67008929
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 106.99782205, sen-loss: 30.24732885, dom-loss: 76.75049305, train-acc: 0.89214286, val-acc: 0.89000000 val_loss: 0.30446199, dom-acc: 0.67303571
---------------------------------------------------

Successfully load model from save path: ./work/models/dvd_video_PNet.ckpt
Best Epoch: [ 17] best val accuracy: 0.00000000 best val loss: 0.28890660
Testing accuracy: 0.88416667
./work/attentions/dvd_video_train.txt
./work/pivots/dvd_video_pos.txt
./work/pivots/dvd_video_neg.txt
./work/attentions/dvd_video_test.txt
loading data...
source domain:  electronics target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 9750
vocab-size:  83050
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 18
max memory size: 20
83050
word_embedding done:  83051
5600 400 6000 23009 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83051, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.84465158, sen-loss: 75.30518931, dom-loss: 80.53946245, train-acc: 0.78285714, val-acc: 0.81250000 val_loss: 0.62905055, dom-acc: 0.81241071
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 138.92026460, sen-loss: 64.73283860, dom-loss: 74.18742585, train-acc: 0.82053571, val-acc: 0.85500000 val_loss: 0.49968410, dom-acc: 0.80803571
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 123.07996851, sen-loss: 51.73805651, dom-loss: 71.34191203, train-acc: 0.82500000, val-acc: 0.85000000 val_loss: 0.41437352, dom-acc: 0.66517857
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 117.10738486, sen-loss: 46.16435143, dom-loss: 70.94303322, train-acc: 0.83821429, val-acc: 0.87000000 val_loss: 0.36273944, dom-acc: 0.64526786
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 113.31666017, sen-loss: 41.92319030, dom-loss: 71.39346969, train-acc: 0.86000000, val-acc: 0.89000000 val_loss: 0.32510769, dom-acc: 0.64116071
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.04602242, sen-loss: 38.55510724, dom-loss: 72.49091494, train-acc: 0.87267857, val-acc: 0.88250000 val_loss: 0.30247712, dom-acc: 0.65133929
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 109.29270738, sen-loss: 36.01915230, dom-loss: 73.27355498, train-acc: 0.87964286, val-acc: 0.90250000 val_loss: 0.27948168, dom-acc: 0.63875000
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 108.64006835, sen-loss: 34.43836586, dom-loss: 74.20170248, train-acc: 0.88339286, val-acc: 0.91250000 val_loss: 0.26246512, dom-acc: 0.61142857
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 108.82564974, sen-loss: 33.43902026, dom-loss: 75.38662970, train-acc: 0.88642857, val-acc: 0.91250000 val_loss: 0.25499994, dom-acc: 0.59660714
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 108.60717839, sen-loss: 32.29908490, dom-loss: 76.30809391, train-acc: 0.89214286, val-acc: 0.91250000 val_loss: 0.24838118, dom-acc: 0.56383929
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.69410574, sen-loss: 31.56773399, dom-loss: 77.12637186, train-acc: 0.89160714, val-acc: 0.91250000 val_loss: 0.24252409, dom-acc: 0.51133929
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 109.12597734, sen-loss: 30.97919998, dom-loss: 78.14677721, train-acc: 0.89803571, val-acc: 0.91250000 val_loss: 0.24432018, dom-acc: 0.46705357
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 109.19965446, sen-loss: 30.31902322, dom-loss: 78.88063097, train-acc: 0.90142857, val-acc: 0.92000000 val_loss: 0.23681152, dom-acc: 0.43750000
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 109.22171605, sen-loss: 29.67718996, dom-loss: 79.54452592, train-acc: 0.90303571, val-acc: 0.92250000 val_loss: 0.23404047, dom-acc: 0.40035714
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.46250015, sen-loss: 29.34418823, dom-loss: 80.11831188, train-acc: 0.90517857, val-acc: 0.92000000 val_loss: 0.23034710, dom-acc: 0.37446429
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 109.23752522, sen-loss: 28.74690612, dom-loss: 80.49061865, train-acc: 0.89857143, val-acc: 0.91500000 val_loss: 0.23336147, dom-acc: 0.36267857
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 109.07672197, sen-loss: 28.37467285, dom-loss: 80.70204902, train-acc: 0.90750000, val-acc: 0.92250000 val_loss: 0.22680610, dom-acc: 0.34223214
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 108.62962490, sen-loss: 27.79625163, dom-loss: 80.83337325, train-acc: 0.90642857, val-acc: 0.91750000 val_loss: 0.23856637, dom-acc: 0.33205357
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 108.29542863, sen-loss: 27.62347408, dom-loss: 80.67195475, train-acc: 0.90982143, val-acc: 0.92750000 val_loss: 0.22317775, dom-acc: 0.33464286
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 107.52974212, sen-loss: 27.15739642, dom-loss: 80.37234575, train-acc: 0.91017857, val-acc: 0.92750000 val_loss: 0.22242555, dom-acc: 0.34982143
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 107.03615630, sen-loss: 26.66795551, dom-loss: 80.36820084, train-acc: 0.91178571, val-acc: 0.93000000 val_loss: 0.22064222, dom-acc: 0.37223214
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 106.31845832, sen-loss: 26.46700662, dom-loss: 79.85145211, train-acc: 0.91357143, val-acc: 0.92250000 val_loss: 0.22173040, dom-acc: 0.37473214
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 105.91537285, sen-loss: 26.24980471, dom-loss: 79.66556835, train-acc: 0.91428571, val-acc: 0.93000000 val_loss: 0.21754417, dom-acc: 0.40392857
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 104.88842809, sen-loss: 25.77921127, dom-loss: 79.10921687, train-acc: 0.91625000, val-acc: 0.92500000 val_loss: 0.22120066, dom-acc: 0.42848214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 104.21083283, sen-loss: 25.38217141, dom-loss: 78.82866108, train-acc: 0.91910714, val-acc: 0.93250000 val_loss: 0.21673456, dom-acc: 0.46026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 103.53596777, sen-loss: 25.08171410, dom-loss: 78.45425385, train-acc: 0.91892857, val-acc: 0.93500000 val_loss: 0.21537496, dom-acc: 0.47901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.81458509, sen-loss: 24.78700947, dom-loss: 78.02757555, train-acc: 0.91964286, val-acc: 0.92750000 val_loss: 0.21403754, dom-acc: 0.48785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.17880005, sen-loss: 24.56183596, dom-loss: 77.61696440, train-acc: 0.92214286, val-acc: 0.93250000 val_loss: 0.21550150, dom-acc: 0.49562500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.91142690, sen-loss: 24.36003534, dom-loss: 77.55139118, train-acc: 0.92125000, val-acc: 0.92750000 val_loss: 0.21268350, dom-acc: 0.52750000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.25934947, sen-loss: 24.05891958, dom-loss: 77.20042992, train-acc: 0.92410714, val-acc: 0.93000000 val_loss: 0.21480797, dom-acc: 0.53419643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.66318887, sen-loss: 23.69520463, dom-loss: 76.96798438, train-acc: 0.92642857, val-acc: 0.93000000 val_loss: 0.21416651, dom-acc: 0.52241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.49643224, sen-loss: 23.47846852, dom-loss: 77.01796359, train-acc: 0.92553571, val-acc: 0.93000000 val_loss: 0.21750709, dom-acc: 0.55267857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 99.97296745, sen-loss: 23.23619645, dom-loss: 76.73677081, train-acc: 0.92714286, val-acc: 0.92750000 val_loss: 0.21305081, dom-acc: 0.53330357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.89737010, sen-loss: 23.02981893, dom-loss: 76.86755115, train-acc: 0.92928571, val-acc: 0.92750000 val_loss: 0.21190389, dom-acc: 0.58089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.54185855, sen-loss: 22.70534196, dom-loss: 76.83651638, train-acc: 0.93035714, val-acc: 0.93000000 val_loss: 0.21120647, dom-acc: 0.56241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.49329346, sen-loss: 22.70749976, dom-loss: 76.78579390, train-acc: 0.93017857, val-acc: 0.92500000 val_loss: 0.21190873, dom-acc: 0.53946429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.11471832, sen-loss: 22.30150742, dom-loss: 76.81321067, train-acc: 0.93089286, val-acc: 0.92500000 val_loss: 0.21146581, dom-acc: 0.50151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.21923751, sen-loss: 22.10734179, dom-loss: 77.11189574, train-acc: 0.93250000, val-acc: 0.92500000 val_loss: 0.21186936, dom-acc: 0.53125000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 98.94496125, sen-loss: 21.85136703, dom-loss: 77.09359419, train-acc: 0.93321429, val-acc: 0.92500000 val_loss: 0.21202093, dom-acc: 0.52580357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.69735241, sen-loss: 21.44496660, dom-loss: 77.25238580, train-acc: 0.93535714, val-acc: 0.92500000 val_loss: 0.21463382, dom-acc: 0.52705357
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_books_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.21120647
Testing accuracy: 0.83166667
./work/attentions/electronics_books_train.txt
./work/pivots/electronics_books_pos.txt
./work/pivots/electronics_books_neg.txt
./work/attentions/electronics_books_test.txt
loading data...
source domain:  electronics target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 11843
vocab-size:  85442
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 18
max memory size: 20
85442
word_embedding done:  85443
5600 400 6000 23009 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(85443, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.68767405, sen-loss: 75.30501223, dom-loss: 80.38266057, train-acc: 0.78303571, val-acc: 0.81250000 val_loss: 0.62904048, dom-acc: 0.77035714
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 139.60858130, sen-loss: 64.73086804, dom-loss: 74.87771356, train-acc: 0.82017857, val-acc: 0.85500000 val_loss: 0.49966881, dom-acc: 0.75285714
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 124.13859355, sen-loss: 51.75065562, dom-loss: 72.38793832, train-acc: 0.82517857, val-acc: 0.85250000 val_loss: 0.41462320, dom-acc: 0.63107143
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 118.08295721, sen-loss: 46.22572443, dom-loss: 71.85723275, train-acc: 0.83785714, val-acc: 0.87000000 val_loss: 0.36335796, dom-acc: 0.61473214
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 113.90249449, sen-loss: 42.01086941, dom-loss: 71.89162546, train-acc: 0.85910714, val-acc: 0.89000000 val_loss: 0.32588744, dom-acc: 0.60348214
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.56754625, sen-loss: 38.64733458, dom-loss: 72.92021197, train-acc: 0.87285714, val-acc: 0.87750000 val_loss: 0.30319196, dom-acc: 0.59660714
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 109.68107110, sen-loss: 36.09362909, dom-loss: 73.58744174, train-acc: 0.87964286, val-acc: 0.89750000 val_loss: 0.27994132, dom-acc: 0.58303571
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 108.85518658, sen-loss: 34.48952575, dom-loss: 74.36566120, train-acc: 0.88267857, val-acc: 0.91250000 val_loss: 0.26290300, dom-acc: 0.56723214
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 108.96736664, sen-loss: 33.47595733, dom-loss: 75.49140877, train-acc: 0.88625000, val-acc: 0.91250000 val_loss: 0.25538975, dom-acc: 0.53839286
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 108.72968608, sen-loss: 32.32679254, dom-loss: 76.40289354, train-acc: 0.89178571, val-acc: 0.91250000 val_loss: 0.24875085, dom-acc: 0.51187500
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 108.75185722, sen-loss: 31.58608474, dom-loss: 77.16577172, train-acc: 0.89267857, val-acc: 0.90750000 val_loss: 0.24293585, dom-acc: 0.48473214
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 109.01205844, sen-loss: 30.99566191, dom-loss: 78.01639676, train-acc: 0.89821429, val-acc: 0.91250000 val_loss: 0.24472302, dom-acc: 0.44741071
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 109.21505493, sen-loss: 30.33780623, dom-loss: 78.87724859, train-acc: 0.90196429, val-acc: 0.91500000 val_loss: 0.23715855, dom-acc: 0.43169643
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 109.07524627, sen-loss: 29.69031027, dom-loss: 79.38493609, train-acc: 0.90321429, val-acc: 0.92000000 val_loss: 0.23452733, dom-acc: 0.39821429
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.04505360, sen-loss: 29.35567275, dom-loss: 79.68938082, train-acc: 0.90500000, val-acc: 0.92000000 val_loss: 0.23089267, dom-acc: 0.38875000
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 108.67372149, sen-loss: 28.75414983, dom-loss: 79.91957170, train-acc: 0.89910714, val-acc: 0.91250000 val_loss: 0.23390314, dom-acc: 0.39910714
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 108.50463140, sen-loss: 28.37919162, dom-loss: 80.12543958, train-acc: 0.90732143, val-acc: 0.92250000 val_loss: 0.22727096, dom-acc: 0.37812500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 107.96638644, sen-loss: 27.80432557, dom-loss: 80.16206032, train-acc: 0.90589286, val-acc: 0.91500000 val_loss: 0.23863444, dom-acc: 0.36125000
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 107.46250641, sen-loss: 27.62884995, dom-loss: 79.83365637, train-acc: 0.91071429, val-acc: 0.92750000 val_loss: 0.22357310, dom-acc: 0.38250000
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 106.77381504, sen-loss: 27.16211294, dom-loss: 79.61170197, train-acc: 0.91035714, val-acc: 0.92500000 val_loss: 0.22278671, dom-acc: 0.39687500
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 105.95421767, sen-loss: 26.67505011, dom-loss: 79.27916759, train-acc: 0.91178571, val-acc: 0.92750000 val_loss: 0.22080016, dom-acc: 0.41946429
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 105.27444166, sen-loss: 26.47272690, dom-loss: 78.80171478, train-acc: 0.91517857, val-acc: 0.92000000 val_loss: 0.22173396, dom-acc: 0.42535714
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 104.93588632, sen-loss: 26.24986109, dom-loss: 78.68602514, train-acc: 0.91464286, val-acc: 0.93000000 val_loss: 0.21771049, dom-acc: 0.44562500
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 103.95651627, sen-loss: 25.78148473, dom-loss: 78.17503136, train-acc: 0.91589286, val-acc: 0.92500000 val_loss: 0.22139271, dom-acc: 0.45321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 103.39586145, sen-loss: 25.38733257, dom-loss: 78.00852901, train-acc: 0.91821429, val-acc: 0.93000000 val_loss: 0.21662258, dom-acc: 0.47991071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.68616563, sen-loss: 25.08756091, dom-loss: 77.59860492, train-acc: 0.91946429, val-acc: 0.93250000 val_loss: 0.21521923, dom-acc: 0.49035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.06874698, sen-loss: 24.79220959, dom-loss: 77.27653760, train-acc: 0.91785714, val-acc: 0.92750000 val_loss: 0.21381773, dom-acc: 0.49714286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.57925653, sen-loss: 24.56783675, dom-loss: 77.01142007, train-acc: 0.92267857, val-acc: 0.93000000 val_loss: 0.21508692, dom-acc: 0.51214286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.28101581, sen-loss: 24.36793681, dom-loss: 76.91307884, train-acc: 0.92142857, val-acc: 0.92750000 val_loss: 0.21234915, dom-acc: 0.51241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.77001512, sen-loss: 24.07089773, dom-loss: 76.69911724, train-acc: 0.92428571, val-acc: 0.92750000 val_loss: 0.21427639, dom-acc: 0.50276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.36105716, sen-loss: 23.70262397, dom-loss: 76.65843326, train-acc: 0.92642857, val-acc: 0.93250000 val_loss: 0.21386535, dom-acc: 0.51214286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.37827402, sen-loss: 23.49164286, dom-loss: 76.88663113, train-acc: 0.92553571, val-acc: 0.93000000 val_loss: 0.21685156, dom-acc: 0.53803571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 99.81799614, sen-loss: 23.24301445, dom-loss: 76.57498139, train-acc: 0.92589286, val-acc: 0.92750000 val_loss: 0.21236055, dom-acc: 0.52428571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.77802891, sen-loss: 23.03918791, dom-loss: 76.73884094, train-acc: 0.92964286, val-acc: 0.92750000 val_loss: 0.21121171, dom-acc: 0.52544643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.63580233, sen-loss: 22.71365748, dom-loss: 76.92214543, train-acc: 0.93053571, val-acc: 0.92250000 val_loss: 0.21051832, dom-acc: 0.51785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.67813534, sen-loss: 22.71844541, dom-loss: 76.95969009, train-acc: 0.93071429, val-acc: 0.92250000 val_loss: 0.21105075, dom-acc: 0.51169643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.22831386, sen-loss: 22.30707312, dom-loss: 76.92124099, train-acc: 0.93232143, val-acc: 0.92250000 val_loss: 0.21052116, dom-acc: 0.48723214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.56529880, sen-loss: 22.11583067, dom-loss: 77.44946831, train-acc: 0.93321429, val-acc: 0.92500000 val_loss: 0.21097673, dom-acc: 0.48839286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 99.18534154, sen-loss: 21.86221651, dom-loss: 77.32312471, train-acc: 0.93321429, val-acc: 0.92500000 val_loss: 0.21108116, dom-acc: 0.49250000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 99.12605661, sen-loss: 21.45482932, dom-loss: 77.67122698, train-acc: 0.93571429, val-acc: 0.92500000 val_loss: 0.21364786, dom-acc: 0.47857143
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_dvd_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.21051832
Testing accuracy: 0.83450000
./work/attentions/electronics_dvd_train.txt
./work/pivots/electronics_dvd_pos.txt
./work/pivots/electronics_dvd_neg.txt
./work/attentions/electronics_dvd_test.txt
loading data...
source domain:  electronics target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 13856
vocab-size:  49470
max  story size: 129
mean story size: 6
max  sentence size: 440
mean sentence size: 15
max memory size: 20
49470
word_embedding done:  49471
5600 400 6000 23009 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(49471, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 154.65628421, sen-loss: 75.30404639, dom-loss: 79.35223782, train-acc: 0.78267857, val-acc: 0.81250000 val_loss: 0.62900537, dom-acc: 0.74062500
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.85938704, sen-loss: 64.72115862, dom-loss: 76.13822812, train-acc: 0.82017857, val-acc: 0.85500000 val_loss: 0.49936807, dom-acc: 0.80642857
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 127.04518378, sen-loss: 51.72594586, dom-loss: 75.31923795, train-acc: 0.82392857, val-acc: 0.85250000 val_loss: 0.41462022, dom-acc: 0.77544643
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 121.20034617, sen-loss: 46.19373417, dom-loss: 75.00661200, train-acc: 0.83678571, val-acc: 0.87000000 val_loss: 0.36331722, dom-acc: 0.75401786
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 117.04972774, sen-loss: 41.97689468, dom-loss: 75.07283294, train-acc: 0.85892857, val-acc: 0.89000000 val_loss: 0.32572836, dom-acc: 0.75250000
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 113.65144932, sen-loss: 38.60677214, dom-loss: 75.04467773, train-acc: 0.87232143, val-acc: 0.88250000 val_loss: 0.30277288, dom-acc: 0.74696429
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 111.17880201, sen-loss: 36.05801475, dom-loss: 75.12078691, train-acc: 0.87910714, val-acc: 0.90750000 val_loss: 0.27973595, dom-acc: 0.72910714
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 109.90331811, sen-loss: 34.46305899, dom-loss: 75.44025898, train-acc: 0.88232143, val-acc: 0.91250000 val_loss: 0.26237595, dom-acc: 0.72366071
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 108.96452379, sen-loss: 33.45980752, dom-loss: 75.50471580, train-acc: 0.88714286, val-acc: 0.91750000 val_loss: 0.25471810, dom-acc: 0.72008929
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 107.78364712, sen-loss: 32.32943282, dom-loss: 75.45421410, train-acc: 0.89142857, val-acc: 0.91750000 val_loss: 0.24798635, dom-acc: 0.70839286
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 107.41982996, sen-loss: 31.59834780, dom-loss: 75.82148176, train-acc: 0.89142857, val-acc: 0.91750000 val_loss: 0.24202871, dom-acc: 0.70330357
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 106.89771491, sen-loss: 31.01064040, dom-loss: 75.88707459, train-acc: 0.89857143, val-acc: 0.91500000 val_loss: 0.24353714, dom-acc: 0.71053571
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 106.44291174, sen-loss: 30.35182287, dom-loss: 76.09108871, train-acc: 0.90232143, val-acc: 0.92000000 val_loss: 0.23628943, dom-acc: 0.69946429
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 105.88877410, sen-loss: 29.71476593, dom-loss: 76.17400855, train-acc: 0.90375000, val-acc: 0.92000000 val_loss: 0.23355713, dom-acc: 0.69321429
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 105.93891877, sen-loss: 29.38514251, dom-loss: 76.55377614, train-acc: 0.90392857, val-acc: 0.92250000 val_loss: 0.22989640, dom-acc: 0.68625000
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 105.65251559, sen-loss: 28.79202136, dom-loss: 76.86049372, train-acc: 0.89750000, val-acc: 0.91500000 val_loss: 0.23291734, dom-acc: 0.66696429
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.32039684, sen-loss: 28.41644785, dom-loss: 76.90394878, train-acc: 0.90660714, val-acc: 0.92500000 val_loss: 0.22633386, dom-acc: 0.67937500
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 104.74821442, sen-loss: 27.84387169, dom-loss: 76.90434313, train-acc: 0.90571429, val-acc: 0.91750000 val_loss: 0.23827790, dom-acc: 0.68848214
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 104.90841424, sen-loss: 27.67269223, dom-loss: 77.23572201, train-acc: 0.90964286, val-acc: 0.93000000 val_loss: 0.22291572, dom-acc: 0.65437500
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 104.50432217, sen-loss: 27.21050104, dom-loss: 77.29382110, train-acc: 0.91035714, val-acc: 0.92750000 val_loss: 0.22208862, dom-acc: 0.66232143
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 104.00248498, sen-loss: 26.72144366, dom-loss: 77.28104120, train-acc: 0.91160714, val-acc: 0.93250000 val_loss: 0.22032759, dom-acc: 0.66312500
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 104.11365932, sen-loss: 26.52301627, dom-loss: 77.59064245, train-acc: 0.91428571, val-acc: 0.93500000 val_loss: 0.22139323, dom-acc: 0.66285714
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 103.88385212, sen-loss: 26.30252505, dom-loss: 77.58132702, train-acc: 0.91321429, val-acc: 0.93250000 val_loss: 0.21750385, dom-acc: 0.64776786
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 103.56941921, sen-loss: 25.83924707, dom-loss: 77.73017198, train-acc: 0.91446429, val-acc: 0.93000000 val_loss: 0.22091898, dom-acc: 0.65839286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.94017476, sen-loss: 25.44539917, dom-loss: 77.49477547, train-acc: 0.91821429, val-acc: 0.93000000 val_loss: 0.21651334, dom-acc: 0.65410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.76864225, sen-loss: 25.14614224, dom-loss: 77.62249994, train-acc: 0.91839286, val-acc: 0.93250000 val_loss: 0.21524248, dom-acc: 0.65044643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.63284570, sen-loss: 24.86209231, dom-loss: 77.77075350, train-acc: 0.91750000, val-acc: 0.93000000 val_loss: 0.21390896, dom-acc: 0.64232143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 102.67900503, sen-loss: 24.62892138, dom-loss: 78.05008394, train-acc: 0.92267857, val-acc: 0.93750000 val_loss: 0.21520936, dom-acc: 0.64410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 102.27418971, sen-loss: 24.43323818, dom-loss: 77.84095156, train-acc: 0.92035714, val-acc: 0.92750000 val_loss: 0.21272482, dom-acc: 0.64419643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.81847674, sen-loss: 24.13014466, dom-loss: 77.68833238, train-acc: 0.92428571, val-acc: 0.93250000 val_loss: 0.21453446, dom-acc: 0.63830357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 101.69100529, sen-loss: 23.77756456, dom-loss: 77.91344100, train-acc: 0.92642857, val-acc: 0.93500000 val_loss: 0.21406022, dom-acc: 0.64000000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 101.17361987, sen-loss: 23.56141708, dom-loss: 77.61220258, train-acc: 0.92339286, val-acc: 0.92750000 val_loss: 0.21739222, dom-acc: 0.65392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.19837153, sen-loss: 23.31894999, dom-loss: 77.87942147, train-acc: 0.92642857, val-acc: 0.92750000 val_loss: 0.21286875, dom-acc: 0.63357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.63947499, sen-loss: 23.10715352, dom-loss: 77.53232127, train-acc: 0.92875000, val-acc: 0.92750000 val_loss: 0.21169470, dom-acc: 0.65232143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.45391750, sen-loss: 22.79454415, dom-loss: 77.65937322, train-acc: 0.93017857, val-acc: 0.92750000 val_loss: 0.21095107, dom-acc: 0.64419643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.55773187, sen-loss: 22.80559328, dom-loss: 77.75213850, train-acc: 0.92875000, val-acc: 0.92750000 val_loss: 0.21172874, dom-acc: 0.63133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.14927292, sen-loss: 22.39399894, dom-loss: 77.75527382, train-acc: 0.92982143, val-acc: 0.92750000 val_loss: 0.21121593, dom-acc: 0.61937500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.62886691, sen-loss: 22.20592469, dom-loss: 77.42294246, train-acc: 0.93339286, val-acc: 0.92750000 val_loss: 0.21144897, dom-acc: 0.64687500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 99.41302580, sen-loss: 21.94430681, dom-loss: 77.46871883, train-acc: 0.93142857, val-acc: 0.92750000 val_loss: 0.21154986, dom-acc: 0.64160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.97385073, sen-loss: 21.54935698, dom-loss: 77.42449397, train-acc: 0.93410714, val-acc: 0.92500000 val_loss: 0.21398836, dom-acc: 0.65348214
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_kitchen_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.21095107
Testing accuracy: 0.90333333
./work/attentions/electronics_kitchen_train.txt
./work/pivots/electronics_kitchen_pos.txt
./work/pivots/electronics_kitchen_neg.txt
./work/attentions/electronics_kitchen_test.txt
loading data...
source domain:  electronics target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  17009 30180
vocab-size:  83059
max  story size: 129
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
83059
word_embedding done:  83060
5600 400 6000 23009 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83060, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.55719399, sen-loss: 75.30517226, dom-loss: 80.25202185, train-acc: 0.78214286, val-acc: 0.81250000 val_loss: 0.62902749, dom-acc: 0.80651786
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 139.14320278, sen-loss: 64.72986388, dom-loss: 74.41333908, train-acc: 0.82000000, val-acc: 0.85500000 val_loss: 0.49960113, dom-acc: 0.79562500
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 123.67787266, sen-loss: 51.75314012, dom-loss: 71.92473245, train-acc: 0.82517857, val-acc: 0.85250000 val_loss: 0.41462094, dom-acc: 0.65883929
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 117.47519457, sen-loss: 46.22651881, dom-loss: 71.24867594, train-acc: 0.83732143, val-acc: 0.87000000 val_loss: 0.36344153, dom-acc: 0.63366071
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 113.47553617, sen-loss: 42.01147650, dom-loss: 71.46405929, train-acc: 0.85875000, val-acc: 0.89000000 val_loss: 0.32584143, dom-acc: 0.61848214
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.61884731, sen-loss: 38.64370129, dom-loss: 72.97514623, train-acc: 0.87285714, val-acc: 0.87750000 val_loss: 0.30315852, dom-acc: 0.61241071
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 109.88729799, sen-loss: 36.09352203, dom-loss: 73.79377604, train-acc: 0.87982143, val-acc: 0.89750000 val_loss: 0.27983996, dom-acc: 0.59080357
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 109.44085842, sen-loss: 34.49298590, dom-loss: 74.94787270, train-acc: 0.88303571, val-acc: 0.91250000 val_loss: 0.26288247, dom-acc: 0.56187500
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 109.85624141, sen-loss: 33.47870797, dom-loss: 76.37753326, train-acc: 0.88660714, val-acc: 0.91250000 val_loss: 0.25535938, dom-acc: 0.53562500
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 109.72995037, sen-loss: 32.32905485, dom-loss: 77.40089500, train-acc: 0.89196429, val-acc: 0.91250000 val_loss: 0.24869800, dom-acc: 0.50008929
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 109.90508229, sen-loss: 31.59216283, dom-loss: 78.31291986, train-acc: 0.89214286, val-acc: 0.90750000 val_loss: 0.24291565, dom-acc: 0.46285714
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 110.12649900, sen-loss: 31.00256741, dom-loss: 79.12393206, train-acc: 0.89803571, val-acc: 0.91250000 val_loss: 0.24471012, dom-acc: 0.40937500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 110.31346470, sen-loss: 30.34477615, dom-loss: 79.96868873, train-acc: 0.90196429, val-acc: 0.92000000 val_loss: 0.23714703, dom-acc: 0.39205357
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 110.04952937, sen-loss: 29.69890936, dom-loss: 80.35062027, train-acc: 0.90321429, val-acc: 0.91750000 val_loss: 0.23445794, dom-acc: 0.37160714
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.96159387, sen-loss: 29.36203200, dom-loss: 80.59956163, train-acc: 0.90482143, val-acc: 0.92000000 val_loss: 0.23089901, dom-acc: 0.36026786
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 109.25342220, sen-loss: 28.76230728, dom-loss: 80.49111491, train-acc: 0.89910714, val-acc: 0.91250000 val_loss: 0.23385583, dom-acc: 0.38571429
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 108.73898429, sen-loss: 28.38838261, dom-loss: 80.35060191, train-acc: 0.90714286, val-acc: 0.92250000 val_loss: 0.22728494, dom-acc: 0.37491071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 107.98201877, sen-loss: 27.81451410, dom-loss: 80.16750437, train-acc: 0.90535714, val-acc: 0.91500000 val_loss: 0.23881981, dom-acc: 0.37741071
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 107.21385592, sen-loss: 27.64047970, dom-loss: 79.57337624, train-acc: 0.91071429, val-acc: 0.92750000 val_loss: 0.22367026, dom-acc: 0.39553571
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 106.22798973, sen-loss: 27.17208826, dom-loss: 79.05590123, train-acc: 0.91000000, val-acc: 0.92500000 val_loss: 0.22293074, dom-acc: 0.42803571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 105.36168385, sen-loss: 26.68491748, dom-loss: 78.67676657, train-acc: 0.91160714, val-acc: 0.92500000 val_loss: 0.22093363, dom-acc: 0.45500000
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 104.55006689, sen-loss: 26.48108991, dom-loss: 78.06897730, train-acc: 0.91482143, val-acc: 0.92250000 val_loss: 0.22186054, dom-acc: 0.46660714
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 104.12683427, sen-loss: 26.25811949, dom-loss: 77.86871487, train-acc: 0.91464286, val-acc: 0.93250000 val_loss: 0.21785080, dom-acc: 0.48098214
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 103.10292625, sen-loss: 25.79145056, dom-loss: 77.31147575, train-acc: 0.91589286, val-acc: 0.92500000 val_loss: 0.22156969, dom-acc: 0.49446429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.64369267, sen-loss: 25.39468585, dom-loss: 77.24900711, train-acc: 0.91750000, val-acc: 0.93250000 val_loss: 0.21684243, dom-acc: 0.51142857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.05846167, sen-loss: 25.09578472, dom-loss: 76.96267682, train-acc: 0.91964286, val-acc: 0.93250000 val_loss: 0.21540384, dom-acc: 0.52517857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.56050211, sen-loss: 24.80014948, dom-loss: 76.76035243, train-acc: 0.91839286, val-acc: 0.92750000 val_loss: 0.21408300, dom-acc: 0.52500000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.08583921, sen-loss: 24.57352738, dom-loss: 76.51231170, train-acc: 0.92321429, val-acc: 0.93000000 val_loss: 0.21537760, dom-acc: 0.53125000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.13389051, sen-loss: 24.37656332, dom-loss: 76.75732726, train-acc: 0.92125000, val-acc: 0.92750000 val_loss: 0.21264239, dom-acc: 0.54071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.76681370, sen-loss: 24.07806984, dom-loss: 76.68874377, train-acc: 0.92410714, val-acc: 0.93000000 val_loss: 0.21465278, dom-acc: 0.52812500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.33890373, sen-loss: 23.71177595, dom-loss: 76.62712783, train-acc: 0.92625000, val-acc: 0.93250000 val_loss: 0.21413124, dom-acc: 0.51901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.46968168, sen-loss: 23.50121959, dom-loss: 76.96846205, train-acc: 0.92500000, val-acc: 0.93000000 val_loss: 0.21728171, dom-acc: 0.53241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.12919098, sen-loss: 23.25304548, dom-loss: 76.87614542, train-acc: 0.92678571, val-acc: 0.92750000 val_loss: 0.21274365, dom-acc: 0.51160714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.29489654, sen-loss: 23.04822237, dom-loss: 77.24667448, train-acc: 0.92875000, val-acc: 0.92500000 val_loss: 0.21165957, dom-acc: 0.52553571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.14816606, sen-loss: 22.71917966, dom-loss: 77.42898649, train-acc: 0.93089286, val-acc: 0.92250000 val_loss: 0.21105610, dom-acc: 0.50687500
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.37566316, sen-loss: 22.72554783, dom-loss: 77.65011555, train-acc: 0.93053571, val-acc: 0.92250000 val_loss: 0.21166423, dom-acc: 0.48553571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 100.10394180, sen-loss: 22.31591002, dom-loss: 77.78803164, train-acc: 0.93178571, val-acc: 0.92250000 val_loss: 0.21121278, dom-acc: 0.46758929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 100.10153770, sen-loss: 22.12413116, dom-loss: 77.97740662, train-acc: 0.93285714, val-acc: 0.92250000 val_loss: 0.21168607, dom-acc: 0.45241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 100.10420907, sen-loss: 21.86844137, dom-loss: 78.23576790, train-acc: 0.93214286, val-acc: 0.92500000 val_loss: 0.21187781, dom-acc: 0.46142857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 99.71765715, sen-loss: 21.45743454, dom-loss: 78.26022249, train-acc: 0.93589286, val-acc: 0.92500000 val_loss: 0.21438691, dom-acc: 0.44473214
---------------------------------------------------

Successfully load model from save path: ./work/models/electronics_video_PNet.ckpt
Best Epoch: [ 35] best val accuracy: 0.00000000 best val loss: 0.21105610
Testing accuracy: 0.83900000
./work/attentions/electronics_video_train.txt
./work/pivots/electronics_video_pos.txt
./work/pivots/electronics_video_neg.txt
./work/attentions/electronics_video_test.txt
loading data...
source domain:  kitchen target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 9750
vocab-size:  78006
max  story size: 189
mean story size: 7
max  sentence size: 702
mean sentence size: 17
max memory size: 20
78006
word_embedding done:  78007
5600 400 6000 19856 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78007, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.69235921, sen-loss: 74.68497992, dom-loss: 81.00737941, train-acc: 0.81107143, val-acc: 0.83000000 val_loss: 0.61627740, dom-acc: 0.77705357
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 137.20855784, sen-loss: 62.68009746, dom-loss: 74.52846026, train-acc: 0.84500000, val-acc: 0.84500000 val_loss: 0.48021832, dom-acc: 0.78419643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 119.51506084, sen-loss: 48.01962209, dom-loss: 71.49543875, train-acc: 0.85125000, val-acc: 0.84750000 val_loss: 0.38572651, dom-acc: 0.65875000
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 112.40607864, sen-loss: 41.37914596, dom-loss: 71.02693290, train-acc: 0.86660714, val-acc: 0.85750000 val_loss: 0.34635201, dom-acc: 0.65625000
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 108.63213563, sen-loss: 37.27742599, dom-loss: 71.35471010, train-acc: 0.87767857, val-acc: 0.87250000 val_loss: 0.32088026, dom-acc: 0.67678571
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 106.27952343, sen-loss: 34.03003900, dom-loss: 72.24948454, train-acc: 0.89321429, val-acc: 0.89750000 val_loss: 0.31128103, dom-acc: 0.68437500
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 104.86332989, sen-loss: 31.80286764, dom-loss: 73.06046242, train-acc: 0.89696429, val-acc: 0.89500000 val_loss: 0.30059987, dom-acc: 0.64366071
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 104.71278036, sen-loss: 30.48570542, dom-loss: 74.22707486, train-acc: 0.90035714, val-acc: 0.90000000 val_loss: 0.30044964, dom-acc: 0.62794643
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 104.79807353, sen-loss: 29.47225588, dom-loss: 75.32581776, train-acc: 0.90089286, val-acc: 0.91000000 val_loss: 0.28790644, dom-acc: 0.58678571
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 105.12581468, sen-loss: 28.62321798, dom-loss: 76.50259614, train-acc: 0.90464286, val-acc: 0.90750000 val_loss: 0.29895800, dom-acc: 0.57267857
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 105.43577743, sen-loss: 28.05822156, dom-loss: 77.37755567, train-acc: 0.90678571, val-acc: 0.91750000 val_loss: 0.29230559, dom-acc: 0.49026786
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 105.93047196, sen-loss: 27.50795752, dom-loss: 78.42251414, train-acc: 0.90946429, val-acc: 0.91500000 val_loss: 0.28412890, dom-acc: 0.44776786
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 106.03293389, sen-loss: 26.86886191, dom-loss: 79.16407162, train-acc: 0.91178571, val-acc: 0.91750000 val_loss: 0.28356490, dom-acc: 0.40544643
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 106.36249429, sen-loss: 26.60521679, dom-loss: 79.75727761, train-acc: 0.91303571, val-acc: 0.92750000 val_loss: 0.28792208, dom-acc: 0.37089286
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 106.33021140, sen-loss: 26.15774682, dom-loss: 80.17246473, train-acc: 0.91410714, val-acc: 0.92250000 val_loss: 0.27905425, dom-acc: 0.35080357
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.31240368, sen-loss: 25.77288886, dom-loss: 80.53951466, train-acc: 0.91446429, val-acc: 0.92250000 val_loss: 0.27502781, dom-acc: 0.33517857
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 106.22843134, sen-loss: 25.43159114, dom-loss: 80.79684085, train-acc: 0.91714286, val-acc: 0.92500000 val_loss: 0.28859723, dom-acc: 0.31375000
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 105.76298052, sen-loss: 25.13656256, dom-loss: 80.62641740, train-acc: 0.91785714, val-acc: 0.92500000 val_loss: 0.28511167, dom-acc: 0.32705357
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 105.27565354, sen-loss: 24.82079494, dom-loss: 80.45485866, train-acc: 0.92017857, val-acc: 0.92500000 val_loss: 0.27381232, dom-acc: 0.34294643
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 104.88218403, sen-loss: 24.61457465, dom-loss: 80.26760972, train-acc: 0.92000000, val-acc: 0.92500000 val_loss: 0.28206691, dom-acc: 0.34366071
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 104.30823088, sen-loss: 24.29240301, dom-loss: 80.01582766, train-acc: 0.92017857, val-acc: 0.92750000 val_loss: 0.27912694, dom-acc: 0.35803571
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 103.67271119, sen-loss: 24.02831559, dom-loss: 79.64439553, train-acc: 0.92125000, val-acc: 0.92000000 val_loss: 0.28887486, dom-acc: 0.36705357
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 102.87748688, sen-loss: 23.63987990, dom-loss: 79.23760706, train-acc: 0.92303571, val-acc: 0.92750000 val_loss: 0.27845615, dom-acc: 0.40151786
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 102.16593325, sen-loss: 23.41477276, dom-loss: 78.75116038, train-acc: 0.92410714, val-acc: 0.92750000 val_loss: 0.27718106, dom-acc: 0.42062500
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_books_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27381232
Testing accuracy: 0.83933333
./work/attentions/kitchen_books_train.txt
./work/pivots/kitchen_books_pos.txt
./work/pivots/kitchen_books_neg.txt
./work/attentions/kitchen_books_test.txt
loading data...
source domain:  kitchen target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 11843
vocab-size:  80685
max  story size: 226
mean story size: 7
max  sentence size: 783
mean sentence size: 17
max memory size: 20
80685
word_embedding done:  80686
5600 400 6000 19856 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(80686, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.42822409, sen-loss: 74.68355155, dom-loss: 80.74467224, train-acc: 0.81125000, val-acc: 0.83000000 val_loss: 0.61625725, dom-acc: 0.75937500
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 137.48676503, sen-loss: 62.67451316, dom-loss: 74.81225222, train-acc: 0.84500000, val-acc: 0.84500000 val_loss: 0.48020905, dom-acc: 0.74044643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 120.24360019, sen-loss: 48.02864367, dom-loss: 72.21495622, train-acc: 0.85053571, val-acc: 0.84500000 val_loss: 0.38615456, dom-acc: 0.62330357
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 113.22023052, sen-loss: 41.42560588, dom-loss: 71.79462427, train-acc: 0.86553571, val-acc: 0.85750000 val_loss: 0.34693703, dom-acc: 0.61214286
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 109.23481750, sen-loss: 37.34199513, dom-loss: 71.89282233, train-acc: 0.87696429, val-acc: 0.87250000 val_loss: 0.32129750, dom-acc: 0.61142857
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 106.96597505, sen-loss: 34.09163260, dom-loss: 72.87434232, train-acc: 0.89357143, val-acc: 0.89750000 val_loss: 0.31151626, dom-acc: 0.60464286
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 105.40084350, sen-loss: 31.86533427, dom-loss: 73.53550887, train-acc: 0.89642857, val-acc: 0.89750000 val_loss: 0.30073559, dom-acc: 0.58044643
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 105.23531878, sen-loss: 30.54217510, dom-loss: 74.69314301, train-acc: 0.90071429, val-acc: 0.90500000 val_loss: 0.30009574, dom-acc: 0.56142857
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 105.16230106, sen-loss: 29.52111269, dom-loss: 75.64118838, train-acc: 0.90142857, val-acc: 0.91250000 val_loss: 0.28754869, dom-acc: 0.52794643
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 105.51483721, sen-loss: 28.66498204, dom-loss: 76.84985542, train-acc: 0.90428571, val-acc: 0.91250000 val_loss: 0.29873598, dom-acc: 0.49321429
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 105.56894171, sen-loss: 28.10069235, dom-loss: 77.46824920, train-acc: 0.90660714, val-acc: 0.91500000 val_loss: 0.29160860, dom-acc: 0.46241071
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 105.99212927, sen-loss: 27.55014621, dom-loss: 78.44198358, train-acc: 0.90910714, val-acc: 0.91250000 val_loss: 0.28352940, dom-acc: 0.43714286
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 105.95317346, sen-loss: 26.90810600, dom-loss: 79.04506755, train-acc: 0.91071429, val-acc: 0.92000000 val_loss: 0.28294435, dom-acc: 0.42026786
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 106.04018617, sen-loss: 26.64644322, dom-loss: 79.39374274, train-acc: 0.91196429, val-acc: 0.92750000 val_loss: 0.28746578, dom-acc: 0.39133929
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 105.68048650, sen-loss: 26.19570876, dom-loss: 79.48477751, train-acc: 0.91339286, val-acc: 0.92500000 val_loss: 0.27822518, dom-acc: 0.39767857
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 105.65552330, sen-loss: 25.81423529, dom-loss: 79.84128827, train-acc: 0.91482143, val-acc: 0.92000000 val_loss: 0.27432430, dom-acc: 0.39848214
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.41117740, sen-loss: 25.47847069, dom-loss: 79.93270671, train-acc: 0.91571429, val-acc: 0.92750000 val_loss: 0.28766283, dom-acc: 0.37991071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 104.68163097, sen-loss: 25.17316743, dom-loss: 79.50846356, train-acc: 0.91767857, val-acc: 0.92750000 val_loss: 0.28465608, dom-acc: 0.38955357
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 104.13051963, sen-loss: 24.86022517, dom-loss: 79.27029443, train-acc: 0.91982143, val-acc: 0.93000000 val_loss: 0.27315134, dom-acc: 0.41330357
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 103.88255078, sen-loss: 24.65535248, dom-loss: 79.22719836, train-acc: 0.92017857, val-acc: 0.92500000 val_loss: 0.28179210, dom-acc: 0.41071429
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 103.01891047, sen-loss: 24.33737668, dom-loss: 78.68153369, train-acc: 0.92053571, val-acc: 0.92750000 val_loss: 0.27856201, dom-acc: 0.42267857
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 102.53431684, sen-loss: 24.07432538, dom-loss: 78.45999104, train-acc: 0.92071429, val-acc: 0.92500000 val_loss: 0.28833601, dom-acc: 0.42651786
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 101.82910770, sen-loss: 23.68680896, dom-loss: 78.14229852, train-acc: 0.92303571, val-acc: 0.92750000 val_loss: 0.27817047, dom-acc: 0.45000000
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 101.17080188, sen-loss: 23.46267948, dom-loss: 77.70812243, train-acc: 0.92410714, val-acc: 0.92750000 val_loss: 0.27690336, dom-acc: 0.45553571
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_dvd_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27315134
Testing accuracy: 0.84350000
./work/attentions/kitchen_dvd_train.txt
./work/pivots/kitchen_dvd_pos.txt
./work/pivots/kitchen_dvd_neg.txt
./work/attentions/kitchen_dvd_test.txt
loading data...
source domain:  kitchen target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 17009
vocab-size:  49470
max  story size: 129
mean story size: 6
max  sentence size: 440
mean sentence size: 15
max memory size: 20
49470
word_embedding done:  49471
5600 400 6000 19856 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(49471, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.02560472, sen-loss: 74.68324047, dom-loss: 80.34236431, train-acc: 0.81089286, val-acc: 0.83000000 val_loss: 0.61624092, dom-acc: 0.65642857
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 139.54327261, sen-loss: 62.66540805, dom-loss: 76.87786371, train-acc: 0.84464286, val-acc: 0.84500000 val_loss: 0.47991905, dom-acc: 0.61598214
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 124.01972073, sen-loss: 47.99949616, dom-loss: 76.02022481, train-acc: 0.85035714, val-acc: 0.84500000 val_loss: 0.38571647, dom-acc: 0.57375000
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 117.12718481, sen-loss: 41.39606977, dom-loss: 75.73111457, train-acc: 0.86571429, val-acc: 0.85500000 val_loss: 0.34630412, dom-acc: 0.63678571
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 112.89999527, sen-loss: 37.29443407, dom-loss: 75.60556155, train-acc: 0.87750000, val-acc: 0.87000000 val_loss: 0.32067266, dom-acc: 0.69008929
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 109.67086071, sen-loss: 34.03295524, dom-loss: 75.63790572, train-acc: 0.89303571, val-acc: 0.89750000 val_loss: 0.31101015, dom-acc: 0.67107143
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 107.63027894, sen-loss: 31.79499511, dom-loss: 75.83528382, train-acc: 0.89714286, val-acc: 0.89750000 val_loss: 0.29994509, dom-acc: 0.70026786
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 106.28391743, sen-loss: 30.46883445, dom-loss: 75.81508285, train-acc: 0.90125000, val-acc: 0.90250000 val_loss: 0.29999846, dom-acc: 0.69053571
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 105.47703689, sen-loss: 29.44793482, dom-loss: 76.02910185, train-acc: 0.90107143, val-acc: 0.91250000 val_loss: 0.28734684, dom-acc: 0.67500000
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 104.69850832, sen-loss: 28.59886152, dom-loss: 76.09964687, train-acc: 0.90464286, val-acc: 0.90750000 val_loss: 0.29852176, dom-acc: 0.69946429
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 104.35717970, sen-loss: 28.03854591, dom-loss: 76.31863385, train-acc: 0.90767857, val-acc: 0.91250000 val_loss: 0.29187444, dom-acc: 0.69178571
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 103.90645856, sen-loss: 27.48783596, dom-loss: 76.41862237, train-acc: 0.90946429, val-acc: 0.91750000 val_loss: 0.28373292, dom-acc: 0.69107143
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 103.42606127, sen-loss: 26.84964866, dom-loss: 76.57641262, train-acc: 0.91142857, val-acc: 0.92000000 val_loss: 0.28309897, dom-acc: 0.66339286
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 103.34015012, sen-loss: 26.58965700, dom-loss: 76.75049299, train-acc: 0.91321429, val-acc: 0.92750000 val_loss: 0.28761607, dom-acc: 0.66107143
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 103.05669773, sen-loss: 26.14074099, dom-loss: 76.91595691, train-acc: 0.91375000, val-acc: 0.92500000 val_loss: 0.27858531, dom-acc: 0.66169643
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 102.83130646, sen-loss: 25.76168152, dom-loss: 77.06962472, train-acc: 0.91517857, val-acc: 0.92000000 val_loss: 0.27456301, dom-acc: 0.67000000
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 102.59699285, sen-loss: 25.41597540, dom-loss: 77.18101746, train-acc: 0.91678571, val-acc: 0.92000000 val_loss: 0.28835386, dom-acc: 0.64839286
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 102.45560032, sen-loss: 25.12480624, dom-loss: 77.33079398, train-acc: 0.91803571, val-acc: 0.92250000 val_loss: 0.28482506, dom-acc: 0.63964286
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 102.35490817, sen-loss: 24.80974762, dom-loss: 77.54516035, train-acc: 0.92035714, val-acc: 0.93000000 val_loss: 0.27347672, dom-acc: 0.64535714
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 102.13522041, sen-loss: 24.60499113, dom-loss: 77.53022921, train-acc: 0.91982143, val-acc: 0.93000000 val_loss: 0.28176510, dom-acc: 0.63553571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 101.97142839, sen-loss: 24.28713410, dom-loss: 77.68429458, train-acc: 0.92035714, val-acc: 0.92750000 val_loss: 0.27864277, dom-acc: 0.60160714
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 101.85163605, sen-loss: 24.01974896, dom-loss: 77.83188713, train-acc: 0.92178571, val-acc: 0.91750000 val_loss: 0.28832415, dom-acc: 0.59008929
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 101.53300601, sen-loss: 23.63807777, dom-loss: 77.89492851, train-acc: 0.92196429, val-acc: 0.92500000 val_loss: 0.27803022, dom-acc: 0.61535714
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 101.44110686, sen-loss: 23.40992485, dom-loss: 78.03118199, train-acc: 0.92321429, val-acc: 0.92750000 val_loss: 0.27647164, dom-acc: 0.57017857
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_electronics_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27347672
Testing accuracy: 0.88283333
./work/attentions/kitchen_electronics_train.txt
./work/pivots/kitchen_electronics_pos.txt
./work/pivots/kitchen_electronics_neg.txt
./work/attentions/kitchen_electronics_test.txt
loading data...
source domain:  kitchen target domain: video
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  13856 30180
vocab-size:  78115
max  story size: 104
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
78115
word_embedding done:  78116
5600 400 6000 19856 30180
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78116, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 155.23726499, sen-loss: 74.68301421, dom-loss: 80.55425107, train-acc: 0.81107143, val-acc: 0.83000000 val_loss: 0.61623037, dom-acc: 0.80678571
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 136.94386458, sen-loss: 62.66893709, dom-loss: 74.27492732, train-acc: 0.84500000, val-acc: 0.84500000 val_loss: 0.48001748, dom-acc: 0.78196429
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 119.60163450, sen-loss: 48.01975569, dom-loss: 71.58187902, train-acc: 0.85035714, val-acc: 0.84500000 val_loss: 0.38587987, dom-acc: 0.64883929
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 112.65489203, sen-loss: 41.42240122, dom-loss: 71.23249054, train-acc: 0.86607143, val-acc: 0.85750000 val_loss: 0.34667015, dom-acc: 0.63660714
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 108.86196375, sen-loss: 37.33725831, dom-loss: 71.52470541, train-acc: 0.87696429, val-acc: 0.87250000 val_loss: 0.32113811, dom-acc: 0.63125000
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 107.01113373, sen-loss: 34.09038474, dom-loss: 72.92074925, train-acc: 0.89321429, val-acc: 0.89750000 val_loss: 0.31143343, dom-acc: 0.62500000
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 105.67861557, sen-loss: 31.86673667, dom-loss: 73.81187940, train-acc: 0.89660714, val-acc: 0.89750000 val_loss: 0.30072507, dom-acc: 0.58491071
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 105.85727823, sen-loss: 30.54441172, dom-loss: 75.31286627, train-acc: 0.90071429, val-acc: 0.90500000 val_loss: 0.30013186, dom-acc: 0.54946429
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 106.19035387, sen-loss: 29.52319695, dom-loss: 76.66715723, train-acc: 0.90142857, val-acc: 0.91250000 val_loss: 0.28753522, dom-acc: 0.51714286
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 106.63352019, sen-loss: 28.66982727, dom-loss: 77.96369272, train-acc: 0.90428571, val-acc: 0.91000000 val_loss: 0.29881072, dom-acc: 0.47714286
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 106.81397629, sen-loss: 28.10331567, dom-loss: 78.71066034, train-acc: 0.90696429, val-acc: 0.91500000 val_loss: 0.29170540, dom-acc: 0.43258929
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 107.13417512, sen-loss: 27.55097079, dom-loss: 79.58320451, train-acc: 0.90910714, val-acc: 0.91250000 val_loss: 0.28365877, dom-acc: 0.39187500
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 107.04868954, sen-loss: 26.90938903, dom-loss: 80.13930064, train-acc: 0.91160714, val-acc: 0.92000000 val_loss: 0.28316140, dom-acc: 0.38473214
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 106.94802845, sen-loss: 26.64711040, dom-loss: 80.30091834, train-acc: 0.91196429, val-acc: 0.92750000 val_loss: 0.28755397, dom-acc: 0.37535714
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 106.54888010, sen-loss: 26.19553858, dom-loss: 80.35334152, train-acc: 0.91321429, val-acc: 0.92500000 val_loss: 0.27840710, dom-acc: 0.38383929
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.04620451, sen-loss: 25.81340969, dom-loss: 80.23279482, train-acc: 0.91446429, val-acc: 0.92000000 val_loss: 0.27455375, dom-acc: 0.38687500
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.50503612, sen-loss: 25.47857482, dom-loss: 80.02646148, train-acc: 0.91571429, val-acc: 0.92750000 val_loss: 0.28790167, dom-acc: 0.38125000
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 104.57989365, sen-loss: 25.17375748, dom-loss: 79.40613675, train-acc: 0.91732143, val-acc: 0.92750000 val_loss: 0.28486121, dom-acc: 0.40973214
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 103.75201988, sen-loss: 24.86068109, dom-loss: 78.89133853, train-acc: 0.92053571, val-acc: 0.93000000 val_loss: 0.27332842, dom-acc: 0.42973214
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 103.29939270, sen-loss: 24.65581965, dom-loss: 78.64357275, train-acc: 0.92000000, val-acc: 0.92500000 val_loss: 0.28187239, dom-acc: 0.44678571
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 102.43085814, sen-loss: 24.33924906, dom-loss: 78.09160906, train-acc: 0.92071429, val-acc: 0.92750000 val_loss: 0.27870920, dom-acc: 0.46151786
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 101.83305931, sen-loss: 24.07610736, dom-loss: 77.75695169, train-acc: 0.92035714, val-acc: 0.92500000 val_loss: 0.28840628, dom-acc: 0.46214286
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 101.14518881, sen-loss: 23.68760506, dom-loss: 77.45758331, train-acc: 0.92392857, val-acc: 0.93000000 val_loss: 0.27826682, dom-acc: 0.48214286
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 100.43792629, sen-loss: 23.46586546, dom-loss: 76.97206086, train-acc: 0.92482143, val-acc: 0.93000000 val_loss: 0.27692464, dom-acc: 0.48616071
---------------------------------------------------

Successfully load model from save path: ./work/models/kitchen_video_PNet.ckpt
Best Epoch: [ 19] best val accuracy: 0.00000000 best val loss: 0.27332842
Testing accuracy: 0.84183333
./work/attentions/kitchen_video_train.txt
./work/pivots/kitchen_video_pos.txt
./work/pivots/kitchen_video_neg.txt
./work/attentions/kitchen_video_test.txt
loading data...
source domain:  video target domain: books
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 9750
vocab-size:  98084
max  story size: 189
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
98084
word_embedding done:  98085
5600 400 6000 36180 9750
train_op
<tf.Variable 'PNet/word2vec:0' shape=(98085, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 157.19344270, sen-loss: 76.31692255, dom-loss: 80.87652087, train-acc: 0.75607143, val-acc: 0.75750000 val_loss: 0.64893889, dom-acc: 0.57446429
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 146.44974124, sen-loss: 68.89134198, dom-loss: 77.55839884, train-acc: 0.79017857, val-acc: 0.80500000 val_loss: 0.57296389, dom-acc: 0.69473214
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 135.70826292, sen-loss: 59.07349479, dom-loss: 76.63476807, train-acc: 0.81553571, val-acc: 0.79500000 val_loss: 0.47924647, dom-acc: 0.78187500
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 125.37153268, sen-loss: 49.29854128, dom-loss: 76.07299119, train-acc: 0.84267857, val-acc: 0.81750000 val_loss: 0.40851992, dom-acc: 0.81276786
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 118.11219805, sen-loss: 42.24147522, dom-loss: 75.87072229, train-acc: 0.85750000, val-acc: 0.84250000 val_loss: 0.36150512, dom-acc: 0.78651786
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 113.30139911, sen-loss: 37.56677029, dom-loss: 75.73462886, train-acc: 0.87857143, val-acc: 0.87000000 val_loss: 0.34379911, dom-acc: 0.79151786
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 110.32947743, sen-loss: 34.79369865, dom-loss: 75.53577876, train-acc: 0.88875000, val-acc: 0.87500000 val_loss: 0.33203095, dom-acc: 0.77482143
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 108.84051234, sen-loss: 33.33817145, dom-loss: 75.50234061, train-acc: 0.89678571, val-acc: 0.88750000 val_loss: 0.31948444, dom-acc: 0.76330357
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 107.79465652, sen-loss: 32.18102372, dom-loss: 75.61363316, train-acc: 0.88750000, val-acc: 0.87500000 val_loss: 0.33489156, dom-acc: 0.73839286
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 106.90353280, sen-loss: 31.31259809, dom-loss: 75.59093517, train-acc: 0.90178571, val-acc: 0.88500000 val_loss: 0.31025052, dom-acc: 0.73616071
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 106.43513465, sen-loss: 30.73258039, dom-loss: 75.70255411, train-acc: 0.90535714, val-acc: 0.89000000 val_loss: 0.31029287, dom-acc: 0.72205357
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 105.78001535, sen-loss: 30.01648398, dom-loss: 75.76353168, train-acc: 0.90910714, val-acc: 0.89250000 val_loss: 0.30711144, dom-acc: 0.70741071
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 105.51702356, sen-loss: 29.50740587, dom-loss: 76.00961781, train-acc: 0.91125000, val-acc: 0.89500000 val_loss: 0.30513194, dom-acc: 0.69678571
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 104.64307004, sen-loss: 28.69011093, dom-loss: 75.95295936, train-acc: 0.91339286, val-acc: 0.89500000 val_loss: 0.30253345, dom-acc: 0.69589286
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 104.89836651, sen-loss: 28.59696341, dom-loss: 76.30140358, train-acc: 0.90410714, val-acc: 0.89000000 val_loss: 0.32353547, dom-acc: 0.68616071
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 104.57041222, sen-loss: 28.15164217, dom-loss: 76.41876966, train-acc: 0.91517857, val-acc: 0.89250000 val_loss: 0.29664823, dom-acc: 0.67312500
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 103.75061226, sen-loss: 27.44998575, dom-loss: 76.30062687, train-acc: 0.91892857, val-acc: 0.89750000 val_loss: 0.30200458, dom-acc: 0.67455357
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 103.75147188, sen-loss: 27.22996484, dom-loss: 76.52150667, train-acc: 0.91732143, val-acc: 0.88750000 val_loss: 0.29438826, dom-acc: 0.66553571
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 103.31386870, sen-loss: 26.55288623, dom-loss: 76.76098198, train-acc: 0.92196429, val-acc: 0.89750000 val_loss: 0.29397935, dom-acc: 0.66419643
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 103.09020680, sen-loss: 26.39918213, dom-loss: 76.69102442, train-acc: 0.92303571, val-acc: 0.90000000 val_loss: 0.29561093, dom-acc: 0.65812500
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 102.88497251, sen-loss: 25.97338568, dom-loss: 76.91158700, train-acc: 0.92446429, val-acc: 0.89500000 val_loss: 0.29471636, dom-acc: 0.65785714
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 102.82142025, sen-loss: 25.72690877, dom-loss: 77.09451139, train-acc: 0.92053571, val-acc: 0.89250000 val_loss: 0.30156353, dom-acc: 0.64973214
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 102.56427169, sen-loss: 25.25849426, dom-loss: 77.30577707, train-acc: 0.92500000, val-acc: 0.89750000 val_loss: 0.29440358, dom-acc: 0.63794643
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 102.17560399, sen-loss: 24.89641221, dom-loss: 77.27919215, train-acc: 0.92535714, val-acc: 0.90250000 val_loss: 0.28994179, dom-acc: 0.62508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.03815001, sen-loss: 24.60635678, dom-loss: 77.43179351, train-acc: 0.92732143, val-acc: 0.89750000 val_loss: 0.29162368, dom-acc: 0.62892857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.58157951, sen-loss: 24.22470800, dom-loss: 77.35687143, train-acc: 0.92678571, val-acc: 0.90000000 val_loss: 0.28885776, dom-acc: 0.61723214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.63155961, sen-loss: 24.06559847, dom-loss: 77.56596100, train-acc: 0.92857143, val-acc: 0.90000000 val_loss: 0.28753000, dom-acc: 0.60767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.37790394, sen-loss: 23.80675556, dom-loss: 77.57114834, train-acc: 0.93000000, val-acc: 0.90000000 val_loss: 0.28776613, dom-acc: 0.60508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.32468075, sen-loss: 23.55900688, dom-loss: 77.76567352, train-acc: 0.93071429, val-acc: 0.89750000 val_loss: 0.29014581, dom-acc: 0.60401786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.13146782, sen-loss: 23.37991020, dom-loss: 77.75155753, train-acc: 0.93089286, val-acc: 0.89750000 val_loss: 0.28656623, dom-acc: 0.60241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.75528616, sen-loss: 22.87176285, dom-loss: 77.88352352, train-acc: 0.93125000, val-acc: 0.88500000 val_loss: 0.28733638, dom-acc: 0.59928571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.73861283, sen-loss: 22.84126180, dom-loss: 77.89735085, train-acc: 0.93142857, val-acc: 0.89750000 val_loss: 0.28615063, dom-acc: 0.58392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.43977785, sen-loss: 22.37199780, dom-loss: 78.06778002, train-acc: 0.93321429, val-acc: 0.89500000 val_loss: 0.29221943, dom-acc: 0.58080357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.92466408, sen-loss: 22.09864698, dom-loss: 77.82601708, train-acc: 0.93500000, val-acc: 0.89250000 val_loss: 0.28962013, dom-acc: 0.58035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.84177154, sen-loss: 21.87711157, dom-loss: 77.96465993, train-acc: 0.93410714, val-acc: 0.89250000 val_loss: 0.28523234, dom-acc: 0.57482143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.75905263, sen-loss: 21.52841038, dom-loss: 78.23064244, train-acc: 0.93678571, val-acc: 0.89750000 val_loss: 0.28422993, dom-acc: 0.57767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.43980891, sen-loss: 21.32868835, dom-loss: 78.11112052, train-acc: 0.93803571, val-acc: 0.89250000 val_loss: 0.28739119, dom-acc: 0.58517857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.16249061, sen-loss: 21.05061750, dom-loss: 78.11187309, train-acc: 0.93732143, val-acc: 0.89000000 val_loss: 0.28588578, dom-acc: 0.56785714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 99.07280409, sen-loss: 20.83829833, dom-loss: 78.23450583, train-acc: 0.93982143, val-acc: 0.89250000 val_loss: 0.28702727, dom-acc: 0.56133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.58087552, sen-loss: 20.46700523, dom-loss: 78.11387008, train-acc: 0.94214286, val-acc: 0.89000000 val_loss: 0.28762695, dom-acc: 0.57276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 98.33156836, sen-loss: 20.26087683, dom-loss: 78.07069141, train-acc: 0.94303571, val-acc: 0.89500000 val_loss: 0.28949231, dom-acc: 0.54901786
---------------------------------------------------

Successfully load model from save path: ./work/models/video_books_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.28422993
Testing accuracy: 0.86716667
./work/attentions/video_books_train.txt
./work/pivots/video_books_pos.txt
./work/pivots/video_books_neg.txt
./work/attentions/video_books_test.txt
loading data...
source domain:  video target domain: dvd
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 11843
vocab-size:  91852
max  story size: 226
mean story size: 8
max  sentence size: 959
mean sentence size: 19
max memory size: 20
91852
word_embedding done:  91853
5600 400 6000 36180 11843
train_op
<tf.Variable 'PNet/word2vec:0' shape=(91853, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 157.22447169, sen-loss: 76.31681615, dom-loss: 80.90765631, train-acc: 0.75607143, val-acc: 0.75750000 val_loss: 0.64892352, dom-acc: 0.45625000
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 147.86604345, sen-loss: 68.88671017, dom-loss: 78.97933346, train-acc: 0.79035714, val-acc: 0.80500000 val_loss: 0.57283658, dom-acc: 0.43919643
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 137.99660528, sen-loss: 59.06135517, dom-loss: 78.93525004, train-acc: 0.81517857, val-acc: 0.79500000 val_loss: 0.47905585, dom-acc: 0.43500000
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 128.10268950, sen-loss: 49.29841366, dom-loss: 78.80427480, train-acc: 0.84232143, val-acc: 0.81500000 val_loss: 0.40859815, dom-acc: 0.44741071
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 120.99749553, sen-loss: 42.25537318, dom-loss: 78.74212235, train-acc: 0.85803571, val-acc: 0.84250000 val_loss: 0.36166528, dom-acc: 0.45294643
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 116.31300938, sen-loss: 37.56848307, dom-loss: 78.74452674, train-acc: 0.87910714, val-acc: 0.87000000 val_loss: 0.34367293, dom-acc: 0.52258929
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 113.39622390, sen-loss: 34.78139201, dom-loss: 78.61483192, train-acc: 0.88892857, val-acc: 0.87500000 val_loss: 0.33187050, dom-acc: 0.57580357
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 111.87239933, sen-loss: 33.32904939, dom-loss: 78.54334974, train-acc: 0.89589286, val-acc: 0.88500000 val_loss: 0.31959954, dom-acc: 0.58964286
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 110.72939420, sen-loss: 32.16755778, dom-loss: 78.56183624, train-acc: 0.88714286, val-acc: 0.87500000 val_loss: 0.33488816, dom-acc: 0.57500000
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 109.70722109, sen-loss: 31.29127215, dom-loss: 78.41594887, train-acc: 0.90178571, val-acc: 0.88750000 val_loss: 0.31014702, dom-acc: 0.59205357
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 109.15241134, sen-loss: 30.71259028, dom-loss: 78.43982112, train-acc: 0.90500000, val-acc: 0.89000000 val_loss: 0.31025240, dom-acc: 0.56035714
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 108.44317460, sen-loss: 29.99153595, dom-loss: 78.45163828, train-acc: 0.90803571, val-acc: 0.89250000 val_loss: 0.30692694, dom-acc: 0.56401786
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 107.83171231, sen-loss: 29.47476110, dom-loss: 78.35695124, train-acc: 0.91142857, val-acc: 0.89500000 val_loss: 0.30496240, dom-acc: 0.59678571
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 107.00273669, sen-loss: 28.66254239, dom-loss: 78.34019434, train-acc: 0.91410714, val-acc: 0.89500000 val_loss: 0.30235237, dom-acc: 0.55562500
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 106.84619766, sen-loss: 28.55786255, dom-loss: 78.28833473, train-acc: 0.90392857, val-acc: 0.89000000 val_loss: 0.32291836, dom-acc: 0.51571429
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 106.39444482, sen-loss: 28.11707223, dom-loss: 78.27737278, train-acc: 0.91589286, val-acc: 0.89000000 val_loss: 0.29653084, dom-acc: 0.53714286
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.68710071, sen-loss: 27.42678937, dom-loss: 78.26031160, train-acc: 0.91857143, val-acc: 0.89750000 val_loss: 0.30163118, dom-acc: 0.58455357
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 105.38366628, sen-loss: 27.20823266, dom-loss: 78.17543346, train-acc: 0.91767857, val-acc: 0.89000000 val_loss: 0.29430351, dom-acc: 0.57133929
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 104.68547720, sen-loss: 26.52498914, dom-loss: 78.16048789, train-acc: 0.92196429, val-acc: 0.89500000 val_loss: 0.29384643, dom-acc: 0.59169643
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 104.48819095, sen-loss: 26.38200245, dom-loss: 78.10618830, train-acc: 0.92196429, val-acc: 0.89500000 val_loss: 0.29544708, dom-acc: 0.60107143
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 104.03020662, sen-loss: 25.94694538, dom-loss: 78.08326107, train-acc: 0.92321429, val-acc: 0.89500000 val_loss: 0.29416892, dom-acc: 0.59696429
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 103.77422249, sen-loss: 25.69813183, dom-loss: 78.07609105, train-acc: 0.92160714, val-acc: 0.89250000 val_loss: 0.30147383, dom-acc: 0.61080357
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 103.33973235, sen-loss: 25.22803743, dom-loss: 78.11169457, train-acc: 0.92535714, val-acc: 0.89500000 val_loss: 0.29373503, dom-acc: 0.59089286
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 102.96080339, sen-loss: 24.86328305, dom-loss: 78.09752017, train-acc: 0.92607143, val-acc: 0.90000000 val_loss: 0.28964621, dom-acc: 0.55901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 102.54411578, sen-loss: 24.58640631, dom-loss: 77.95770943, train-acc: 0.92660714, val-acc: 0.89750000 val_loss: 0.29111552, dom-acc: 0.57589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 102.29740632, sen-loss: 24.20125066, dom-loss: 78.09615541, train-acc: 0.92785714, val-acc: 0.89750000 val_loss: 0.28852335, dom-acc: 0.58098214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 102.06338960, sen-loss: 24.03110228, dom-loss: 78.03228724, train-acc: 0.92892857, val-acc: 0.89750000 val_loss: 0.28740123, dom-acc: 0.57910714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.69210225, sen-loss: 23.76143260, dom-loss: 77.93066961, train-acc: 0.92982143, val-acc: 0.89250000 val_loss: 0.28769279, dom-acc: 0.60276786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.50371426, sen-loss: 23.51525556, dom-loss: 77.98845851, train-acc: 0.92910714, val-acc: 0.89500000 val_loss: 0.29012701, dom-acc: 0.59026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.31035596, sen-loss: 23.34069204, dom-loss: 77.96966439, train-acc: 0.93071429, val-acc: 0.88750000 val_loss: 0.28665638, dom-acc: 0.56151786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.75560921, sen-loss: 22.82141440, dom-loss: 77.93419474, train-acc: 0.93071429, val-acc: 0.88250000 val_loss: 0.28742173, dom-acc: 0.59035714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.67175210, sen-loss: 22.78656714, dom-loss: 77.88518536, train-acc: 0.93125000, val-acc: 0.89500000 val_loss: 0.28637257, dom-acc: 0.59026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.19591880, sen-loss: 22.31807937, dom-loss: 77.87783951, train-acc: 0.93321429, val-acc: 0.89500000 val_loss: 0.29257086, dom-acc: 0.59919643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 99.98409665, sen-loss: 22.04023355, dom-loss: 77.94386292, train-acc: 0.93500000, val-acc: 0.89500000 val_loss: 0.28972548, dom-acc: 0.55107143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 99.71471322, sen-loss: 21.81888202, dom-loss: 77.89583135, train-acc: 0.93321429, val-acc: 0.89500000 val_loss: 0.28579441, dom-acc: 0.54089286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 99.34520870, sen-loss: 21.47780398, dom-loss: 77.86740464, train-acc: 0.93553571, val-acc: 0.89000000 val_loss: 0.28499377, dom-acc: 0.61375000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.10717762, sen-loss: 21.26664661, dom-loss: 77.84053069, train-acc: 0.93571429, val-acc: 0.89500000 val_loss: 0.28832117, dom-acc: 0.60642857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 98.79645658, sen-loss: 20.98205232, dom-loss: 77.81440401, train-acc: 0.93767857, val-acc: 0.89250000 val_loss: 0.28690410, dom-acc: 0.57348214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 98.56347185, sen-loss: 20.76449211, dom-loss: 77.79898012, train-acc: 0.93821429, val-acc: 0.89500000 val_loss: 0.28833535, dom-acc: 0.54026786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.22944736, sen-loss: 20.40760972, dom-loss: 77.82183772, train-acc: 0.94071429, val-acc: 0.89750000 val_loss: 0.28894764, dom-acc: 0.59392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 98.02485257, sen-loss: 20.19503730, dom-loss: 77.82981521, train-acc: 0.94160714, val-acc: 0.89500000 val_loss: 0.29139671, dom-acc: 0.57116071
---------------------------------------------------

Successfully load model from save path: ./work/models/video_dvd_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.28499377
Testing accuracy: 0.87700000
./work/attentions/video_dvd_train.txt
./work/pivots/video_dvd_pos.txt
./work/pivots/video_dvd_neg.txt
./work/attentions/video_dvd_test.txt
loading data...
source domain:  video target domain: electronics
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 17009
vocab-size:  83059
max  story size: 129
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
83059
word_embedding done:  83060
5600 400 6000 36180 17009
train_op
<tf.Variable 'PNet/word2vec:0' shape=(83060, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 153.71538723, sen-loss: 76.31645709, dom-loss: 77.39893067, train-acc: 0.75607143, val-acc: 0.75750000 val_loss: 0.64891279, dom-acc: 0.85125000
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.56276572, sen-loss: 68.89810854, dom-loss: 71.66465753, train-acc: 0.79000000, val-acc: 0.80500000 val_loss: 0.57305396, dom-acc: 0.82714286
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 128.61696243, sen-loss: 59.09865215, dom-loss: 69.51831031, train-acc: 0.81821429, val-acc: 0.81250000 val_loss: 0.47914940, dom-acc: 0.69464286
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 119.65946066, sen-loss: 49.26619750, dom-loss: 70.39326310, train-acc: 0.84339286, val-acc: 0.81750000 val_loss: 0.40798435, dom-acc: 0.59116071
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 114.49292684, sen-loss: 42.21475524, dom-loss: 72.27817160, train-acc: 0.85660714, val-acc: 0.84250000 val_loss: 0.36112550, dom-acc: 0.58250000
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.38066673, sen-loss: 37.62195119, dom-loss: 73.75871503, train-acc: 0.87803571, val-acc: 0.87000000 val_loss: 0.34555590, dom-acc: 0.58589286
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 110.34668648, sen-loss: 34.90442626, dom-loss: 75.44226009, train-acc: 0.88785714, val-acc: 0.87500000 val_loss: 0.33349922, dom-acc: 0.61187500
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.28002882, sen-loss: 33.43048026, dom-loss: 76.84954852, train-acc: 0.89482143, val-acc: 0.88250000 val_loss: 0.32064378, dom-acc: 0.51276786
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 110.83145624, sen-loss: 32.27508615, dom-loss: 78.55636990, train-acc: 0.88785714, val-acc: 0.87500000 val_loss: 0.33661094, dom-acc: 0.42250000
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 111.40086138, sen-loss: 31.39289220, dom-loss: 80.00796968, train-acc: 0.89964286, val-acc: 0.88250000 val_loss: 0.31122243, dom-acc: 0.36776786
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 111.79064435, sen-loss: 30.80267674, dom-loss: 80.98796755, train-acc: 0.90339286, val-acc: 0.89000000 val_loss: 0.31130117, dom-acc: 0.33741071
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 111.54778516, sen-loss: 30.09742446, dom-loss: 81.45036024, train-acc: 0.90892857, val-acc: 0.89500000 val_loss: 0.30807957, dom-acc: 0.33401786
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 110.93069696, sen-loss: 29.56983157, dom-loss: 81.36086506, train-acc: 0.91000000, val-acc: 0.89500000 val_loss: 0.30643597, dom-acc: 0.34160714
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 109.75344640, sen-loss: 28.76248299, dom-loss: 80.99096352, train-acc: 0.91357143, val-acc: 0.90000000 val_loss: 0.30359620, dom-acc: 0.35875000
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.08063495, sen-loss: 28.66997766, dom-loss: 80.41065747, train-acc: 0.90410714, val-acc: 0.88750000 val_loss: 0.32487810, dom-acc: 0.36991071
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 107.51581722, sen-loss: 28.22562543, dom-loss: 79.29019189, train-acc: 0.91410714, val-acc: 0.89750000 val_loss: 0.29753178, dom-acc: 0.41160714
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 105.95792395, sen-loss: 27.52942125, dom-loss: 78.42850262, train-acc: 0.91857143, val-acc: 0.89500000 val_loss: 0.30267799, dom-acc: 0.42741071
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 105.00248522, sen-loss: 27.31445407, dom-loss: 77.68803132, train-acc: 0.91642857, val-acc: 0.89250000 val_loss: 0.29500934, dom-acc: 0.46741071
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 103.53214824, sen-loss: 26.62824897, dom-loss: 76.90389925, train-acc: 0.92035714, val-acc: 0.90000000 val_loss: 0.29444584, dom-acc: 0.48241071
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 102.73747045, sen-loss: 26.48792332, dom-loss: 76.24954736, train-acc: 0.92232143, val-acc: 0.90000000 val_loss: 0.29648650, dom-acc: 0.49892857
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 101.97229052, sen-loss: 26.05851786, dom-loss: 75.91377288, train-acc: 0.92285714, val-acc: 0.90250000 val_loss: 0.29533786, dom-acc: 0.51598214
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 101.70973593, sen-loss: 25.82104736, dom-loss: 75.88868839, train-acc: 0.92089286, val-acc: 0.89500000 val_loss: 0.30410832, dom-acc: 0.51937500
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 100.82338578, sen-loss: 25.35657603, dom-loss: 75.46680975, train-acc: 0.92517857, val-acc: 0.90000000 val_loss: 0.29513660, dom-acc: 0.52526786
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 100.29164743, sen-loss: 24.99322587, dom-loss: 75.29842162, train-acc: 0.92428571, val-acc: 0.90250000 val_loss: 0.29036134, dom-acc: 0.50357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 100.27990091, sen-loss: 24.70536128, dom-loss: 75.57453895, train-acc: 0.92625000, val-acc: 0.90250000 val_loss: 0.29203346, dom-acc: 0.49866071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 100.03580749, sen-loss: 24.31216035, dom-loss: 75.72364712, train-acc: 0.92589286, val-acc: 0.90000000 val_loss: 0.28900889, dom-acc: 0.49875000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 100.15113455, sen-loss: 24.15402939, dom-loss: 75.99710554, train-acc: 0.92589286, val-acc: 0.90250000 val_loss: 0.28755409, dom-acc: 0.48241071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 100.29512638, sen-loss: 23.89464689, dom-loss: 76.40047956, train-acc: 0.92803571, val-acc: 0.90250000 val_loss: 0.28782463, dom-acc: 0.47321429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 100.50530005, sen-loss: 23.63960321, dom-loss: 76.86569685, train-acc: 0.92875000, val-acc: 0.90000000 val_loss: 0.29059386, dom-acc: 0.45125000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 100.62387246, sen-loss: 23.46250612, dom-loss: 77.16136706, train-acc: 0.92857143, val-acc: 0.89750000 val_loss: 0.28685227, dom-acc: 0.44901786
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 100.37699974, sen-loss: 22.95189711, dom-loss: 77.42510283, train-acc: 0.92982143, val-acc: 0.88500000 val_loss: 0.28732160, dom-acc: 0.44366071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 100.74129796, sen-loss: 22.93525346, dom-loss: 77.80604464, train-acc: 0.92964286, val-acc: 0.89500000 val_loss: 0.28636733, dom-acc: 0.43053571
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 100.65736884, sen-loss: 22.45717779, dom-loss: 78.20019096, train-acc: 0.93232143, val-acc: 0.90250000 val_loss: 0.29303131, dom-acc: 0.40964286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 100.61463690, sen-loss: 22.17479934, dom-loss: 78.43983757, train-acc: 0.93339286, val-acc: 0.89250000 val_loss: 0.29053995, dom-acc: 0.40017857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.37573761, sen-loss: 21.95699086, dom-loss: 78.41874707, train-acc: 0.93482143, val-acc: 0.89500000 val_loss: 0.28573069, dom-acc: 0.41071429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.12611353, sen-loss: 21.62757948, dom-loss: 78.49853396, train-acc: 0.93500000, val-acc: 0.89000000 val_loss: 0.28494030, dom-acc: 0.41357143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.95232433, sen-loss: 21.40898561, dom-loss: 78.54333889, train-acc: 0.93428571, val-acc: 0.89500000 val_loss: 0.28851202, dom-acc: 0.41696429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.23609048, sen-loss: 21.14130508, dom-loss: 78.09478521, train-acc: 0.93571429, val-acc: 0.89250000 val_loss: 0.28723583, dom-acc: 0.42133929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 98.89386290, sen-loss: 20.93207551, dom-loss: 77.96178746, train-acc: 0.93660714, val-acc: 0.89250000 val_loss: 0.28830916, dom-acc: 0.42508929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 98.60394210, sen-loss: 20.57552861, dom-loss: 78.02841359, train-acc: 0.93946429, val-acc: 0.89500000 val_loss: 0.28900090, dom-acc: 0.44008929
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 97.76574254, sen-loss: 20.36981411, dom-loss: 77.39592862, train-acc: 0.94089286, val-acc: 0.89750000 val_loss: 0.29167736, dom-acc: 0.44187500
---------------------------------------------------

Successfully load model from save path: ./work/models/video_electronics_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.28494030
Testing accuracy: 0.84383333
./work/attentions/video_electronics_train.txt
./work/pivots/video_electronics_pos.txt
./work/pivots/video_electronics_neg.txt
./work/attentions/video_electronics_test.txt
loading data...
source domain:  video target domain: kitchen
train-size:  5600
val-size:  400
test-size:  6000
unlabeled-size:  30180 13856
vocab-size:  78115
max  story size: 104
mean story size: 7
max  sentence size: 959
mean sentence size: 18
max memory size: 20
78115
word_embedding done:  78116
5600 400 6000 36180 13856
train_op
<tf.Variable 'PNet/word2vec:0' shape=(78116, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_query:0' shape=(1, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/W_w:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/word_attention/b_w:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/W_c:0' shape=(300, 300) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sent_attention/b_c:0' shape=(300,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/sentiment_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/W_fc:0' shape=(300, 2) dtype=float32_ref>
<tf.Variable 'PNet/P_net/domain_classifier/b_fc:0' shape=(2,) dtype=float32_ref>
adapt 0.0 lr 0.005
Epoch: [1  ] loss: 153.28524435, sen-loss: 76.31626213, dom-loss: 76.96898216, train-acc: 0.75625000, val-acc: 0.75750000 val_loss: 0.64891529, dom-acc: 0.87250000
---------------------------------------------------

adapt 0.049958374957880025 lr 0.004655062223111114
Epoch: [2  ] loss: 140.64329660, sen-loss: 68.89209884, dom-loss: 71.75119811, train-acc: 0.79017857, val-acc: 0.80500000 val_loss: 0.57296640, dom-acc: 0.87437500
---------------------------------------------------

adapt 0.0996679946249559 lr 0.0043609797474671065
Epoch: [3  ] loss: 129.58229017, sen-loss: 59.06541726, dom-loss: 70.51687318, train-acc: 0.81535714, val-acc: 0.79750000 val_loss: 0.47904414, dom-acc: 0.80392857
---------------------------------------------------

adapt 0.1 lr 0.004106884509124773
Epoch: [4  ] loss: 120.40896058, sen-loss: 49.24549007, dom-loss: 71.16347021, train-acc: 0.84267857, val-acc: 0.81750000 val_loss: 0.40808019, dom-acc: 0.75964286
---------------------------------------------------

adapt 0.1 lr 0.003884847521204562
Epoch: [5  ] loss: 114.72244304, sen-loss: 42.17097586, dom-loss: 72.55146724, train-acc: 0.85732143, val-acc: 0.84000000 val_loss: 0.36120766, dom-acc: 0.83473214
---------------------------------------------------

adapt 0.1 lr 0.0036889397323344054
Epoch: [6  ] loss: 111.65328074, sen-loss: 37.55636485, dom-loss: 74.09691578, train-acc: 0.87839286, val-acc: 0.87000000 val_loss: 0.34452629, dom-acc: 0.81330357
---------------------------------------------------

adapt 0.1 lr 0.0035146332824396815
Epoch: [7  ] loss: 110.40199316, sen-loss: 34.83342917, dom-loss: 75.56856394, train-acc: 0.88821429, val-acc: 0.87500000 val_loss: 0.33274963, dom-acc: 0.72901786
---------------------------------------------------

adapt 0.1 lr 0.0033584068983394896
Epoch: [8  ] loss: 110.78705341, sen-loss: 33.38046068, dom-loss: 77.40659314, train-acc: 0.89660714, val-acc: 0.88750000 val_loss: 0.32002962, dom-acc: 0.62625000
---------------------------------------------------

adapt 0.1 lr 0.003217478292467414
Epoch: [9  ] loss: 111.54365414, sen-loss: 32.21503730, dom-loss: 79.32861716, train-acc: 0.88714286, val-acc: 0.87500000 val_loss: 0.33552614, dom-acc: 0.55946429
---------------------------------------------------

adapt 0.1 lr 0.003089618120905312
Epoch: [10 ] loss: 112.07278359, sen-loss: 31.34254840, dom-loss: 80.73023587, train-acc: 0.90142857, val-acc: 0.88000000 val_loss: 0.31059834, dom-acc: 0.49276786
---------------------------------------------------

adapt 0.1 lr 0.002973017787506803
Epoch: [11 ] loss: 112.64698189, sen-loss: 30.75792614, dom-loss: 81.88905603, train-acc: 0.90482143, val-acc: 0.89000000 val_loss: 0.31052038, dom-acc: 0.43500000
---------------------------------------------------

adapt 0.1 lr 0.0028661936750064665
Epoch: [12 ] loss: 112.58726645, sen-loss: 30.03498720, dom-loss: 82.55227971, train-acc: 0.90946429, val-acc: 0.89750000 val_loss: 0.30723092, dom-acc: 0.34678571
---------------------------------------------------

adapt 0.1 lr 0.0027679165582520605
Epoch: [13 ] loss: 112.15225559, sen-loss: 29.51895061, dom-loss: 82.63330483, train-acc: 0.91107143, val-acc: 0.89500000 val_loss: 0.30550128, dom-acc: 0.33696429
---------------------------------------------------

adapt 0.1 lr 0.002677158766052148
Epoch: [14 ] loss: 110.72481501, sen-loss: 28.70577225, dom-loss: 82.01904267, train-acc: 0.91321429, val-acc: 0.89750000 val_loss: 0.30272061, dom-acc: 0.35571429
---------------------------------------------------

adapt 0.1 lr 0.002593054072035326
Epoch: [15 ] loss: 109.84178758, sen-loss: 28.60309105, dom-loss: 81.23869693, train-acc: 0.90446429, val-acc: 0.89250000 val_loss: 0.32363078, dom-acc: 0.39008929
---------------------------------------------------

adapt 0.1 lr 0.002514866859365871
Epoch: [16 ] loss: 108.35874003, sen-loss: 28.15424053, dom-loss: 80.20449895, train-acc: 0.91482143, val-acc: 0.89000000 val_loss: 0.29696575, dom-acc: 0.43901786
---------------------------------------------------

adapt 0.1 lr 0.0024419681393728185
Epoch: [17 ] loss: 106.65447575, sen-loss: 27.45953969, dom-loss: 79.19493616, train-acc: 0.91767857, val-acc: 0.89750000 val_loss: 0.30202687, dom-acc: 0.50428571
---------------------------------------------------

adapt 0.1 lr 0.0023738167022013005
Epoch: [18 ] loss: 105.45566720, sen-loss: 27.24213740, dom-loss: 78.21352935, train-acc: 0.91714286, val-acc: 0.88750000 val_loss: 0.29454991, dom-acc: 0.55812500
---------------------------------------------------

adapt 0.1 lr 0.0023099441564585744
Epoch: [19 ] loss: 104.00227576, sen-loss: 26.56053672, dom-loss: 77.44173920, train-acc: 0.92196429, val-acc: 0.90000000 val_loss: 0.29418617, dom-acc: 0.59375000
---------------------------------------------------

adapt 0.1 lr 0.0022499429485385797
Epoch: [20 ] loss: 103.23141110, sen-loss: 26.41208696, dom-loss: 76.81932384, train-acc: 0.92250000, val-acc: 0.90000000 val_loss: 0.29579261, dom-acc: 0.62410714
---------------------------------------------------

adapt 0.1 lr 0.002193456688254154
Epoch: [21 ] loss: 102.38258004, sen-loss: 25.98511915, dom-loss: 76.39746088, train-acc: 0.92321429, val-acc: 0.90000000 val_loss: 0.29487044, dom-acc: 0.64142857
---------------------------------------------------

adapt 0.1 lr 0.0021401722764675278
Epoch: [22 ] loss: 102.02188390, sen-loss: 25.74110763, dom-loss: 76.28077632, train-acc: 0.91964286, val-acc: 0.89250000 val_loss: 0.30235812, dom-acc: 0.64008929
---------------------------------------------------

adapt 0.1 lr 0.0020898134530513185
Epoch: [23 ] loss: 101.37453288, sen-loss: 25.28067271, dom-loss: 76.09386033, train-acc: 0.92482143, val-acc: 0.89750000 val_loss: 0.29474878, dom-acc: 0.62955357
---------------------------------------------------

adapt 0.1 lr 0.002042135473504465
Epoch: [24 ] loss: 101.12446350, sen-loss: 24.91791605, dom-loss: 76.20654756, train-acc: 0.92517857, val-acc: 0.90000000 val_loss: 0.29021719, dom-acc: 0.61375000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [25 ] loss: 101.10460591, sen-loss: 24.63290825, dom-loss: 76.47169733, train-acc: 0.92607143, val-acc: 0.90000000 val_loss: 0.29177806, dom-acc: 0.60705357
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [26 ] loss: 101.01721394, sen-loss: 24.25183072, dom-loss: 76.76538318, train-acc: 0.92767857, val-acc: 0.90000000 val_loss: 0.28908414, dom-acc: 0.57660714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [27 ] loss: 101.32439893, sen-loss: 24.08688373, dom-loss: 77.23751521, train-acc: 0.92785714, val-acc: 0.89750000 val_loss: 0.28780189, dom-acc: 0.55589286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [28 ] loss: 101.40279454, sen-loss: 23.82752643, dom-loss: 77.57526791, train-acc: 0.92857143, val-acc: 0.89250000 val_loss: 0.28801784, dom-acc: 0.51723214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [29 ] loss: 101.66923308, sen-loss: 23.58086948, dom-loss: 78.08836353, train-acc: 0.92964286, val-acc: 0.89500000 val_loss: 0.29050004, dom-acc: 0.46839286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [30 ] loss: 101.87437421, sen-loss: 23.41047574, dom-loss: 78.46389806, train-acc: 0.93053571, val-acc: 0.89000000 val_loss: 0.28696385, dom-acc: 0.44419643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [31 ] loss: 101.64744049, sen-loss: 22.89877953, dom-loss: 78.74866092, train-acc: 0.93035714, val-acc: 0.88500000 val_loss: 0.28769192, dom-acc: 0.40946429
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [32 ] loss: 101.93098068, sen-loss: 22.87536765, dom-loss: 79.05561310, train-acc: 0.93000000, val-acc: 0.89500000 val_loss: 0.28648004, dom-acc: 0.38857143
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [33 ] loss: 101.45976627, sen-loss: 22.40062181, dom-loss: 79.05914432, train-acc: 0.93303571, val-acc: 0.89500000 val_loss: 0.29259285, dom-acc: 0.38723214
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [34 ] loss: 101.21321249, sen-loss: 22.12237936, dom-loss: 79.09083307, train-acc: 0.93303571, val-acc: 0.89250000 val_loss: 0.28972271, dom-acc: 0.38392857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [35 ] loss: 100.65557486, sen-loss: 21.90838959, dom-loss: 78.74718505, train-acc: 0.93285714, val-acc: 0.89750000 val_loss: 0.28561062, dom-acc: 0.40116071
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [36 ] loss: 100.16133684, sen-loss: 21.56701180, dom-loss: 78.59432536, train-acc: 0.93482143, val-acc: 0.89500000 val_loss: 0.28464091, dom-acc: 0.42767857
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [37 ] loss: 99.79861861, sen-loss: 21.36498779, dom-loss: 78.43363053, train-acc: 0.93535714, val-acc: 0.89250000 val_loss: 0.28795889, dom-acc: 0.45214286
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [38 ] loss: 99.02363425, sen-loss: 21.09134653, dom-loss: 77.93228775, train-acc: 0.93660714, val-acc: 0.89750000 val_loss: 0.28648311, dom-acc: 0.45625000
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [39 ] loss: 98.51192123, sen-loss: 20.87275373, dom-loss: 77.63916761, train-acc: 0.93660714, val-acc: 0.89500000 val_loss: 0.28785574, dom-acc: 0.47410714
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [40 ] loss: 97.96792865, sen-loss: 20.52417132, dom-loss: 77.44375736, train-acc: 0.94000000, val-acc: 0.89500000 val_loss: 0.28833315, dom-acc: 0.49669643
---------------------------------------------------

adapt 0.1 lr 0.002
Epoch: [41 ] loss: 97.61022002, sen-loss: 20.31475209, dom-loss: 77.29546791, train-acc: 0.94160714, val-acc: 0.89500000 val_loss: 0.29091543, dom-acc: 0.49553571
---------------------------------------------------

Successfully load model from save path: ./work/models/video_kitchen_PNet.ckpt
Best Epoch: [ 36] best val accuracy: 0.00000000 best val loss: 0.28464091
Testing accuracy: 0.84550000
./work/attentions/video_kitchen_train.txt
./work/pivots/video_kitchen_pos.txt
./work/pivots/video_kitchen_neg.txt
./work/attentions/video_kitchen_test.txt
